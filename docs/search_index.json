[["index.html", "Data Wrangling for Economists Chapter 1 Welcome 1.1 Organization", " Data Wrangling for Economists Michael Topper1 Danny Klinenberg2 2021-09-10 Chapter 1 Welcome This book is designed to go with the UCSB course Econ 245: Data Wrangling for Economists. The book is still a work in progress and will be updated regularly. In the following chapters, you will practice data wrangling with some hand-holding as well as some simple exercises to check your understanding. The purpose of these chapters is the following: Make your homework easier. Make you a better coder by observing good code. Get hands-on practice with functions you will need to complete your assignments. Provide a reference for each topic in the course. It is strongly suggested that you code along with the examples that we go through, although there will be times when copying and pasting can be useful (e.g., loading in a data set). 1.1 Organization The book’s organization was designed to help the second-year PhD student get ready to do research as soon as possible. There is focus on both organization and coding techniques. In later updates, we hope to add in some more advanced topics that are covered in the course such as PDF extracting, webscraping, estimation, making a package, publication tables, and spatial data. The book was made with a tidyverse focus. UC Santa Barbara, michaeltopper@ucsb.edu↩︎ UC Santa Barbara, dklinenberg@ucsb.edu↩︎ "],["intro-to-r.html", "Chapter 2 Intro to R 2.1 Basic summary statistics 2.2 Basic histogram 2.3 Creating Vectors 2.4 Comparing Vectors 2.5 Creating a tibble 2.6 Exercise 2.7 Selected Solutions", " Chapter 2 Intro to R In this chapter, we will be focusing on two topics. The first will be doing common statistics in R, while the other will be an introduction to vectors, tibbles, and logical operators. To begin, we will first load in the data sets that we want to use. We will be using the titanic_train data set from the titanic package. The titanic_train data set provides information on the fate of passengers on the fatal maiden voyage of the ocean liner “Titanic,” summarized according to economic status (class), sex, age and survival. Some import columns: Survived: binary variable equal to 1 if the passenger survived Pclass: the passenger’s class name: the passenger’s name Sex: the sex of the passenger Age: the age of the passenger Let’s load in the data set along with the packages we will be using. Quick aside: A package is a set of functions that are not defined in R by default. Many people create their own packages which have their own unique functions and data sets within. Packages are easy to install, and you only have to install a package one time and then it will be in your local machine for future use. We can install packages using the install.packages function. Important: installing a package does not mean it has been loaded. To be able to use the functions and data sets within the package, you must load the package by using the library function. Also important: a package needs to be loaded within each R session Hence, if you restart R or quit and reopen RStudio (which will restart R), you will need to re-load your packages. Observe: ## installing the necessary packages. The titanic package has the data set we want ## the tidyverse package has the functions we want install.packages(&quot;titanic&quot;) install.packages(&quot;tidyverse&quot;) ## loading in the tidyverse and titanic packages ## remember: functions and data in the packages cannot be used unless loaded in! ## this must be done in each R session! library(tidyverse) ## ── Attaching packages ───────────────────────────────────────────────────────────── tidyverse 1.3.1 ── ## ✓ ggplot2 3.3.5 ✓ purrr 0.3.4 ## ✓ tibble 3.1.4 ✓ dplyr 1.0.7 ## ✓ tidyr 1.1.3 ✓ stringr 1.4.0 ## ✓ readr 2.0.0 ✓ forcats 0.5.1 ## ── Conflicts ──────────────────────────────────────────────────────────────── tidyverse_conflicts() ── ## x dplyr::filter() masks stats::filter() ## x dplyr::lag() masks stats::lag() library(titanic) ## loading in the titanic data set titanic &lt;- titanic_train 2.1 Basic summary statistics To start off, we will go through some basic summary statistics. For this section, we will focus on the Age column of the data set. Let’s say we wanted to view only the Age column of the data. We could accomplish this using the $ attachment. Observe: ## viewing only the age column titanic$Age From this, we can see that there are many values in the Age column, some numbers, and others NA. NA is a value that R recognizes as “missing.” We will touch more on this in lectures and other assignments. For now, just think of it as a missing element. Alternatively, we can get a “snapshot” of our data using the head function. ## using the head function to get a snapshot of the data head(titanic) ## PassengerId Survived Pclass Name Sex Age SibSp ## 1 1 0 3 Braund, Mr. Owen Harris male 22 1 ## 2 2 1 1 Cumings, Mrs. John Bradley (Florence Briggs Thayer) female 38 1 ## 3 3 1 3 Heikkinen, Miss. Laina female 26 0 ## 4 4 1 1 Futrelle, Mrs. Jacques Heath (Lily May Peel) female 35 1 ## 5 5 0 3 Allen, Mr. William Henry male 35 0 ## 6 6 0 3 Moran, Mr. James male NA 0 ## Parch Ticket Fare Cabin Embarked ## 1 0 A/5 21171 7.2500 S ## 2 0 PC 17599 71.2833 C85 C ## 3 0 STON/O2. 3101282 7.9250 S ## 4 0 113803 53.1000 C123 S ## 5 0 373450 8.0500 S ## 6 0 330877 8.4583 Q Taking a look at your data before you start doing analysis is imperative, and the head function gives you a concise preview of most of your columns. Now, let’s attempt some basic summary statistics. For starters, we will use the mean, sd, and var functions to get the mean, standard deviation, and variance of the Age column respectively. ## finding the mean of the age column mean(titanic$Age) ## [1] NA We get a value of NA as our mean of the Age column, despite our knowledge that the Age column contains many different age values. Let’s use the ? to get more information on the mean function to see what may be causing this. ?mean If we look at some of the arguments that the mean function takes, we can see that one of them is called na.rm. The na.rm function is initially defaulted to FALSE. But what does na.rm do? If we set the na.rm argument to TRUE, then na.rm will remove the NA values before the computation proceeds. This is exactly what we need to get a numerical answer for our mean. Before, R was trying to compute missing values into our mean function which does not make any sense (hence the nonsensical answer). ## trying this again using the na.rm = T argument mean(titanic$Age, na.rm = T) ## [1] 29.69912 Now we finally get our desired result. It is important to check your column values using the head function if you ever get NA as a statistic to make sure your whole column is not solely missing values. Now it’s time to try it yourself. 2.1.1 Exercise Using the sd and var functions, find the standard deviation and variance of the Age column. Check your solutions at the end of the document. 2.2 Basic histogram Another tool to give you an idea of the distribution of your data is the hist function. The hist function creates a histogram of your data. Suppose we are interested in the distribution of ages on the titanic. We could quickly get an accurate depiction by graphing a histogram of the column. ## graphing a histogram of the Age column hist(titanic$Age) 2.2.1 Exercise Make a histogram of the Fare column. Change the title of the histogram to “Distribution of Fare.” Do you notice anything interesting? 2.3 Creating Vectors R is a vectorized computer language. This means that when you perform a function, it performs it on an entire vector of values, rather than value-by-value. The vectorization of R allows us to perform functions on an entire column of the spreadsheet, rather than going cell-by-cell. In the previous example with the titanic data set, we took the mean of an entire column of values by simply using the mean function rather than iterating through each element of our column, adding up the values, and dividing by the total. To get a better understanding of vectors, it is useful to create them yourself. Let’s create a vector using the c function. To create a vector, we need a few things: If we want to refer to our vector later, we need to name it. We need to give the vector elements. To begin, we will investigate (1). ## creating a vector but not saving it ## the vector has 4 elements c(1,3,4,10) ## [1] 1 3 4 10 Here, we created a vector of four values: 1, 3, 4, and 10. Notice at the top right of RStudio that our Global Environment did not change. This is because we did not save the vector. To save the vector, we need to give it a name. For our purposes, the vector will be named first_vector. ## creating a vector and naming it to save first_vector &lt;- c(1,3,4,10) Once you run this line, you should see that your Global Environment has changed. It should now have the first_vector along with a small description of what it contains (e.g. 1, 3, 4, 10). The purpose of saving vectors (or saving anything) is so that we can refer to it later. Instead of creating a new vector of 1, 3, 4, and 10 each time we want to use it, we can call it by typing its name. ## calling our vector to observe its elements first_vector ## [1] 1 3 4 10 2.3.1 Exercise Create two vectors called my_own_vector1 and my_own_vector2. Each vector should have four numbers in them. Use whichever numbers you like. 2.4 Comparing Vectors Vectors can be compared to values and other vectors. To perform this task we use logical operators. The logical operators are similar to what you learned in elementary math: greater than, equal to, or not equal to. In R, we use the following for logical operators for comparisons: &lt; greater (less) than &lt;= greater (less) than or equal to == equal to != not equal to The best way to understand how logical operators work is to see them in action. As an example, we will compare our first_vector to the value 7. ## which elements are greater than 7? 7 &gt; first_vector ## [1] TRUE TRUE TRUE FALSE ## ordering does not matter first_vector &lt; 7 ## [1] TRUE TRUE TRUE FALSE Notice that R returned logical values TRUE and FALSE. R went through each element of our vector and checked whether the element was less than the number 7. According to our output, the first three elements in our vector were less than the number 7 (hence TRUE) and the last element was not (hence FALSE). We can evaluate the other logical operators as well: ## checking if each element is not equal to 7 first_vector != 7 ## [1] TRUE TRUE TRUE TRUE ## checking if each element is equal to 7 first_vector == 7 ## [1] FALSE FALSE FALSE FALSE As a brief aside, observe the last line of code we wrote to check whether first_vector was equal to 7. Notice that the “equal to” operator is == rather than =. This is because == checks the equivalence of components, while = is an assignment character similar to &lt;-. In fact, &lt;- and = serve the exact same purpose for assignment. ## assigning our first_vector to the value 7 ## we are not checking whether it is equal to 7 first_vector = 7 ## showing what our first_vector contains after assignment first_vector ## [1] 7 The R community typically uses &lt;- as assignment rather than =. It does not matter which one you use when assigning a variable name, but this class will use the &lt;- assignment as it is the the most frequent one you see online. 2.4.1 Exercise Using your my_own_vector1 and my_own_vector2, compare each of these vectors using the 4 logical operators. 2.5 Creating a tibble A tibble is essentially a collection of columns with names, similar to an excel spreadsheet. If you are familiar with other computer languages, it is a special type of data frame that has particularly user-friendly characteristics such as making previewing data easier. To demonstrate this, we will observe the titanic data set we were working with earlier. Enter and run the following code: ## this is currently a data frame - it does not have nice features to view the data or see the data types ## the code output is suppressed here to make this document shorter titanic The titanic data set is currently a data frame, and hence, it is difficult to view. Let’s change it to a tibble: ## changing the titanic data frame to a tibble titanic &lt;- tibble(titanic) Now that we’ve changed titanic to a tibble, it has nicer previewing features. Observe what happens when we preview the data: ## previewing the data titanic ## # A tibble: 891 × 12 ## PassengerId Survived Pclass Name Sex Age SibSp Parch Ticket Fare Cabin Embarked ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 1 0 3 Braund, Mr. Owen… male 22 1 0 A/5 211… 7.25 &quot;&quot; S ## 2 2 1 1 Cumings, Mrs. Jo… fema… 38 1 0 PC 17599 71.3 &quot;C85&quot; C ## 3 3 1 3 Heikkinen, Miss.… fema… 26 0 0 STON/O2… 7.92 &quot;&quot; S ## 4 4 1 1 Futrelle, Mrs. J… fema… 35 1 0 113803 53.1 &quot;C12… S ## 5 5 0 3 Allen, Mr. Willi… male 35 0 0 373450 8.05 &quot;&quot; S ## 6 6 0 3 Moran, Mr. James male NA 0 0 330877 8.46 &quot;&quot; Q ## 7 7 0 1 McCarthy, Mr. Ti… male 54 0 0 17463 51.9 &quot;E46&quot; S ## 8 8 0 3 Palsson, Master.… male 2 3 1 349909 21.1 &quot;&quot; S ## 9 9 1 3 Johnson, Mrs. Os… fema… 27 0 2 347742 11.1 &quot;&quot; S ## 10 10 1 2 Nasser, Mrs. Nic… fema… 14 1 0 237736 30.1 &quot;&quot; C ## # … with 881 more rows As you can see, we now have a helpful snapshot of our data that displays far nicer than when the titanic data set was a data frame: we can see multiple columns, we see only the first 10 rows, and we can see the data types of each column nested under the column names (for instance, PassengerID is an &lt;int&gt; which stands for integer). Tibbles are what we will be working with most frequently in this course. While it is generally uncommon to manually create a tibble, it is a great exercise to get a better understanding of how they work. First, we will create another two vectors and recreate our first_vector with its original values: ## reassigning original values to the first_vector first_vector &lt;- c(1,3,4,10) ## new vector second_vector &lt;- c(1,1,2,2) Now let’s create a tibble that has two columns. Our first column will be the values of first_vector and our second column will be the values of second_vector. We will use the tibble function which takes vectors as arguments. Similarly to vectors, we need to make sure that we save our tibble by assigning it to a name. ## creating a tibble named first_tibble with two columns first_tibble &lt;- tibble(first_vector, second_vector) Since we assigned this tibble a name, we can now see in our Global Environment that it has saved with our desired name. If we click first_tibble in the Global Environment, it will give us a spreadsheet view of our tibble. We can also accomplish this by using the View function. ## Viewing our tibble in spreadsheet form View(first_tibble) Notice that the tibble has two columns which are named identically to our vectors. As shown earlier using the titanic data, we can also perform actions on this tibble. ## finding the mean of the first_vector column ## I did not need to set the na.rm = T since no NA values, but did it anyways mean(first_tibble$first_vector, na.rm = T) ## [1] 4.5 Alternatively, we could create a tibble with column names that differ from our vector names. In the previous example, our first_tibble has two columns with the names defaulted to first_vector and second_vector. However, we can initialize different names to the column by adding a little more syntax to our tibble function. Suppose I want to make a new tibble named second_tibble with the first_vector and second_vector as columns. However, I want the first_vector column to be named age and the second_vector column to be named gender. ## Creating a new tibble with two columns with the names &quot;age&quot; and &quot;gender&quot; second_tibble &lt;- tibble(&quot;age&quot; = first_vector, &quot;gender&quot; = second_vector) ## showing the result second_tibble ## # A tibble: 4 × 2 ## age gender ## &lt;dbl&gt; &lt;dbl&gt; ## 1 1 1 ## 2 3 1 ## 3 4 2 ## 4 10 2 One other important point: Notice how in the tibble function we used = rather than &lt;- for assigning names. It is important that you use = for assigning arguments rather than &lt;-. Try using &lt;- in the tibble argument, and see how it fails to properly do what we want. 2.6 Exercise Using your vectors my_own_vector1 and my_own_vector2 that you created in the earlier exercise, create a tibble using the tibble function. 2.7 Selected Solutions (Exercise 1.1.1) Standard deviation: 14.5264973 Variance: 211.0191247 "],["the-rproject.html", "Chapter 3 The Rproject", " Chapter 3 The Rproject This chapter provides an introduction to the R Project - an organizational tool which we highly recommend you adopt ASAP. This tool will be invaluable for reproducible research, collaboration, and integrates seamlessly with Git/Github. When working with coauthors, each writer will need to source scripts between local machines. A common problem is that these scripts will no longer work since the file paths are “hard-coded.” For example, if your Homework 1 was part of a research project, the naive start may be something like this: library(tidyverse) ## sets the working directory ## never use this command ever again!!!! setwd(&quot;user/Desktop/econ_145/homework_1/&quot;) If you were to send your script to your coauthor, it would not necessarily run on their local machine. It may be the case that you each have different files within different directories. This is a common problem, but there is one great solution: R Projects. An R Project is a way to locally source all files regardless of computer you are operating on. An R Project automatically detects the file-path leading up to the project meaning you only have to locally source. For instance, say you created a research project folder named “research_project” on your Desktop where you keep all your files. To run a file named “regressions.R” without an Rproject, you would need to call the following using the source function: ## The source function simply runs the file that is passed to it ## note that this file path is &quot;hard-coded&quot; and will not work on any other machine than the one it was created on source(&quot;user/Desktop/research_project/regressions.R&quot;) However, with an Rproject you could simply do the following: ## this code would be able to run on any machine that has the R project source(&quot;regressions.R&quot;) Hence, as specified earlier, an R Project detects the file-path leading to the project folder. So in this case, every file we source will be relative to the user/Desktop/research_project/. This is terrific because R Projects will automatically detect the file-path leading to the folder, so you can send the R Project folder to any coauthor and they will be able to run the files on their local machine without making any changes. As a secondary example, suppose you want to load in the data which is nested in the following path: “user/Desktop/research_project/data/my_data.csv.” If an Rproject was made in the “research_project” folder, then you would call in the data using the following: ## reading in the data my_data &lt;- read_csv(&quot;data/my_data.csv&quot;) This is a much less error-prone way to work collaboratively, and sets you up for success for reproducibility. Aside: If you’re less comfortable writing file-paths, you can use the here package to make the job a bit easier. here finds the file-path leading to the Rproject, then allows you to enter each folder separating the lines with a comma. Creating an R Project is simple. Just click File-&gt;New Project in the RStudio user interface (see Figure ): Figure 3.1: Creating a Project RStudio also allows you to quickly switch between your projects. Figure points out the R Project in the top right hand corner of the `R session. If you click on the name, the drop down appears with all of the previously accessed projects to quickly hop between projects. Figure 3.2: Easily Switching Projects The other benefit of R Projects is the seamless synchronization and integration with Github, which will be covered soon. This is a brief introduction to Rprojects. Additional reading on the matter can be found here. We highly recommend you adopt R Projects from the very beginning of this course - it will save you a ton of time later on! ## here() starts at /Users/dannyklinenberg/OneDrive/Documents/school_stuff/UCSB/TA/data-wrangling-econ-book "],["git-and-github.html", "Chapter 4 Git and Github 4.1 Installing Git 4.2 Create a Github account 4.3 Introduce yourself to Git 4.4 Create a PAT 4.5 The Workflow 4.6 Branches 4.7 .gitignore 4.8 Reverting", " Chapter 4 Git and Github Git is a version control system. Think of it as a better Dropbox - you can track changes of your files and revert back to old versions of projects, but all without pinging your internet every microsecond. Why not just use Dropbox? I will not explicitly tell you why you should not use certain software (by all means, use what works for you), but I will tell you some of the benefits of Git: It allows you to revert to previous versions of your work. Most private sector jobs we will be qualified for use a combination of Git and Github. It sends a signal to employers (and other academics) that you have ability to learn new practical skills. It is excellent for collaborating. It integrates seamlessly with RStudio. No more paper_v1.pdf, paper_v2.pdf, paper_v2_edit.pdf etc. Unfortunately, Git has a steep learning curve. This is mainly due to the jargon that comes along with it.3 I will do my best to define terms, and hopefully make the process a little less confusing. The next few subsections are dedicated to getting all of software installed and communicating with each other for integration. Honestly, this is an extremely painful process without good resources. Fortunately, there is a good one made by Jenny Bryan that I will be following closely throughout this document. 4.1 Installing Git Git is much different from Github. Git is the actual version control software, while Github is hosting service that provide a home for your Git-based projects. Think of Github as an online repository of files that Git can communicate with to make changes. Before we can get to Github, we need to install the Git software on our local machine. But first, let’s check if you installed it at one point already (all of us probably tried learning at one point). Open up the terminal in RStudio (Tools -&gt; Terminal -&gt; New Terminal). You can see an example of where to type this in Figure . Figure 4.1: The terminal in RStudio. Now type in the following: which git ## /usr/bin/git Did you get output showing you a file path similar to the one shown above? Great! You have Git installed and are ready to move on to the next section. If not, you should see something like git: command not found and you will need to install Git. Here is where to download: Windows: https://gitforwindows.org/ Mac: http://git-scm.com/downloads 4.2 Create a Github account Once you have installed Git, it is time to make a Github account. Go here, and create an account. Give your username some thought since it can be a pain to change in the future. I recommend incorporating your actual name into your username. Why? Github is a website many professionals use and it’s important to associate yourself with your work. Additionally, you can create your own website and host it for free using Github, but the url will be something like yourusername.github.io. Hence, choose your username wisely, as it will be how many access your research and materials for the foreseeable future. Also, I recommend against using your UCSB email for your Github account. This email will disappear when you graduate. There is no need for a headache 5 years from now. 4.3 Introduce yourself to Git We are going to use the usethis package to do this. Type the following: library(usethis) use_git_config(user.name = &quot;Jane Doe&quot;, user.email = &quot;jane@example.org&quot;) Substitute your name and the email associated with your Github account!!!!. 4.4 Create a PAT This section is almost copied entirely from Jenny Bryan’s book. A PAT is a personal access token. Think of it as a special password. Nowadays (as of August 2021), you need to have a PAT to be able to do the workflow proposed in this document. Github offers instructions for creating a personal access token and I suggest you read them. You can also type in the following: usethis::create_github_token() This function take you to the web form to create a PAT with the added benefit that it pre-selects the recommended scopes. Once you have created your PAT, install the gitcreds package and run the following lines (following the prompts returned by the function output): ## Respond to the prompt with your PAT you created gitcreds::gitcreds_set() ## checks whether you&#39;ve stored a credential gitcreds::gitcreds_get() 4.5 The Workflow 4.5.1 Definitions Before we get into the workflow, there is a lot of jargon that needs to be defined. Here are some of the main Git commands, explained in layman terms: Clone - make a copy. You will generally only need to use this command once at the start of every project. Stage - get ready to save a new Git version of a file (or files). Commit - save the changes. Push - send the new changes. Pull - “download” any updates. Note that all of these commands are baked into RStudio’s user interface and therefore we will not actually have to type any of these commands (although you can!). These five commands are the essence of using Git. 4.5.2 The Workflow This section is to be covered thoroughly in the lecture. This section will cover the workflow from the start of a new project4 to the general day-to-day tasks. Here are the steps: Create a Github Repository with an intuitive name. Initialize the Github repository with a Readme, and keep all the other defaults the same. This only needs to be done one time for each project. Clone the Github Repository in RStudio. This requires going to the main page of your Github repository and then: Clicking the green CODE button, Copying the HTTPS to your clipboard Going to RStudio and clicking File -&gt; New Project -&gt; Version Control -&gt; Git Copying the HTTPS code into the Repository URL space, naming the RProject the same as your Github repository5, and choosing the folder directory on your computer that you want this project to be nested in. This only needs to be done one time for each project. After these two steps are done, the workflow will remain as follows for the rest of your project. Pull any changes. It’s important to make this a habit as the first thing you do when you open your RStudio project. Edit files as necessary. When done making changes, stage them, commit them (adding in a nice message so you know what you did), and then push them. I will cover each of these thoroughly in further subsections. Pull again. This is mostly as insurance in case you forget to pull in a future step 3. Do it. It will not hurt you and will save you headaches down the road. In the next few subsections, I will demonstrate how to recreate this workflow. 4.5.3 The Git panel of RStudio Assuming you have cloned your repository correctly, you should now have a Git panel whenever you switch to your RStudio project that is connected with Git/Github. Figure shows what each of the aspects of the Git panel means: the panel shows any changes that have been made (checked if staged, unchecked if unstaged), the branch you are on (we are on the master in this case-more on branches later), and buttons to commit, pull, and push. Figure 4.2: The Git panel of RStudio. 4.5.4 Pulling As stated in number 3 of the workflow, you want to press the Pull button before you make any changes. In fact, you should make a habit of this being the first thing you do the second you open an RStudio project. Note that you should also press this button after any commits you make. You can never pull too much. It is safe to continue on your work when you get the message “Already up to date.” 4.5.5 Commiting Recall that “committing” is jargon for submitting a new version of your work. Git and Github will track each commit you make and you can revert back to these specific versions at any time you like. This subsection will focus on committing within RStudio. As shown in Figure , you can press the Commit button to save the version of your work. This will bring up a new interface in RStudio as shown in Figure . From here, you are able to click on any of the files that have saved changes to.6 Check any of the boxes you want to add to this particular commit. Checking a box is equivalent to “staging” a change. When you stage a change, you can see the differences in the files highlighted by green and red. You can stage as many files as you like in a commit. Personally, I think each commit should be a single task, so do not try to stage and commit too many changes at once. You should also add a commit message that explains what you did in the changes. This will be extremely useful for when you want to go back to a previous version. Click the Commit button when ready to commit to the changes. Figure 4.3: The Commit user-interface of RStudio. 4.5.6 Pushing Now that you have committed a change, be sure to push the changes using the Push button (either in the Git panel or Commit UI). Recall that pushing will send the changes to Github. 4.5.7 Pulling (again) Now click on the Pull button in the Git panel. If you are working alone on the master branch (we will talk about branches very soon I promise), then you should get a message saying “Already up to date.” This is the message we want. Before you do anything new, you need to make certain that you are up to date. 4.5.8 The Main Commands (Command Line/Terminal) The workflow described above can all be done within the terminal. I advise against using the terminal7 as a beginner since the terminal itself has a steep learning curve. However, once (or if) you are comfortable using it, it can speed up your interactions with Git/Github. I have mapped out the main commands to get you started in the terminal if you want to try it out. Personally, I was not comfortable using these commands until a few days into writing this lecture, so no rush. Assuming all of this is done on the master branch. Stage changes (e.g., get ready for saving all the changes to a version) git add -A Commit changes (e.g., finalize adding these changes to your version) git commit -m &quot;this is a commit to take the staged changes and save them as a version&quot; Push changes (e.g., put the new changes onto Github) git push 4.5.9 Exercise Make a change to your readme file. Save, stage, commit, push, and pull. Go to your Github Repository - do you see the change? 4.6 Branches Branches are one of the most appealing features of Git. As an example, suppose you want to try a whole new analysis in your paper, but do not necessarily want to “commit” (bad pun) to the changes. This is where branches come in. A branch is essentially a clone of your files, but you can “branch” off into different directions without hurting your master copy. This includes adding new documents, deleting documents, adding data, editing scripts etc. However, if you like the changes you make on the new branch, you can push and merge them into the master copy. Don’t like the changes? Then just delete the branch and switch back to the master copy. For the purposes of this document, we will call our main copy of our files the master branch. This is generally the default on Github8, and you should either adopt this convention or find a very intuitive substitute. Branches have a steep learning curve (as does all of Git), but they are extremely important and make Git worthwhile. 4.6.1 Creating a branch To create a branch, you want to: Go to the Git panel of RStudio then click the purple L in the upper right hand corner as shown in Figure . Name your branch something intuitive so you can remember what it is you wanted to accomplish in the branch. Leave all of the other presets the defaults (e.g., remote = origin, and sync branch with origin). Once you create your branch, you should see the label to the left of the purple L has changed to the branch you just created. Figure 4.4: Creating a branch. 4.6.2 Branches when working independently As stated before, branches are valuable for independent work when you want to try out new ideas or new paths in your analysis. For instance, suppose you want to try out some triple differences in your paper. You can create a new branch titled “analysis_triple_difference,” create new documents, new tables, new R scripts etc. If you want these to be saved on Github (you do), stage, commit, and push the changes you made in the branch. Remember, the branch is effectively a copy of the master with you “branching off” into new directions. All of your work is going to be saved locally and remotely when you commit and push the changes, but it will not be part of the master branch until you push and “create a pull request” on Github (more on this in a second). Hence, let’s go through the two scenarios: (1) you like your changes you made on your branch and want to merge them into the master branch (2) you do not like your changes and want your files to be back to how they were. Now that you like your changes you can create a pull request on Github. Go to your Github account on your web browser and navigate to the appropriate repository. You should that there is a “Compare &amp; pull request” button that shows up at the top of your repository - click there (see Figure ). From here you can “Create a pull request.” A pull request is a request to merge in the new changes you made to the master branch. Click “Create a pull request.” Now, assuming the branch has no conflicts with your master branch, you can click “Merge pull request.” This will merge your changes into the master branch. Switch back to the master branch in RStudio, and pull down the changes. If you made changes on a branch and you don’t like them, you can simply switch back to the master branch and all of your changes will be gone. Of course, your branch still exists, and that may be irritating to you (it is to me). However, you can delete the branch on your local machine by typing git branch -D branch_name in the terminal, and you can delete your branch on Github using point-and-click by going to Code -&gt; Branches -&gt; clicking on the trash can next to the branch you don’t want anymore. Figure 4.5: Creating a pull request. 4.6.3 Branches when working collaboratively Consider the following workflow which is meant to demonstrate the problem of working on only one branch on a collaborative project: You and your coauthor both decide to work on the R script titled regressions_main.R at 10:00am. You want to try one analysis, while your coauthor wants to try another. At 10:30am, you find some unique results that you believe really enhance your paper. You save the file, commit the changes, and (try to) push to Github. However, 5 minutes before you, your coauthor found different results that they believe are worthy of saving. They saved, committed, and pushed to Github at 10:25am. Now when you try and push your changes, there is an issue. Git had already saved the version that your coauthor pushed at 10:25, so it does not know how to merge in your changes with the new lines your coauthor made. Branches solve this problem. Each person can make their own branch which is a copy of the master branch (call this branch_objective), and begin working on their changes. Essentially every task you do when working collaboratively should be done on a branch with each author first pulling any new changes on the master branch, creating a branch that is a copy of the master, adding changes, committing and pushing the changes, then creating a pull request. A rather nice feature of pull requests is that you can set up your coauthor to be a reviewer of the code you wrote. This will allow your coauthor to sign off on the final changes before merging them with the master branch. 4.6.4 Branches with the Terminal Make a new branch and switch to it (note that the “checkout” command means “switch to”): git checkout -b &quot;branch_name&quot; Push the branch to Github so it will sync. git push -u origin branch_name Now you can continue making changes as you did before. One new thing will be that you will need to go to your Github account and merge the changes you made by “creating a pull request.” Deleting a branch so it no longer appears in your branches on RStudio: git branch -D branch_name 4.7 .gitignore When you cloned the Github repository and synced your RStudio project, you should notice in the project folder that there is a file called .gitignore. This is an important file. It tells Git what to…ignore. When should you make edits to this? I find that it is best to ignore large data files as Git was primarily made for tracking text changes. Additionally, I always add the line **/.DS_Store to the .gitignore. These are files that are unnecessary that get updated when compiling documents in RStudio. It’s best to ignore these. You can check out other nice patterns for ignoring files using the git documentation. 4.8 Reverting Of course, the main benefit of using Git is that you can revert back to previous versions of your work. In this section, I will cover how to revert back to a previous version using a “safe” method. 4.8.1 Reverting Safelty I want to preface these next few steps by saying if you are working collaboratively, you and your coauthor should make sure to have each others master branches fully pulled and up to date before doing anything of this sort. Have only one author do these steps. However, for this Guided Exercise, we will be working alone. First, create a new .R file and title it one.R. Save, stage, commit (with message “get back here”), push, and pull. Now, let’s create 2 new .R files - two.R and three.R, adding in some rubbish text to each. Save stage, commit (with message “do not want”), push and pull. Next, let’s try to get back to our previous version where we only had one.R in our file directory. To do this, we are going to need to use both branches and the terminal, as RStudio’s UI does not have this functionality. Open the Terminal in RStudio by going to Tools -&gt; Terminal -&gt; New Terminal. Go to your Github repository on a web browser and click on the “commits” button. Here, we can see all of the commits we’ve made to the repository with numbers associated with each commit. For fun, you can click on any of these commits and browse what the repository looked like at each of these stages (time travel!). Our goal is to get back to the previous version where we only had the .R file titled one.R. Now we are going to follow the following steps: Copy the commit code you see associated with this version (it should read something like bf7a65c). Create a new branch called “revert” and switch to it. Type the following in the terminal git reset --hard bf7a65c. This does a hard reset to the version bf7a65c. Type the following in the terminal git reset --soft Head@{1}. Type the following in the terminal git commit -m \"reverting to bf7a65c\". This commits the version. Type the following in the terminal git push. This pushes the old version to Github. Finally go to Github and create a pull request. You should be able to merge and bring yourself back! Git was created by computer scientists, for computer scientists. So the jargon doesn’t always translate well to economists.↩︎ By project, I do not mean RProject.↩︎ This is not necessary, you can name it whatever you want, but why confuse yourself?↩︎ If you have not saved the changes to your local computer, Git will not show any changes!↩︎ We are actually going to have to use the terminal later in this documenet to revert to previous versions. Of course, you hopefully won’t have to do this too often so you can simply copy and paste the lines shown later on.↩︎ Sometimes Github will set up the master branch with the name main. You can of course change this when initializing your repository.↩︎ "],["cleaning-data-i.html", "Chapter 5 Cleaning Data I 5.1 The Pipe 5.2 The clean_names function 5.3 The select function 5.4 The filter function 5.5 The distinct function 5.6 The mutate function. 5.7 The summarize function 5.8 The group_by and summarize functions 5.9 Exercise 5.10 Selected Solutions", " Chapter 5 Cleaning Data I For this chapter, we will once again be working with the titanic_train data set from the titanic package. This data set provides information on the fate of passengers on the fatal maiden voyage of the ocean liner “Titanic” summarized according to economic status (class), sex, age, and survival. As a reminder, here are some of the important columns: Survived: binary variable equal to 1 if the passenger survived Pclass: the passenger’s class Name: the passenger’s name Sex: the sex of the passenger Age: the age of the passenger Now let’s load in the data and necessary packages. ## install the package if you do not have it # install.packages(&quot;titanic&quot;) library(titanic) library(tidyverse) library(janitor) ## saving our data to the name titanic as a tibble titanic &lt;- tibble(titanic_train) We will be focusing on getting comfortable with the following functions in the tidyverse package: select distinct mutate group_by summarize We will also learn how to use the following functions in the janitor package: clean_names We will be using these functions in conjunction with the pipe (typed as %&gt;%) operator. By going through these exercises, you will see proper ways to utilize functions and learn to write code in a readable and reproducible way. 5.1 The Pipe A pipe (typed as %&gt;%) is a specific operator that comes from the magrittr package, but is automatically loaded in with the tidyverse. Essentially, it makes reading code easier, typing code faster, and finding complicated results very easy. A pipe essentially is saying “and now, do this” to a tibble. Piping is best used to chain together multiple functions to subset your data set into smaller pieces that you find more interesting. We will see this pipe in action in the following sections. Mastering the pipe is essential to quick and efficient cleaning, and you can find some incredible results with using pipes and a few simple functions. To demonstrate how a pipe works, I’ll use a rather bland motivating example: suppose we want to glance at our titanic data using the head function. Before the pipe existed, we would need to type the following: ## without a pipe head(titanic) However, with a pipe, we can type the following: ## using a pipe titanic %&gt;% head() Each of these give us the same result. The way the pipe works, is that it automatically fills the “data” argument of a function with the tibble you are piping from (in this case, the titanic tibble). While this seems extraneous in this example, the benefit of the pipe is that you can combine multiple functions together in a readable way. We will see a demonstration of this as we get further into this Guided Exercise. 5.2 The clean_names function The clean_names function allows us to put all of our column names in our tibble in a standardized format. In particular, the function makes certain that the column names are all lowercase and blank spaces are replaced with an underscore. Keeping your variable names standardized is an important practice that will make data wrangling much easier as your data sets get bigger and you begin collaborating with others. Let’s take a look at our data set without cleaning the names. ## viewing a snapshot of our data set titanic %&gt;% head() ## # A tibble: 6 × 12 ## PassengerId Survived Pclass Name Sex Age SibSp Parch Ticket Fare Cabin Embarked ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 1 0 3 Braund, Mr. Owen… male 22 1 0 A/5 211… 7.25 &quot;&quot; S ## 2 2 1 1 Cumings, Mrs. Jo… female 38 1 0 PC 17599 71.3 &quot;C85&quot; C ## 3 3 1 3 Heikkinen, Miss.… female 26 0 0 STON/O2… 7.92 &quot;&quot; S ## 4 4 1 1 Futrelle, Mrs. J… female 35 1 0 113803 53.1 &quot;C12… S ## 5 5 0 3 Allen, Mr. Willi… male 35 0 0 373450 8.05 &quot;&quot; S ## 6 6 0 3 Moran, Mr. James male NA 0 0 330877 8.46 &quot;&quot; Q Notice here we used the pipe. The pipe told us to take the titanic data set, and perform the head function to it. In terms of piping language we could specify what happened: Use titanic data set And now take the head of the titanic data set Another important aspect of this output to notice is that our columns begin with capital letters (e.g. Class). As stated, we can use the clean_names function from the janitor package to standardize the column name format to all lower case and underscores. Observe: ## Using the clean_names function on the titanic data titanic %&gt;% clean_names() The column names now all have our desired standardized format. Now let’s try to use our previous head function: ## Using the head function again titanic %&gt;% head() ## # A tibble: 6 × 12 ## PassengerId Survived Pclass Name Sex Age SibSp Parch Ticket Fare Cabin Embarked ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 1 0 3 Braund, Mr. Owen… male 22 1 0 A/5 211… 7.25 &quot;&quot; S ## 2 2 1 1 Cumings, Mrs. Jo… female 38 1 0 PC 17599 71.3 &quot;C85&quot; C ## 3 3 1 3 Heikkinen, Miss.… female 26 0 0 STON/O2… 7.92 &quot;&quot; S ## 4 4 1 1 Futrelle, Mrs. J… female 35 1 0 113803 53.1 &quot;C12… S ## 5 5 0 3 Allen, Mr. Willi… male 35 0 0 373450 8.05 &quot;&quot; S ## 6 6 0 3 Moran, Mr. James male NA 0 0 330877 8.46 &quot;&quot; Q The columns have gone back to their normal messy ways! This is because we failed to save the changes we made to our titanic data set. The pipe operator will perform functions on your tibble, but it will not save the changes unless you explicitly tell R to do so. Let’s use the clean_names function, and save the tibble with the cleaned column names. ## saving the titanic tibble with cleaned names titanic &lt;- titanic %&gt;% clean_names() ## viewing the cleaned names data set as it has now been saved titanic %&gt;% head() ## # A tibble: 6 × 12 ## passenger_id survived pclass name sex age sib_sp parch ticket fare cabin embarked ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 1 0 3 Braund, Mr. Owe… male 22 1 0 A/5 211… 7.25 &quot;&quot; S ## 2 2 1 1 Cumings, Mrs. J… fema… 38 1 0 PC 17599 71.3 &quot;C85&quot; C ## 3 3 1 3 Heikkinen, Miss… fema… 26 0 0 STON/O2… 7.92 &quot;&quot; S ## 4 4 1 1 Futrelle, Mrs. … fema… 35 1 0 113803 53.1 &quot;C12… S ## 5 5 0 3 Allen, Mr. Will… male 35 0 0 373450 8.05 &quot;&quot; S ## 6 6 0 3 Moran, Mr. James male NA 0 0 330877 8.46 &quot;&quot; Q For the rest of this guided exercise, we will be working with this tibble. 5.3 The select function The select function is a way to subset your data. It selects whichever variables you are particularly concerned with. For instance, suppose we were only interested in the age and survived columns of the titanic tibble. We could use the select function to observe only these columns. ## selecting only the age and survived columns and then previewing with head titanic %&gt;% select(age, survived) %&gt;% head() ## # A tibble: 6 × 2 ## age survived ## &lt;dbl&gt; &lt;int&gt; ## 1 22 0 ## 2 38 1 ## 3 26 1 ## 4 35 1 ## 5 35 0 ## 6 NA 0 There are a few things that should be noted here. First, we did not save this sub-selection of variables as a new tibble, so this is just a temporary sub-selection. Second, we performed two pipes with one pipe on each line until the ending function. This code could be read as: Use the titanic tibble And then select the age and survived columns And then use the head function to view Of course, if we wanted to save our sub-selection, we could easily do this by assigning it to a new tibble. ## assigning the subselection to a new tibble titanic_age_survived &lt;- titanic %&gt;% select(age, survived) ## did not use head here because do not want only the first 5 rows to be saved Generally, the select function is a great way to subset your data to focus on only the columns you are particularly concerned with. 5.4 The filter function The filter function is one of the most powerful and frequently used functions when combined with a pipe. The filter function filters your data set based on some criteria you choose. For example, suppose we want to only look at children in this data set. We can filter out all of the passengers in the data set that have an age less than 18. Observe: titanic %&gt;% filter(age &lt; 18) %&gt;% head() ## # A tibble: 6 × 12 ## passenger_id survived pclass name sex age sib_sp parch ticket fare cabin embarked ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 8 0 3 &quot;Palsson, Master.… male 2 3 1 349909 21.1 &quot;&quot; S ## 2 10 1 2 &quot;Nasser, Mrs. Nic… fema… 14 1 0 237736 30.1 &quot;&quot; C ## 3 11 1 3 &quot;Sandstrom, Miss.… fema… 4 1 1 PP 95… 16.7 &quot;G6&quot; S ## 4 15 0 3 &quot;Vestrom, Miss. H… fema… 14 0 0 350406 7.85 &quot;&quot; S ## 5 17 0 3 &quot;Rice, Master. Eu… male 2 4 1 382652 29.1 &quot;&quot; Q ## 6 23 1 3 &quot;McGowan, Miss. A… fema… 15 0 0 330923 8.03 &quot;&quot; Q Just to further our understanding, let’s once again write out what this code is doing: Use the titanic tibble And then filter out only rows that have age equal to “Child” And then give the heading of the tibble 5.4.1 Exercise Filter the rows of the titanic tibble such that the column fare column is greater than 100. 5.5 The distinct function The distinct function allows you to see the unique values within a specified column. For instance, suppose we wanted to know all of the unique values that are within the pclass column of the titanic tibble. We could use the distinct function to do this. ## using distinct to find unique values in a column titanic %&gt;% distinct(pclass) ## # A tibble: 3 × 1 ## pclass ## &lt;int&gt; ## 1 3 ## 2 1 ## 3 2 We can see from the distinct function that the pclass column has three unique values: 1, 2, and 3 which correspond to the passengers’ class. The distinct function can be a great way to take a look at your data and figure out what kind of values reside within specific columns. 5.5.1 Exercise Using the distinct function, find the unique values of the age column. 5.6 The mutate function. The mutate function creates a new column in your tibble based on some computation statement. To motivate this, suppose we wanted to create a column in the titanic tibble that is named adjusted_fare which takes the fare column and multiplies it by the rate of inflation to get the ticket fare in today’s prices. Using the mutate function, we could accomplish this: ## assigning a variable the inflation rate inflation_rate &lt;- 27.14 ## creating a new variable called adjusted_fare which will be the fare in today&#39;s dollars titanic %&gt;% mutate(adjusted_fare = fare * inflation_rate) %&gt;% head() ## # A tibble: 6 × 13 ## passenger_id survived pclass name sex age sib_sp parch ticket fare cabin embarked ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 1 0 3 Braund, Mr. Owe… male 22 1 0 A/5 211… 7.25 &quot;&quot; S ## 2 2 1 1 Cumings, Mrs. J… fema… 38 1 0 PC 17599 71.3 &quot;C85&quot; C ## 3 3 1 3 Heikkinen, Miss… fema… 26 0 0 STON/O2… 7.92 &quot;&quot; S ## 4 4 1 1 Futrelle, Mrs. … fema… 35 1 0 113803 53.1 &quot;C12… S ## 5 5 0 3 Allen, Mr. Will… male 35 0 0 373450 8.05 &quot;&quot; S ## 6 6 0 3 Moran, Mr. James male NA 0 0 330877 8.46 &quot;&quot; Q ## # … with 1 more variable: adjusted_fare &lt;dbl&gt; There is actually quite a bit going on here, so it’s worth noting the syntax of the mutate function. ## mutate function syntax titanic %&gt;% mutate(your_variable_name = some expression) Recall that the tibble will not save with this new variable that you created unless you tell it to do so. Where mutate becomes very powerful is using in conjunction with the ifelse function. The ifelse function is a function that takes a conditional statement, and if it is TRUE, assigns a value, and if it is FALSE, assigns a different value. For instance, suppose we want to create a binary variable equal to 1 if a person is under the age of 18 and 0 if are not. Hence, we can use the ifelse function to create our desired binary variable. The syntax for the ifelse function is as follows: ## ifelse syntax ifelse(a condition, value if condition is TRUE, value if condition is FALSE) This will be more clear once you see it in action. Let’s actually create the desired binary variable: titanic %&gt;% mutate(child = ifelse(age &lt; 18, 1, 0)) %&gt;% head() ## # A tibble: 6 × 13 ## passenger_id survived pclass name sex age sib_sp parch ticket fare cabin embarked child ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 1 0 3 Braund, Mr… male 22 1 0 A/5 21… 7.25 &quot;&quot; S 0 ## 2 2 1 1 Cumings, M… fema… 38 1 0 PC 175… 71.3 &quot;C85&quot; C 0 ## 3 3 1 3 Heikkinen,… fema… 26 0 0 STON/O… 7.92 &quot;&quot; S 0 ## 4 4 1 1 Futrelle, … fema… 35 1 0 113803 53.1 &quot;C12… S 0 ## 5 5 0 3 Allen, Mr.… male 35 0 0 373450 8.05 &quot;&quot; S 0 ## 6 6 0 3 Moran, Mr.… male NA 0 0 330877 8.46 &quot;&quot; Q NA Since we cannot see from the preview that we actually created a binary variable, let’s use the distinct function as a check. titanic %&gt;% mutate(child = ifelse(age &lt; 18, 1, 0)) %&gt;% distinct(child) ## # A tibble: 3 × 1 ## child ## &lt;dbl&gt; ## 1 0 ## 2 NA ## 3 1 REMEMBER the child variable DID NOT save unless you specifically tell R to do so. We will save this variable as we will use it later. ## saving the new variable titanic &lt;- titanic %&gt;% mutate(child = ifelse(age &lt; 18, 1, 0)) ## observing the first 5 rows titanic %&gt;% head() ## # A tibble: 6 × 13 ## passenger_id survived pclass name sex age sib_sp parch ticket fare cabin embarked child ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 1 0 3 Braund, Mr… male 22 1 0 A/5 21… 7.25 &quot;&quot; S 0 ## 2 2 1 1 Cumings, M… fema… 38 1 0 PC 175… 71.3 &quot;C85&quot; C 0 ## 3 3 1 3 Heikkinen,… fema… 26 0 0 STON/O… 7.92 &quot;&quot; S 0 ## 4 4 1 1 Futrelle, … fema… 35 1 0 113803 53.1 &quot;C12… S 0 ## 5 5 0 3 Allen, Mr.… male 35 0 0 373450 8.05 &quot;&quot; S 0 ## 6 6 0 3 Moran, Mr.… male NA 0 0 330877 8.46 &quot;&quot; Q NA 5.7 The summarize function The summarize function allows us to create statistics over columns quickly and efficiently. As a demonstration, we will be focusing on our survived column. Let’s suppose that we wanted to know the average of survived. Since this is a binary variable, this would be equivalent to the proportion of people who survived the titanic. Now let’s make a new column called proportion_survived which is equal to the mean of survived. ## finding the average of the survived column titanic %&gt;% summarize(proportion_survived = mean(survived, na.rm = T)) ## # A tibble: 1 × 1 ## proportion_survived ## &lt;dbl&gt; ## 1 0.384 Take a closer look at the summarize function. You can think of the summarize function as similar to the mutate function as it creates a new variable equal to some summary statistic that you tell it to do. The basic syntax for the summarize function is as follows: summarize(your_variable_name = somefunction) As another example, we could find the standard deviation of the survived column using the summarize function. ##finding the standard deviation of the survived column titanic %&gt;% summarize(sd_survived = sd(survived, na.rm = T)) ## # A tibble: 1 × 1 ## sd_survived ## &lt;dbl&gt; ## 1 0.487 5.7.1 Exercise Find the variance of the survived column using the summarize function. See solutions at the end of the document. 5.8 The group_by and summarize functions The group_by and summarize functions work together to make computing statistics within-groups easy. Suppose you wanted to know the average rate of survival by class type on the titanic. In other words, you suspect that the survival rate differs by people of different class To do this, you want to take the average of each group. The group_by function will group classes together and then the summarize function will be able to do summary statistics on each group individually. ## finding the survival rate among classes titanic %&gt;% group_by(pclass) %&gt;% summarize(survival_rate = mean(survived, na.rm = T)) ## # A tibble: 3 × 2 ## pclass survival_rate ## &lt;int&gt; &lt;dbl&gt; ## 1 1 0.630 ## 2 2 0.473 ## 3 3 0.242 From here you can see that the survival rate greatly varied across different classes. It appears that survival was much more prevalent for higher class people. An interesting result! Let’s also review what is happening here in the language of pipes: Take the titanic data And now group by class And now summarize the survival rate by creating a column equal to the mean of the survived column within each class. You may be curious what happens when you do a group_by without a summarize. The truth is, nothing happens! R will create a grouping, but it means nothing unless you actually perform some sort of meaningful statistic on each group. ## using a group_by without a summarize or following function does nothing titanic %&gt;% group_by(sex) ## # A tibble: 891 × 13 ## # Groups: sex [2] ## passenger_id survived pclass name sex age sib_sp parch ticket fare cabin embarked child ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 1 0 3 Braund, M… male 22 1 0 A/5 21… 7.25 &quot;&quot; S 0 ## 2 2 1 1 Cumings, … fema… 38 1 0 PC 175… 71.3 &quot;C85&quot; C 0 ## 3 3 1 3 Heikkinen… fema… 26 0 0 STON/O… 7.92 &quot;&quot; S 0 ## 4 4 1 1 Futrelle,… fema… 35 1 0 113803 53.1 &quot;C12… S 0 ## 5 5 0 3 Allen, Mr… male 35 0 0 373450 8.05 &quot;&quot; S 0 ## 6 6 0 3 Moran, Mr… male NA 0 0 330877 8.46 &quot;&quot; Q NA ## 7 7 0 1 McCarthy,… male 54 0 0 17463 51.9 &quot;E46&quot; S 0 ## 8 8 0 3 Palsson, … male 2 3 1 349909 21.1 &quot;&quot; S 1 ## 9 9 1 3 Johnson, … fema… 27 0 2 347742 11.1 &quot;&quot; S 0 ## 10 10 1 2 Nasser, M… fema… 14 1 0 237736 30.1 &quot;&quot; C 1 ## # … with 881 more rows Since it is imperative to understand the group_by followed by the summarize function, try out a couple of exercises. 5.9 Exercise Did women have a higher rate of survival than males? Find the answer to this question using the group_by and summarize functions. 5.9.1 Exercise Is there a difference in survival rates between women and men who were in a higher class? Using the group_by and summarize functions, find the answer to this question. Hint: put two arguments in the group_by function. ## `summarise()` has grouped output by &#39;sex&#39;. You can override using the `.groups` argument. 5.10 Selected Solutions (Exercise 1.7.1) Variance = 0.24 (Exercise 1.8.1) Women had higher survival rates at 0.74. Males were at 0.19. (Exercise 1.8.2) Females in first, second, and third class had survivals rate of 0.97, 0.92, and 0.5 respectively. On the other hand, males in first, second, and third class had survival rates of 0.37, 0.16, and 0.14 respectively. "],["data-cleaning-ii.html", "Chapter 6 Data Cleaning II 6.1 The count function 6.2 Using the is.na function 6.3 The arrange function 6.4 The filter function with logicals 6.5 Exercise 6.6 Selected Solutions", " Chapter 6 Data Cleaning II For this chapter, we will be importing a dataset from TidyTuesday Github. Tidy Tuesday is a weekly social data project in R where users explore a new dataset each week and share their findings on Twitter with #TidyTuesday. In particular, we will be focusing on a horror movies data set from IMDB. IMDB is the world’s most popular and authoritative source for movie, TV and celebrity content, designed to help fans explore the world of movies and shows and decide what to watch. This data set shows us information on horror movies that are on IMDB’s website. Here are some important variables we will be working with: review_rating- the IMDB users average rating of the movie. release_country - the country the movie was released in. movie_rating - the movie’s Motion Picture Association film rating system score (e.g. G, PG, PG-13) We will be focusing on getting comfortable with the following functions: count is.na arrange filter in conjunction with logicals Let’s begin by importing in the data. To do this, we will be importing it using the read_csv function. Copy and paste the following link: https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-10-22/horror_movies.csv and put it into a tibble called horror_movies using the read_csv function as shown below. ## install the package if you do not have it library(tidyverse) ## loading in the data horror_movies &lt;- read_csv(&quot;https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-10-22/horror_movies.csv&quot;) ## Rows: 3328 Columns: 12 ## ── Column specification ────────────────────────────────────────────────────────────────────────────── ## Delimiter: &quot;,&quot; ## chr (11): title, genres, release_date, release_country, movie_rating, movie_run_time, plot, cast, ... ## dbl (1): review_rating ## ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. Notice how easy it was to read data off of a website and into R using the read_csv function: all it took was copying a pasting a link. 6.1 The count function The count function takes all of the unique elements in a column, and counts how many times each element occurs. For instance, say we want to find the amount of times each movie rating occurs in our data set. We can do this using the count function. ## finding out how many of each rating of horror movie there are horror_movies %&gt;% count(movie_rating) ## # A tibble: 12 × 2 ## movie_rating n ## &lt;chr&gt; &lt;int&gt; ## 1 E 1 ## 2 NC-17 1 ## 3 NOT RATED 699 ## 4 PG 5 ## 5 PG-13 79 ## 6 R 416 ## 7 TV-14 33 ## 8 TV-MA 107 ## 9 TV-PG 1 ## 10 UNRATED 108 ## 11 X 1 ## 12 &lt;NA&gt; 1877 The count function also has a helpful argument called sort. By default, sort is set to FALSE. This means that the count function will not order your results in descending order by the number of times they occur. If you want to view your elements in descending order, you can set the sort argument to TRUE. ## counting in descending order by setting sort = T horror_movies %&gt;% count(movie_rating, sort = T) ## # A tibble: 12 × 2 ## movie_rating n ## &lt;chr&gt; &lt;int&gt; ## 1 &lt;NA&gt; 1877 ## 2 NOT RATED 699 ## 3 R 416 ## 4 UNRATED 108 ## 5 TV-MA 107 ## 6 PG-13 79 ## 7 TV-14 33 ## 8 PG 5 ## 9 E 1 ## 10 NC-17 1 ## 11 TV-PG 1 ## 12 X 1 The sort argument is particularly useful for spotting things like a large amount of NAs, or getting an idea of how a column is distributed. 6.1.1 Exercise What is the most frequent review rating? 6.2 Using the is.na function The is.na function used to find the NAs withing a particular column. It takes one argument: the column you specify . The is.na function works particularly well with the filter function. Suppose we want to see how many NAs are in the movie_rating column. We can do this by count, and a filter in conjunction with the is.na function. ## Looking at only the NAs horror_movies %&gt;% count(movie_rating, sort = T) %&gt;% filter(is.na(movie_rating)) ## # A tibble: 1 × 2 ## movie_rating n ## &lt;chr&gt; &lt;int&gt; ## 1 &lt;NA&gt; 1877 While this is useful, it might be even more useful if we filter out the NAs. Observe: ## Filtering out the NAs horror_movies %&gt;% count(review_rating, sort = T) %&gt;% filter(!is.na(review_rating)) ## # A tibble: 87 × 2 ## review_rating n ## &lt;dbl&gt; &lt;int&gt; ## 1 4.7 95 ## 2 5.2 89 ## 3 5.7 89 ## 4 4.8 83 ## 5 5 83 ## 6 4.6 82 ## 7 5.6 81 ## 8 4.3 80 ## 9 5.1 78 ## 10 5.3 78 ## # … with 77 more rows What exactly happened here? The ! logical is the “not” or “negating” logical. If we were to type filter(is.na(review_rating)) we are telling R to filter all the elements inside of review_rating that are NA. However, if we type filter(!is.na(review_rating)) we are telling R to NOT filter all the elements inside of review_rating taht are NA. Hence, we are actually filtering out the NAs in this line of code. 6.2.1 Exercise Make a new tibble called \\(\\color{magenta}{\\text{horrror\\_movies\\_NA}}\\) that filters out all the NAs in the entire data set. 6.3 The arrange function The arrange function is a simple function that simply sorts columns into ascending or descending order. For instance, suppose we sort our entire data set by which movies had the highest review_rating. We could do this by using the arrange function: ## using the arrange function to sort the review rating from lowest to highest horror_movies %&gt;% arrange(review_rating) %&gt;% head(10) ## # A tibble: 10 × 12 ## title genres release_date release_country movie_rating review_rating movie_run_time plot cast ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Count… Horror 8-Sep-17 USA &lt;NA&gt; 1 &lt;NA&gt; Direc… Robin… ## 2 Una C… Comedy… 21-Sep-17 Peru &lt;NA&gt; 1 91 min Direc… Emili… ## 3 A Rai… Horror 4-Jun-16 Japan &lt;NA&gt; 1.2 &lt;NA&gt; Direc… Hono … ## 4 Potat… Comedy… 23-Jul-15 Germany &lt;NA&gt; 1.3 81 min Direc… Joyce… ## 5 Dead … Horror 31-Jul-13 USA TV-MA 1.4 75 min Direc… Phili… ## 6 Amity… Horror 3-Jan-17 USA &lt;NA&gt; 1.5 77 min Direc… Marie… ## 7 Shark… Horror 14-Aug-15 USA &lt;NA&gt; 1.5 71 min Direc… Angel… ## 8 Attac… Action… 20-Apr-12 India &lt;NA&gt; 1.5 75 min Direc… Emanu… ## 9 Inter… Action… 9-May-16 USA &lt;NA&gt; 1.6 49 min Direc… Danil… ## 10 Raide… Action… 19-May-15 USA NOT RATED 1.6 71 min Direc… Dan D… ## # … with 3 more variables: language &lt;chr&gt;, filming_locations &lt;chr&gt;, budget &lt;chr&gt; By default, the arrange function sorts in ascending rather than descending order. If we want to change this, we can use the arrange function in conjunction with the desc function. ## using the arrange and desc functions to sort the review rating from highest to lowest horror_movies %&gt;% arrange(desc(review_rating)) %&gt;% head(10) ## # A tibble: 10 × 12 ## title genres release_date release_country movie_rating review_rating movie_run_time plot cast ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Boneh… Horror 27-Oct-17 USA &lt;NA&gt; 9.8 &lt;NA&gt; &quot;Dire… Andre… ## 2 The T… Action… 13-Oct-17 USA &lt;NA&gt; 9.6 98 min &quot;Dire… Victo… ## 3 The C… Comedy… 26-Oct-17 Canada &lt;NA&gt; 9.6 97 min &quot;Dire… Elise… ## 4 The S… Horror 1-Oct-17 UK &lt;NA&gt; 9.5 90 min &quot;Dire… Brink… ## 5 Hotel… Action… 29-Sep-17 UK &lt;NA&gt; 9.5 70 min &quot;Dire… Rayne… ## 6 Flesh… Horror 21-Oct-17 USA &lt;NA&gt; 9.5 77 min &quot;Dire… Man W… ## 7 Bong … Horror 20-Oct-17 USA &lt;NA&gt; 9.4 &lt;NA&gt; &quot;Dire… Tiffa… ## 8 The T… Horror 15-May-17 UK &lt;NA&gt; 9.4 72 min &quot;Dire… Rebec… ## 9 Take … Horror 1-Feb-15 USA &lt;NA&gt; 9.3 &lt;NA&gt; &quot;Dire… Tyler… ## 10 Johan… Action… 1-Sep-16 USA &lt;NA&gt; 9.3 52 min &quot;Dire… Curti… ## # … with 3 more variables: language &lt;chr&gt;, filming_locations &lt;chr&gt;, budget &lt;chr&gt; 6.4 The filter function with logicals As you saw last week, the filter function is great for subsetting your data based on a certain criteria. However, the filter function becomes much more powerful when used with logical operators. The three most common logical operators we use are the following: ! - the “not” logical operator &amp; - the “and” logical operator | - the “or” logical operator We already briefly specified the ! logical operator in the previous section, so let’s focus on the &amp; and |. The &amp; operator becomes useful when we want to filter based on more than one true criteria. For example, suppose we want to filter out the movies that received a 9.0 review rating or higher AND was released in Canada. We would need to evaluate whether two criteria are satisfied: the statement “movies that received a 9.0 movie rating or higher”and the statement “released only in Canada.” If both of these statements are TRUE, then they get displayed. If not, they are filtered out. ## filtering for only movies receiving a movie rating of 9.0 or higher ## and in the country Canada horror_movies %&gt;% filter(review_rating &gt;= 9.0 &amp; release_country == &quot;Canada&quot;) ## # A tibble: 2 × 12 ## title genres release_date release_country movie_rating review_rating movie_run_time plot cast ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Tales… Horror 18-Oct-17 Canada &lt;NA&gt; 9 80 min &quot;Direc… Dave M… ## 2 The C… Comed… 26-Oct-17 Canada &lt;NA&gt; 9.6 97 min &quot;Direc… Elise … ## # … with 3 more variables: language &lt;chr&gt;, filming_locations &lt;chr&gt;, budget &lt;chr&gt; Notice that now we are looking at movies that have a 9.0 or higher movie rating, and were released in Canada. We can see that there are only 2 movies that match these criteria. On the other hand, suppose we used the | logical operator instead. The | operator will evaluate whether “review rating is great than 9.0” is TRUE, or “release country is Canada” is TRUE. If either of these statements are TRUE or both of these are TRUE, then the data is displayed. If both of these are false, then they are filtered out. Observe: horror_movies %&gt;% filter(review_rating &gt;= 9.0 | release_country == &quot;Canada&quot;) %&gt;% count(review_rating, release_country, sort = T) ## # A tibble: 52 × 3 ## review_rating release_country n ## &lt;dbl&gt; &lt;chr&gt; &lt;int&gt; ## 1 NA Canada 7 ## 2 9 USA 5 ## 3 4.4 Canada 4 ## 4 4.5 Canada 4 ## 5 2.4 Canada 3 ## 6 3.3 Canada 3 ## 7 4.9 Canada 3 ## 8 9.1 USA 3 ## 9 3.4 Canada 2 ## 10 4 Canada 2 ## # … with 42 more rows Notice that we we have review ratings that are less than 9.0, and also countries that are not Canada. This is because only one of our statements need to be TRUE (although, as stated, both can be TRUE as well). 6.5 Exercise Use the filter function to filter the horror movies that were released only in the USA or were “NOT RATED.” Find which of these movies had the highest review rating. 6.5.1 Exercise Count the number of PG-13 movies that are only in Japan and USA. 6.6 Selected Solutions (Exercise 1.1.1) The most common review rating is 252 for NA, and 95 if we consider NA to not be a review rating. (Exercise 1.4.1) Of the movies that were released in USA or had a rating of “NOT RATED” the highest review rating was a 9.8 by the movie Bonehill Road (2017). (Exercise 1.4.2) Of the movies that were released in USA or Japan, there were 67 movies that were rated “PG-13.” "],["graphics-with-ggplot2.html", "Chapter 7 Graphics with ggplot2 7.1 The grammar of graphics 7.2 Adding options 7.3 Adding multiple plots together 7.4 Creating legends", " Chapter 7 Graphics with ggplot2 In this chapter, we will be focusing on visualization with an emphasis on using ggplot2. While the basic R plots have lower fixed costs to begin using, they are generally less customizable, less initially pretty, and do not work as well in the flow of the tidyverse package. On the other hand, ggplot2 has a logical flow to the graphics system. There is always a specific grammar that must be followed to make graphs, and once you understand it, making graphs becomes fun and (more or less) easy. In practice, you will learn that the essence of making graphs is Googling your questions. There is almost certainly an individual who has needed to make a graph similar to yours, and the R community has probably responded using ggplot2. For this week, we will once again be working with the titanic_train data from the titanic package. As a reminder, this data set provides information on the fate of passengers on the fatal maiden voyage of the ocean liner “Titanic,” summarized according to economic status (class), sex, age, and survival. Here are some of the important columns: Survived: binary variable equal to 1 if the passenger survived Pclass: the passenger’s class name: the passenger’s name Sex: the sex of the passenger Age: the age of the passenger Fare: the price of the ticket the passenger paid ## loading in the data and packages library(tidyverse) library(titanic) ##loading in the data set and cleaning the names titanic &lt;- janitor::clean_names(titanic_train) 7.1 The grammar of graphics The most important aspect to understand in ggplot2 is the “grammar of graphics.” The ggplot2 package has its own syntax for making graphs. This syntax, while confusing at first, is extremely elegant when your graphics become more complicated. Let’s start off with the basic template for making graphics: ##The basic template ## This uses the titanic data set ## creates a histogram with the variable being the age column ggplot(data = titanic, aes(x = age)) + geom_histogram() ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. ## Warning: Removed 177 rows containing non-finite values (stat_bin). There is a LOT to unpack here, so we will go through each component thoroughly: The ggplot function tells R that we want to make a ggplot2 graphic. The ggplot function generally takes two arguments: the tibble you want to use in the data argument, and the aes function. The aes function stands for the “aesthetic mapping.” The purpose of this function is to tell ggplot2 what you want on your x and y axis. It will then take these inputs and “aesthetically map” them to the desired type of graph. You should notice that there are addition signs (+) between these two lines of code. These addition signs can be thought of as a pipe, but for graphics. Specifically, they tell the graph “and now add on this.” The geom_histogram function is a function that specifies we want to make a histogram. All graphs in the ggplot2 package begin with “geom” so that we can easily recognize that we are calling a specific type of graph. Other examples are a scatter plot (geom_point), density plot (geom_density), box-and-whisker plot (geom_boxplot), or a bar graph (geom_bar). 7.2 Adding options As stated above, the + is essentially a %&gt;%, but for graphics. It can be thought of verbally as “and now add this to the graph.” To demonstrate this, let’s use our histogram of the age column that we saw in the last section. Suppose we wanted to do the following: Edit the x axis with our own custom label Edit the y axis with our own custom label Add a title Make the default colors look better This becomes rather simple to do in ggplot2 thanks to the grammar of graphics. ## creating the same plot as above except with a title, and edited axis ggplot(data = titanic, aes(x = age)) + ## use the titanic tibble, map the age column to the graph geom_histogram() + ## and now make a histogram of age xlab(&quot;My x-axis label which is age&quot;) + ## and now label the x axis ylab(&quot;My y axis label which is Count&quot;) + ## and now label the y axis labs(title = &quot;My title&quot;) +## and now label. the label I want is the title theme_light() ## and now use this graphing theme to make it pretty ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. ## Warning: Removed 177 rows containing non-finite values (stat_bin). As specified in the comments, the way we would read this code is Make a ggplot object using the titanic tibble and map age to the x-axis And now add on a histogram And now add on a label the x axis with xlab And now add on a label the y axis with ylabs And now add on the graph a title with labs and the title argument And now use a color scheme that is more appealing with theme_light Let’s try to make a few other types of graphs. As mentioned earlier, graph types usually begin with the geom_ followed by the type of graph that it is. For instance, let’s make a box-and-whisker graph (also known as a box-plot) using the sex and age columns. ## making a box-and-whisker plot ggplot(data = titanic, aes(x = sex, y = age)) + ## make a ggplot plot using the titanic data and map age and sex to x and y geom_boxplot() + ## and now make a box plot with x axis sex and y axis age xlab(&quot;Sex of the passenger&quot;) + ## and now label the x axis ylab(&quot;Age of the passenger&quot;) + ## and now label the y axis labs(title = &quot;Distribution of ages by sex&quot;) + ## and now title the graph theme_light() ## and now make the graph look prettier ## Warning: Removed 177 rows containing non-finite values (stat_boxplot). Now let’s make a scatter plot using the age and fare columns: ## making a scatter plot ggplot(data = titanic, aes(x = age, y = fare)) + ## make a ggplot plot using the titanic dat geom_point() + ## using age as x axis and fare as y axis xlab(&quot;Age of passenger&quot;) + ## and now label the x axis ylab(&quot;Ticket price paid&quot;) + ## and now label the y axis labs(title = &quot;Relationship between age and ticket price&quot;) + ## and now title the graph theme_light() ## and now make the graph look prettier ## Warning: Removed 177 rows containing missing values (geom_point). As shown, it is incredibly simple to switch between different types of graphs. In fact, once you have a template of the certain options you like to add to your graph, you can simply change the geom_ to your desired graph type. 7.3 Adding multiple plots together One of the main draws of ggplot2 is how simple it is to overlay graphs. For instance, suppose we want a plot that has two histograms, one for male age, and one for female age. We can easily do this by simply adding on a geom_histogram argument. ## making two histograms on one graph ggplot(data = titanic, aes(x = age)) + geom_density(data = titanic %&gt;% filter(sex == &quot;male&quot;)) + geom_density(data = titanic %&gt;% filter(sex == &quot;female&quot;)) ## Warning: Removed 124 rows containing non-finite values (stat_density). ## Warning: Removed 53 rows containing non-finite values (stat_density). Notice that the geom_density told ggplot to create a density graph. Also notice something new: we added in a data argument to geom_density. This can be extremely useful when making multiple plots on the same graph. In our example, we told our first density graph to use the titanic data, but filter only the males. This shows how simple it is to add in tidyverse to ggplot! Let’s make this graph a little “prettier.” Suppose we wanted to fill these density graphs with some color so we could tell the difference between them. To do this, we will use the fill argument that comes standard in each geom graph. ## making two histograms on one graph and adding color using the fill argument ggplot(data = titanic, aes(x = age)) + geom_density(data = titanic %&gt;% filter(sex == &quot;male&quot;), fill = &#39;blue&#39;) + geom_density(data = titanic %&gt;% filter(sex == &quot;female&quot;), fill = &#39;red&#39;) ## Warning: Removed 124 rows containing non-finite values (stat_density). ## Warning: Removed 53 rows containing non-finite values (stat_density). Of course, this isn’t so pretty since one of the densities is clearly over-powering the other. This is where another new argument alpha can help us. The alpha argument is simply a number between 0 and 1 which tells ggplot how transparent the color should be. Observe: ## making two histograms on one graph and adding color using the fill argument, and alpha argument ggplot(data = titanic, aes(x = age)) + geom_density(data = titanic %&gt;% filter(sex == &quot;male&quot;), fill = &#39;blue&#39;, alpha = 0.4) + geom_density(data = titanic %&gt;% filter(sex == &quot;female&quot;), fill = &#39;red&#39;, alpha = 0.4) + theme_light() ## Warning: Removed 124 rows containing non-finite values (stat_density). ## Warning: Removed 53 rows containing non-finite values (stat_density). 7.4 Creating legends Legends are automatically created for you using the fill argument within the aesthetic mapping. For instance, suppose we wanted to create a graph similar to above with two densities of age: one for males and one for females. We can actually accomplish this in a more compact way by adding the fill argument to our aesthetic mapping. The fill argument within aes specifically tells ggplot that you want to separate this graph by a categorical variable. ## making two histograms on one graph and adding a legend using the fill argument ggplot(data = titanic, aes(x = age, fill = sex)) + geom_density(alpha = 0.4) + xlab(&quot;Age&quot;) + ## and now add on an xlabel ylab(&quot;Density&quot;) + ## and now add on a ylabel labs(title = &quot;Age by Sex&quot;, fill = &quot;Sex of Passenger&quot;) + ## and now give the graph a title, and # rename the fill argument to &quot;Sex of Passenger&quot; theme_minimal() ## and now make the graph have pretty color scheme ## Warning: Removed 177 rows containing non-finite values (stat_density). Notice that within the labs function, we added in another argument, fill. This fill will specifically label the fill you called in the aesthetic mapping (aes). This is beneficial so you can label your legend however you want. Omit the fill argument in the labs function and see what happens for yourself. Let’s go through the “grammar of graphics” of this graph in plain English: Make a ggplot object and use the titanic tibble and map the age column to the graph, but do two separate “fills” (e.g., versions of the graph), one for each category of sex. And now add on a density plot And now add on a label the x axis with xlab And now add on a label the y axis with ylabs And now add on the graph a title with labs and the title argument, and re-label the fill argument with the label “Sex of Passenger” And now make the graph have default pretty colors with theme_minimal 7.4.1 Exercise Create the following graph (HINT: use the color argument in the aesthetic mapping and turn survived into a factor using as.factor): "],["file-organization.html", "Chapter 8 File Organization 8.1 Organizing 8.2 Rmarkdown", " Chapter 8 File Organization 8.1 Organizing Writing a research project is more than economic theory, models, and analysis; it also relies on being organized. Most of us have never thought about how to organize multi-year projects because we’ve never had to do them. In this chapter, we will be discussing two topics on the organization side of a research project: file organization and reproducible research papers. This will be less about data cleaning and more about staying organized with R. File organization is something we all need but are rarely taught. This section closely follows Princeton’s Empirical Study of Conflict (ESOC) research production guide produced by Jacob N. Shapiro. It is highly recommended you read through the production guide.9 The guide goes through file organization as well as best coding practices. Before continuing, it needs to be noted there is no one best way to organize files. At the end of the day, it is what works best FOR YOU! This portion of the book lays out one example of file organization. It is recommended you tweak the ideas discussed in this portion of the Guided Exercise to meet your needs. Remember, file organization is meant to make your life easier. Before we begin, create a new R Project and name it whatever you want, wherever you want. After creating an R Project, it is time to fill it with all your work. Your base Rproject directory should have every file in a folder except .RData, .Rhistory, lab_diary.txt, the Rproject, project_idea.txt and git_ignore if you’re syncing with Github. Below is an example R Project titled payments_hate_speech: Figure 8.1: Project Layout Note that all folders are numbers and each number is two digits. The leading zeros are to ensure that the documents are in the correct order (e.g., 01, 02, 03). Each folder will have a specific purpose with an accompanying README.txt file. The README.txt file should provide a 1-2 sentence description of what the file is/does. If it is raw data, it should say where the data was from. If it is an R script that creates your main data, say that along with what the inputs and outputs are. If it is an R script that makes Table X for your paper, say it does that along with what it inputs/other files it depends on. Write as if you are writing for someone who has never heard of your project nor ever looked at your data. This person may very well be a reviewer. It will also be you a year after you start your project! Figure provides an example of a README.txt for the folder 03_model. Each file in the folder has a 1 sentence description, a list of the inputs to the file, and what the file outputs. Notice the local file-paths are included in the inputs and outputs so someone can follow the files. Keeping README.txt files are tedious but incredibility important. If done thoroughly, the data replication needed when submitting papers is already complete. You just send the R Project. Figure 8.2: README.txt Example for 03_model The lab_diary.txt is a common tool used in other fields. It’s a place to record what you tried during the day. These notes often come in handy as they cut down the time you spend re-estimating the same regression because you forgot what you did it a week ago. Here is an example of a lab diary. Figure 8.3: Lab Diary When progressing through your research career, it’s important to figure out an organization style that works best for you. After you find it, create a general template of it. Then, whenever you have a new idea, you can just copy the template and your project is already set up. No more wasting time making folders and thinking about how you want to organize your project. Figure shows one approach; this approach has one general folder housing all projects, then a template for the project organization. Whenever a new idea comes to mind, the template folder is copied for quick setup. Figure 8.4: Having a Template 8.2 Rmarkdown Rmarkdown is a native report compiler in R. It can be used to create many many things from .pdf, .docx, and .html files to interactive dashboards to websites. It’s impossible to cover everything in Rmarkdown in the span of a quarter, let alone a lecture. So we’ll focus on the basics. Rmarkdown is an alternative to Latex compilers like Overleaf10. That means you can do all the same fancy math and formatting as if you were in Overleaf without ever leaving R. The benefits of Rmarkdown is the idea of code integration: you can directly run code in the document. This means you can pull data in and make a graph within your file automatically. If you update some data, the graph will update whenever you recompile. You can even have code in the middle of a sentence. You can write 2+2=4, but instead of writing 4, you can write `r ` with 2+2 following the r and it’ll solve it within line. If you’re discussing descriptive statistics in the body of your work, you no longer have to worry about copying and pasting the numbers wrong. It pulls directly from the data. Today we’ll focus on the general setup of an Rmarkdown file and best practices we’ve learned for using Rmarkdown. 8.2.1 The Anatomy of an Rmarkdown File You can create an Rmarkdown file just as you would an Rscript: File-&gt;New File-&gt; R Markdown. After setting the name and type of output, you’ll be greeted with this file (or something quite similar): Figure 8.5: Basic Rmarkdown File We’re going to focus on the top part, known as the YAML. This is where you set all the parameters for your document. Most YAMLs include things such as title, subtitle, author, and general paper preferences. An important note about the YAML is that indentation matters. Parameters end with a colon and parameters that are indented are read as sub-parameters. Below is an example of the YAML for a working paper as of 2021. --- title: &#39;Indirect Financial Effects of Deplatforming&#39; subtitle: &quot;Evidence from OwenBenjaminComedy&quot; author: Danny Klinenberg^[Ph.D. student at University of California, Santa Barbara; dklinenberg@ucsb.edu. All errors, omissions, and opinions are my own.] date: &#39;Last Updated: 2021-09-10&#39; output: pdf_document: keep_tex: TRUE number_sections: yes indent: yes header-includes: - \\usepackage{amsfonts} - \\usepackage{amsthm} - \\usepackage{amsmath} - \\usepackage[english]{babel} - \\usepackage{bm} - \\usepackage{float} - \\usepackage[fontsize=12pt]{scrextend} - \\usepackage{graphicx} - \\usepackage{indentfirst} - \\usepackage[utf8]{inputenc} - \\usepackage{pdfpages} - \\usepackage[round,authoryear]{natbib} - \\usepackage{setspace}\\doublespacing - \\usepackage{subfigure} - \\theoremstyle{definition} - \\newtheorem{definition}{Definition}[section] - \\newtheorem{assumption}{Assumption} - \\newtheorem{theorem}{Theorem}[section] - \\newtheorem{corollary}{Corollary}[theorem] - \\newtheorem{lemma}[theorem]{Lemma} - \\newtheorem*{remark}{Remark} - \\newcommand{\\magenta}[1]{\\textcolor{magenta}{#1}} - \\newcommand{\\indep}{\\perp \\!\\!\\! \\perp} - \\floatplacement{figure}{H} - \\bibliographystyle{plainnat} - \\pagenumbering{gobble} - \\usepackage{eso-pic,graphicx,transparent} link-citations: yes bibliography: references.bib linkcolor: blue # magenta abstract: \\singlespacing I study things. --- Rmarkdown also uses Latex packages. You add Latex packages under header-includes:. They should start with a dash space then slash just as you would do in any other Latex compiler. Notice on line 41, there is a spot for a .bib file. You can add in-line citations by writing (_____?) and normal citations as (____?) where ____ is the reference code for the citation in your .bib file. Rmarkdown works with all normal bibliography software. Zotero is a great option because it’s free, can automatically create bibtex files, and is integrated with Rmarkdown and Microsoft Word. There are many other options for the YAML and other ways to read in the parameters (such as a header.tex file) but we can stop here for now. The end of this discussion provides resources for in-depth questions on the matter. Disclaimer: Setting up the YAML is not a one and done process most projects. It usually involves adding and removing Latex packages. 8.2.2 The Body of the Rmarkdown The actual document is comprise of words, Latex, and code chunks. Below are some helpful tricks for writing in Rmarkdown: A line beginning with one # signifies a section header. A line beginning with two ## signifies a subsection header (and so on and so forth). Dashes at the beginning of a line signify a bullet point. One star around a word a phrase will italicize it. Two will bold it. You can use all your favorite Latex commands in the body just as you would any other compiler. The main benefit to Rmarkdown is the code chunk. You can create code chunk by pressing option+command+i on a Mac. You should see the following appear within your Rmarkdown file: Figure 8.6: R code chunk A code chunk operates just like it’s own little Rscript. Code chunks in an Rmarkdown file are all thought of as being part of the same Rscript, meaning they all use the same global environment. The top part of the code chunk, {r}, has a few options we’d like to highlight. First, you can name your code chunks by adding a title after the r: ```{r example_code_chunk}. There can’t be any spaces in the code chunk. This is useful for quickly moving around your document. Figure 8.7: Quickly Moving You can also choose what each code chunk does. To use these options, you write {r, option1=, option2=,…}. Below is a short list of the common settings you may be interested in: echo: If you see the code in the document: echo=FALSE means you will not see the code. include: Whether or not the output is shown in the document. include=FALSE means the output will not be shown. eval: Whether or not the code is evaluated. The code chunks will be most useful for integrating tables, images, and graphs. For example, the last image we saw was produced using the following code: knitr::include_graphics(here::here(&quot;images&quot;, &quot;organization&quot;,&quot;rmarkdown2.png&quot;)) Some useful options for figures and graphs are: fig.cap: allows you to add a figure caption. You can make the figure reference-able by using label{}. For example, {r, fig.cap=“\\\\label{graph1} graph 1”} will allow you to reference graph 1 in the text by using \\ref{graph1} Then the graph number in the text will always match the graph number in the title. If creating a graph natively using ggplot2/other graphing technique, you will still want to use fig.cap so that the numbers automatically update correctly and you can reference the graphs in text. out.width: Allows you to change the size of the image or graph. examples would be out.width=\"50%\". fig.align: If you want your figure to be centered, left justified, or right justified. Finally, we can see that making tables becomes a painless process. The following code chunk creates a tibble to demonstrate how easy it is to make a table. random_data&lt;-tibble(y=rnorm(100,0,1), x=y+4+rnorm(100,0,1) ) Below, a simple regression is estimated. Using one line, the estimates are pushed to a publication-ready table as shown in Table .11 lm(y~x,data = random_data) %&gt;% modelsummary::modelsummary(title = &quot;\\\\label{table1}A Publication-Quality Table&quot;) Table 8.1: A Publication-Quality Table Model 1 (Intercept) -1.601 (0.210) x 0.421 (0.047) Num.Obs. 100 R2 0.445 R2 Adj. 0.440 AIC 201.8 BIC 209.6 Log.Lik. -97.902 F 78.712 With tables, you want to put the title in the table function. With graphs and images, you want to put the title in fig.cap at the top of the code chunk. 8.2.3 Childing Research papers can be tens, if not hundreds, of pages long. No matter which compiler you choose, you will run into errors that will not let your paper compile. One way to limit this issue is to child parts of your paper into a main Rmarkdown file. Childing is to Rmarkdown as source is to R scripts. It allows us to tell Rmarkdown to go read in other .Rmd files. Figure shows a general setup for a research paper using Rmarkdown. knitr::include_graphics(here::here(&quot;images&quot;, &quot;organization&quot;,&quot;rmarkdown_3.png&quot;)) Figure 8.8: Rmarkdown Research Paper File 00_klinenberg_hatepay.Rmd is the master file that brings all the other files in. This is where we put our YAML information and bring the other files in. Figure shows the beginning of the master .Rmd with the YAML collapsed form view. knitr::include_graphics(here::here(&quot;images&quot;, &quot;organization&quot;,&quot;rmarkdown4.png&quot;)) Figure 8.9: Example Master Rmarkdown File Notice lines 82 and 86. The R header has the child option chosen and nothing else. This means that the R chunk will read the file as it’s execution. If you don’t have all the files next to each other, make sure to properly specify the file path. Now, if your paper is not compiling, you do not have to go through the entire paper. You can individually load each .Rmd file and run it in isolation. Hence, you only need to debug 1-2 pages rather than 50. 8.2.4 Bibliographies You can specify where the bibliography will go by writing the following lines in a Rmarkdown file: # References {.unnumbered} ::: {#refs} ::: You can also specify when the appendix begins (meaning you have different numbering) by writing: \\appendix Rmarkdown works with all the Latex commands you already know. For example, I like to have the appendix of my papers restart page numbers at 1 and have my tables and graphs renumber starting with A1. To do that, I include the following Latex code below the YAML of my appendix.RMD file: \\appendix \\renewcommand{\\thefigure}{A\\arabic{figure}} \\setcounter{figure}{0} \\renewcommand{\\thetable}{A\\arabic{table}} \\setcounter{table}{0} \\renewcommand{\\theequation}{A\\arabic{table}} \\setcounter{equation}{0} \\setcounter{page}{1} 8.2.5 A Final Note on Rmarkdown: Visual Markdown Editor A final note is the recent addition of the visual markdown editor. This is an html interface that blends the best of the Microsoft suite and Latex. You can access this by clicking the compass in the top right corner: Figure 8.10: Enter the Editor When you enter the visual markdown editor, you should notice a few things. First, headers look like headers. Second, we now have options at the top of the toolbar. These options include bolding, italicizing and underlining. We also have the option to use the GUI interface to make bullet points and add in citations (using @). The citation feature integrates with all major citation softwares (like Zotero) and automatically creates a .bib file in the same folder as your .RMD file. There is much, much, more to learn about Rprojects, organization, and Rmarkdown. This served as an introduction to best practices, provided useful guides, and was an overview of what can be done. Here are some recommended additional readings: Rstudio Rmarkdown Cheatsheet Hadley Wickam’s Introduction to Rmarkdown Introduction to Rmarkdown by Rmarkdown Examples using Rmarkdown Yihue Xie’s newest Rmarkdown cookbook If Hadley Wickam or Yihue Xie wrote it, then it’s worth reading. This is a ten minute guide that covers the basics of folder structure in R.↩︎ Fancy math works here too: \\(\\mathbb{E}[Y|X]=X\\beta\\)↩︎ modelsummary::modelsummary is a very powerful tool. Please refer back to Homework 4 for a description of the tool and link to their introduction site.↩︎ "],["strings.html", "Chapter 9 Strings 9.1 Regular Expressions 9.2 Regular Expressions Continued 9.3 Using extract 9.4 Using separate 9.5 The gsub function 9.6 Solutions", " Chapter 9 Strings For this chapter, we will once again be importing the horror movies data set from the TidyTuesday Github. This data set contains information from IMDB on various horror movies. Some important columns we will be focusing on this week: title- the title of the movie release_date- movie release date in day-month-year format Let’s load in the data: ## install the package if you do not have it library(tidyverse) ## Load in the data horror_movies &lt;- read_csv(&quot;https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-10-22/horror_movies.csv&quot;) ## Rows: 3328 Columns: 12 ## ── Column specification ────────────────────────────────────────────────────────────────────────────── ## Delimiter: &quot;,&quot; ## chr (11): title, genres, release_date, release_country, movie_rating, movie_run_time, plot, cast, ... ## dbl (1): review_rating ## ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. Our goal this week to get comfortable with three things: Simple pattern matching with regular expressions Using the extract function Using the separate function Using all of these three things together will allow you to do powerful data wrangling techniques that are valued greatly in the workforce. 9.1 Regular Expressions Regular expressions are a fantastic tool that will allow you to match patterns in strings. To demonstrate their value, we will start off by making a vector of strings, and use str_view to show how we can match patterns using regular expressions. ## creating a vector of strings I would like to analyze x &lt;- c(&quot;Econ 145&quot;, &quot;Hello!&quot;, &quot;Best CLASS&quot;) Let’s see if we can match some basic patterns. Suppose I want to find the “o” in each component of the vector. I can do the following: ## finding all of the o&#39;s in tthe vector x using str_view str_view(string = x, pattern = &quot;o&quot;) Notice that we are matching (see the highlighted text) on the pattern “o” in every element of the vector. Note that there was no “o” to match on in the last element, “Best CLASS,” so nothing was highlighted. We can take this even further by matching on a selection of numbers. Suppose we want to match the numbers “145.” We can simply type in “145” into our pattern match. ## matching on the pattern 145 str_view(string = x, pattern = &quot;145&quot;) However, these are all trivial examples. Regular expressions allow us to match on patterns, not just simple expressions. For example, suppose we have a vector which has multiple names of courses in the economics department: ## creating a new vector with three string elements econ_classes &lt;- c(&quot;Econ 145&quot;, &quot;Econ 10A&quot;, &quot;Econ 140A&quot;) Now suppose I want to pattern match only the course numbers. I can do this by using a regular expression. \\d: the regular expression pattern that matches any digit Let’s see this in action. ## matching incorrectly on any digit str_view(string = econ_classes, pattern = &quot;\\d&quot;) The first thing you should notice when you click enter is that an error message occurs: Error: ’ is an unrecognized escape in character string starting \"\". We get this error message because \\ is an escape character in the R programming language. Therefore, we need to escape the escape character by using \\\\d to match on a number. This can often be annoyingly difficult to remember, but the the error message should guide you to remember this detail. ## matching correctly on any digit str_view(string = econ_classes, pattern = &quot;\\\\d&quot;) We managed to match on a number in every single element of the vector without actually specifying we wanted a “1.” This is absolutely incredible. It is important to note that \\\\d will only match on one number, and by default, the first number it comes across in the string going from left to right. If we want to match on more numbers, we need to add in more \\\\ds. For instance, if we wanted to match on 2 digits, our pattern argument would be equal to \\\\d\\\\d. ## matching on any two digits in each component str_view(string = econ_classes, pattern = &quot;\\\\d\\\\d&quot;) Let’s try to match on all of the course numbers. Notice that some course numbers have 2 digits, while others have 3. Let’s see what happens when we try to match on 3 digits. ## matching on exactly three digits in each component str_view(string = econ_classes, pattern = &quot;\\\\d\\\\d\\\\d&quot;) We can see that we matched on exactly 3 digits, and failed to match on the element that only contained 2 digits. However, as you may have expected, we have ways to work around this using what we call repetition patterns. You can specify the number of matches you would like to make using the following: {n}: matches exactly n amount of your pattern {n,}: matches n or more {,m}: matches at most m {n,m}: matches between n and m Hence, we can match on all the course digits by specifying how many times we would like to match the \\d patter. ##matches any digit 2 or more times str_view(string = econ_classes, pattern = &quot;\\\\d{2,}&quot;) Success! We managed to match the \\d pattern two or more times and have matched on the course digits. The way we would read this pattern is left to right: “match on any digit, and do this two times or more.” 9.1.1 Exercise 1 Find another way to match on the digits of the econ_classes vector. 9.2 Regular Expressions Continued Let’s try matching on other types of expressions. ## creating a new vector for us to match patterns on vector &lt;- c(&quot;aaabbbccc&quot;, &quot;dddAAAccc&quot;, &quot;eib iii&quot;) Here are a couple more useful patterns: [abc]: matches exactly one time on a, b, or c. If multiple appear, it matches on the one that comes first. [^abc]: matches exactly one time on anything except a, b, or c.  \\s: matches any whitespace (e.g. space, tab, newline). We will match on the beginning letter of each of these elements in our vector. ##matching on the letters a d or e str_view(string = vector, pattern = &quot;[ade]&quot;) 9.2.1 Exercise 2 Using the vector and str_view, match on the capital A and the whitespace. 9.3 Using extract We will now focus on matching regular expressions within the context of tidying data. Let’s specifically focus on the title and release_date columns. ## selecting only the title and release date columns in the horror movies data set horror_movies &lt;- horror_movies %&gt;% select(title, release_date) ## showing the head of the data set horror_movies %&gt;% head() ## # A tibble: 6 × 2 ## title release_date ## &lt;chr&gt; &lt;chr&gt; ## 1 Gut (2012) 26-Oct-12 ## 2 The Haunting of Mia Moss (2017) 13-Jan-17 ## 3 Sleepwalking (2017) 21-Oct-17 ## 4 Treasure Chest of Horrors II (2013) 23-Apr-13 ## 5 Infidus (2015) 10-Apr-15 ## 6 In Extremis (2017) 2017 Notice that it looks like each movie title is followed by a whitespace, and then a parenthesis with the movie release year inside of it. For the purposes of explaining extract, we will focus on extracting the dates from the title column. The extract function extracts information you want from a column and puts it into a column of your choice. The specific arguments it has are col, into, and regex. These correspond to the column you want to extract an expression from, the column name you are going to send your extracted expression into, and the regular expression pattern you want to extract respectively. ## extracting the year from the horror_movies %&gt;% extract(col = title, into = &quot;year&quot;, regex = &quot;(\\\\d\\\\d\\\\d\\\\d)&quot;) ## # A tibble: 3,328 × 2 ## year release_date ## &lt;chr&gt; &lt;chr&gt; ## 1 2012 26-Oct-12 ## 2 2017 13-Jan-17 ## 3 2017 21-Oct-17 ## 4 2013 23-Apr-13 ## 5 2015 10-Apr-15 ## 6 2017 2017 ## 7 2013 3-Jun-14 ## 8 2015 25-Apr-15 ## 9 2015 28-May-17 ## 10 2016 7-Oct-16 ## # … with 3,318 more rows It is important to note that we need to put parenthesis around the pattern that we want to match in our regex argument for the match to work. Observe what happens when we do not: ## code does not work because no parenthesis around the regex expression horror_movies %&gt;% extract(col = title, into = &quot;year&quot;, regex = &quot;\\\\d\\\\d\\\\d\\\\d&quot;) This is because the parenthesis define a group of patterns that you want to match. Everything inside your parenthesis is a group. For the purposes of this class, we will only be extracting 1 group, as extracting more than one group gets very complicated. ## the correct code: works because we put parenthesis around the regex expression horror_movies %&gt;% extract(col = title, into = &quot;year&quot;, regex = &quot;(\\\\d\\\\d\\\\d\\\\d)&quot;) ## # A tibble: 3,328 × 2 ## year release_date ## &lt;chr&gt; &lt;chr&gt; ## 1 2012 26-Oct-12 ## 2 2017 13-Jan-17 ## 3 2017 21-Oct-17 ## 4 2013 23-Apr-13 ## 5 2015 10-Apr-15 ## 6 2017 2017 ## 7 2013 3-Jun-14 ## 8 2015 25-Apr-15 ## 9 2015 28-May-17 ## 10 2016 7-Oct-16 ## # … with 3,318 more rows Notice when we ran the previous correct code, our title column disappeared. This is because by default, the extract function deletes the original column. To avoid this, we can set the remove argument to FALSE. ## the correct code: works because we put parenthesis around the regex expression horror_movies %&gt;% extract(col = title, into = &quot;year&quot;, regex = &quot;(\\\\d\\\\d\\\\d\\\\d)&quot;, remove = F) ## # A tibble: 3,328 × 3 ## title year release_date ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Gut (2012) 2012 26-Oct-12 ## 2 The Haunting of Mia Moss (2017) 2017 13-Jan-17 ## 3 Sleepwalking (2017) 2017 21-Oct-17 ## 4 Treasure Chest of Horrors II (2013) 2013 23-Apr-13 ## 5 Infidus (2015) 2015 10-Apr-15 ## 6 In Extremis (2017) 2017 2017 ## 7 Ghostlight (2013) 2013 3-Jun-14 ## 8 Parasyte: Part 2 (2015) 2015 25-Apr-15 ## 9 Stranger in the House (2015) 2015 28-May-17 ## 10 Tutak Tutak Tutiya (2016) 2016 7-Oct-16 ## # … with 3,318 more rows 9.4 Using separate The separate function will split a column into multiple columns based on a regular expression. You can think of separate as a way to split with a more complicated delimiter (a delimiter is a character that separates values). For starters, we will separate once again look at the title column in the horror movies data. Recall that the title column is organized as the movie title, followed by a blank space and then the year of release in parenthesis. We will take advantage of this unique organization and separate our title column into two columns: title which will have the title of the movie, and year which will have the release year. While this will take multiple steps to get into a perfectly cleaned data set, we can utilize our piping procedures to make it relatively straightforward. First, let’s separate the column based on the first parenthesis that we see. ## separating on the first parenthesis in the title column horror_movies %&gt;% separate(col = title, into = c(&quot;title&quot;,&quot;year&quot;), sep = &quot;\\\\(&quot;) ## Warning: Expected 2 pieces. Additional pieces discarded in 7 rows [691, 928, 1289, 2086, 2130, 2545, ## 3262]. ## Warning: Expected 2 pieces. Missing pieces filled with `NA` in 1 rows [932]. ## # A tibble: 3,328 × 3 ## title year release_date ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 &quot;Gut &quot; 2012) 26-Oct-12 ## 2 &quot;The Haunting of Mia Moss &quot; 2017) 13-Jan-17 ## 3 &quot;Sleepwalking &quot; 2017) 21-Oct-17 ## 4 &quot;Treasure Chest of Horrors II &quot; 2013) 23-Apr-13 ## 5 &quot;Infidus &quot; 2015) 10-Apr-15 ## 6 &quot;In Extremis &quot; 2017) 2017 ## 7 &quot;Ghostlight &quot; 2013) 3-Jun-14 ## 8 &quot;Parasyte: Part 2 &quot; 2015) 25-Apr-15 ## 9 &quot;Stranger in the House &quot; 2015) 28-May-17 ## 10 &quot;Tutak Tutak Tutiya &quot; 2016) 7-Oct-16 ## # … with 3,318 more rows Notice how we managed to separate the two columns, but there are now more problems we need to deal with: What do the warning messages mean? We need to get rid of the extra parenthesis in the year column. We need (well, we don’t NEED) to get rid of the blank space at the end of the title column. First and foremost, we will take a second to review what a warning message is. Warning message: These are messages that tell you that your R code was able to execute, but in the process, R decided to do something that you did not tell it to. It is extremely important that you Google warning messages, as your data could be manipulated by R in ways you really did not want. Let’s look at our two warning messages in depth: Warning messages: 1: Expected 2 pieces. Additional pieces discarded in 7 rows [691, 928, 1289, 2086, 2130, 2545, 3262]. 2: Expected 2 pieces. Missing pieces filled with `NA` in 1 rows [932] The first warning message is telling us that R expected 2 pieces, and then discarded additional pieces in 7 rows. While this does not make much sense at first sight, it gives us the rows which it performed this process. The best practice is to investigate these rows to get a better idea of what is happening. ## investigating a couple of the rows that caused the warning message horror_movies$title[691] ## [1] &quot;ErOddity(s) 2 (2015)&quot; horror_movies$title[928] ## [1] &quot;Truth or Double Dare (TODD) (2017)&quot; horror_movies$title[1289] ## [1] &quot;Hi-8 (Horror Independent 8) (2013)&quot; By now you should see a problem: each of these warning rows have a parenthesis in the title name! This means that R is separating based on our parenthesis, but since there are multiple parenthesis, it is separating multiple times. Therefore, it is discarding the extra separated piece in each row. Generally, you want to make sure R is not throwing away any important information. You could check this yourself by saving this as a new tibble, and investigating the rows. Hence, we will create a new tibble for demonstration purposes. ## performing the same task but saving it in a new tibble investigate_horror_movies &lt;- horror_movies %&gt;% separate(col = title, into = c(&quot;title&quot;,&quot;year&quot;), sep = &quot;\\\\(&quot;) ## Warning: Expected 2 pieces. Additional pieces discarded in 7 rows [691, 928, 1289, 2086, 2130, 2545, ## 3262]. ## Warning: Expected 2 pieces. Missing pieces filled with `NA` in 1 rows [932]. ## investigating the 691th row of the saved tibble investigate_horror_movies[691,] ## # A tibble: 1 × 3 ## title year release_date ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 ErOddity &quot;s) 2 &quot; 24-Nov-15 ## investigating the 928th row of the saved tibble investigate_horror_movies[928,] ## # A tibble: 1 × 3 ## title year release_date ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 &quot;Truth or Double Dare &quot; &quot;TODD) &quot; 30-Oct-17 Clearly, this isn’t giving us our desired result for the 7 rows that were causing this issue. While we will ignore this for the purpose of this exercise, you want to be very aware of what is happening to your data. Next, let’s investigate the second warning message: Expected 2 pieces. Missing pieces filled with NA in 1 rows [932]. It seems as though R filled a missing piece of information in our row 932. Let’s take a closer look: ## investigating what happened in row 932 ## checking the title column first in our original data horror_movies$title[932] ## [1] &quot;American Exorcist&quot; ## look what happened to our data in row 932 investigate_horror_movies[932,] ## # A tibble: 1 × 3 ## title year release_date ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 American Exorcist &lt;NA&gt; 2017 Clearly we missed something: not all the movies have the same format of MOVIE TITLE (YEAR). It appears that the movie “American Exorcist” in row 932 did not have a date attached to it. Therefore, when we tried to separate by parenthesis, R was unable to perform this task and replaced the value with NA. In our case, this wouldn’t have affected our analysis since there was no date attached to it, but we would want to find another way to extract the date from another column. However, as before, we will ignore this warning message since fixing it will take a lot of time in effort. It is important to realize that you must read and investigate warning messages since R constantly performs operations on your data that may not be exactly what you intend. Moving on, let’s start solving our second task: getting rid of the extra parenthesis in the year column. Recall, we can actually use the extract function here to remove the final parenthesis. We can do this all in one step using a pipe. ## separating on the first parenthesis in the title column and then extracting the four numbers for date horror_movies %&gt;% separate(col = title, into = c(&quot;title&quot;,&quot;year&quot;), sep = &quot;\\\\(&quot;) %&gt;% extract(col = year, into = &quot;year&quot;, regex = &quot;(\\\\d\\\\d\\\\d\\\\d)&quot;) ## Warning: Expected 2 pieces. Additional pieces discarded in 7 rows [691, 928, 1289, 2086, 2130, 2545, ## 3262]. ## Warning: Expected 2 pieces. Missing pieces filled with `NA` in 1 rows [932]. ## # A tibble: 3,328 × 3 ## title year release_date ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 &quot;Gut &quot; 2012 26-Oct-12 ## 2 &quot;The Haunting of Mia Moss &quot; 2017 13-Jan-17 ## 3 &quot;Sleepwalking &quot; 2017 21-Oct-17 ## 4 &quot;Treasure Chest of Horrors II &quot; 2013 23-Apr-13 ## 5 &quot;Infidus &quot; 2015 10-Apr-15 ## 6 &quot;In Extremis &quot; 2017 2017 ## 7 &quot;Ghostlight &quot; 2013 3-Jun-14 ## 8 &quot;Parasyte: Part 2 &quot; 2015 25-Apr-15 ## 9 &quot;Stranger in the House &quot; 2015 28-May-17 ## 10 &quot;Tutak Tutak Tutiya &quot; 2016 7-Oct-16 ## # … with 3,318 more rows Finally, let’s satisfy (2) and get rid of the whitespace that is at the end of our title column. Luckily, the stringr package has a pre-programmed function called stringr::str_trim that will trim the whitespace off the end of our column. Now we can perform the entire cleaning of the title column in one piping procedure: ## separating on the first parenthesis in the title column and then extracting the four numbers for date ## and then removing the whitespace that is left over horror_movies %&gt;% separate(col = title, into = c(&quot;title&quot;,&quot;year&quot;), sep = &quot;\\\\(&quot;) %&gt;% extract(col = year, into = &quot;year&quot;, regex = &quot;(\\\\d\\\\d\\\\d\\\\d)&quot;) %&gt;% mutate(title = str_trim(title)) ## Warning: Expected 2 pieces. Additional pieces discarded in 7 rows [691, 928, 1289, 2086, 2130, 2545, ## 3262]. ## Warning: Expected 2 pieces. Missing pieces filled with `NA` in 1 rows [932]. ## # A tibble: 3,328 × 3 ## title year release_date ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Gut 2012 26-Oct-12 ## 2 The Haunting of Mia Moss 2017 13-Jan-17 ## 3 Sleepwalking 2017 21-Oct-17 ## 4 Treasure Chest of Horrors II 2013 23-Apr-13 ## 5 Infidus 2015 10-Apr-15 ## 6 In Extremis 2017 2017 ## 7 Ghostlight 2013 3-Jun-14 ## 8 Parasyte: Part 2 2015 25-Apr-15 ## 9 Stranger in the House 2015 28-May-17 ## 10 Tutak Tutak Tutiya 2016 7-Oct-16 ## # … with 3,318 more rows 9.5 The gsub function Many times, we want to simply replace simple patterns in columns of data sets. The stringr::str_replace function is a simple way to take expressions within variables and substitute them with a different result. Let’s create a vector of values to demonstrate. ## creating a vector to demonstrate gsub money &lt;- c(&quot;$100&quot;, &quot;$150&quot;, &quot;$200&quot;) A common use of gsub is to get rid of dollar signs in columns that have monetary values. Omitting the dollar sign is essential if you want to perform any type of summary statistic. The three arguments in the stringr::str_replace function that we are concerned with are the pattern, replacement, and string arguments. The pattern argument is the regular expression we want to find in our vector, and the replacement argument is what we would like to replace the regular expression with. The string argument is the vector you want to perform the stringr::str_replace function on. ## the gsub function attempting (but unsuccessfully) trying to replace the $ with nothing str_replace(money, &quot;\\\\$&quot;, &quot;&quot;) ## [1] &quot;100&quot; &quot;150&quot; &quot;200&quot; Notice that we had to once again, use the escape characters since the dollar sign is a special characer. ## successfully replacing the $ with nothing str_replace(money, &quot;\\\\$&quot;, &quot;&quot;) ## [1] &quot;100&quot; &quot;150&quot; &quot;200&quot; ## saving this new result money &lt;- str_replace(money, &quot;\\\\$&quot;, &quot;&quot;) 9.5.1 Exercise 3 ## use the following vector for the exercise exercise &lt;- c(&quot;100%&quot;, &quot;94%&quot;, &quot;87%&quot;) Using stringr::str_replace, replace the percent signs in the exercise vector with nothing. Then, convert the exercise vector to a double using as.double, and find the variance. 9.6 Solutions Exercise 1: str_view(string = econ_classes, pattern = \"\\\\d{1,3}\") Exercise 2: str_view(string = vector, pattern = \"[A\\\\s]\") Exercise 3: var_exercise &lt;- var(as.double(gsub(\"\\\\%\", \"\", exercise))). "],["an-introduction-to-web-scraping-in-r.html", "Chapter 10 An Introduction to Web Scraping in R 10.1 What is Web Scraping? 10.2 Can I Scrape From This Site? 10.3 Pulling from an API: Hechinger’s Report 10.4 Web Scraping: UCSB Economics Contact Information", " Chapter 10 An Introduction to Web Scraping in R Note: This document is meant for internal uses within UCSB. Proper citations have not been included in this draft. Please use this document as an individual learning tool, not for official citation or distribution. # Packages for lesson: library(pacman) pacman::p_load( &quot;jsonlite&quot;,# read in json formats &quot;formatR&quot;, # makes code wrap in an Rmarkdown file &quot;glue&quot;, # tidyverse concatenate text &quot;magrittr&quot;,# fancy pipe &quot;polite&quot;,# make sure website is okay to scrape &quot;rvest&quot;,# Grabbing, formatting, and cleaning html code &quot;tidyverse&quot;# Thanks Hadley Wickham! ) In addition, this lesson will require using Google Chrome and the selector gadget extension. This link is to Google Chrome selector gadget extension. Please add the selector gadget to Google Chrome now. 10.1 What is Web Scraping? Web scraping is a general term that tends to relate to pulling data from some web pages and converting it into a usable, or tidy, form. Colloquially, we tend to refer to two different methods when we say “web scraping.” The first is actually API pulling. This is accessing a website’s underlying data organization and directly using that. In this case, the data is in a clean and usable form - we just have to pull it in. The second is actual web scraping. This process involves pulling html code from a website, cleaning and ultimately creating a tidy dataset. If given the choice, always API pull. API pulling is easier, there is less chance for user error, and ultimately faster. In this lesson, we’ll go through an example of pulling from an API and web scraping. We’ll be pulling from the Hechinger Report of UC - Santa Barbara as an example of an API pull and scraping the UCSB Economics directory. For the purposes of this lesson, we’ll use the term scrape to describe both pulling and scraping from a website (as is colloquial). 10.2 Can I Scrape From This Site? Before scraping a website, we must ensure the site is scrape-able. This means that the owners of the site are okay with individuals taking information from their site. Reasons they may not be okay with this is proprietary information or crashing the site. Constantly accessing sites with a scraper, or code meant to extract data from a website, can lead to performance issues and ultimately crashing a site. To see if we’re allowed to scrape from a site, we’ll use the package polite. There is a useful repository here. polite ’s main function is bow.12 This command is politely asking if we have permission to access a website. The general framework of the command is as follows: bow( url = &quot;https://tuitiontracker.org/fitness/data/school-data/&quot;, user_agent = &quot;Danny Klinenberg &lt;dklinenberg@ucsb.edu&gt;&quot; ) The command url is our target site we wish to scrape. user_agent is our name and email. While the user_agent is not necessary, it’s extra polite to the hosts of the website. If we’re allowed to scrape from a website, the result will look like this: bow( url = &quot;https://tuitiontracker.org/fitness/data/school-data/&quot;, user_agent = &quot;Danny Klinenberg &lt;dklinenberg@ucsb.edu&gt;&quot; ) ## &lt;polite session&gt; https://tuitiontracker.org/fitness/data/school-data/ ## User-agent: Danny Klinenberg &lt;dklinenberg@ucsb.edu&gt; ## robots.txt: 1 rules are defined for 1 bots ## Crawl delay: 5 sec ## The path is scrapable for this user-agent Let’s walk through the lines of output. Line one is the website we’re asking to pull from. Line 2 is us identifying ourselves. Line 3 are the rules of pulling from their website.13 Line 4 is the crawl delay. This is how much time the hosts requests between pulling from the website. Hosts asks for crawl delays to avoid overloading the site leading to a crash. If we are to pull alot of time from a website, we may get blocked for not following this rule. We’ll talk about how to add time between pulls in the UCSB Economics example.14 If we are not allowed to scrape, the results will look like this: bow( url = &quot;https://collegecrisis.shinyapps.io/dashboard/&quot;, user_agent = &quot;Danny Klinenberg &lt;dklinenberg@ucsb.edu&gt;&quot; ) ## &lt;polite session&gt; https://collegecrisis.shinyapps.io/dashboard/ ## User-agent: Danny Klinenberg &lt;dklinenberg@ucsb.edu&gt; ## robots.txt: 1 rules are defined for 1 bots ## Crawl delay: 5 sec ## The path is not scrapable for this user-agent The legal, ethical, and moral issues of scraping web pages are a popular topic right now. For example, are we really not allowed to scrape a site that asks us not to scrape? Can the authors really do anything to us? If we find ourselves in need of information on a site we’re not given permission to scrape, the best next step is to contact the authors of the site. It’s safest and you don’t want to find yourself in a legal battle over some data. It’s (probably) not worth it? 10.3 Pulling from an API: Hechinger’s Report The Hechinger’s Report created a college financial fitness report for most universities based off of the book College Stress Test. The report shows the financial health of a school along four metrics: enrollment, retention, average tuition, and appropriations. Let’s take a look at how UCSB did. The url for UCSB’s financial health report is https://tuitiontracker.org/fitness/school.html?unitid=110705. The page looks like this (I added the green circle): UCSB Report We’re interested in getting the scores for the four stress variables. Bars filled in with red signify levels of stress. More red bars means more stress. In UCSB’s case, they have no stress (yay!). However, this isn’t in a format to pull directly into a tibble. Analysis is not possible…yet. If we’re using Google chrome, we can dive into the website source code by right clicking on the page and choosing inspect: Opening Inspector After opening inspector, we immediately see half our screen is engulfed with funky code. This is html code, the bones of the website: HTML Code As a fun tangent, to see which part of the webpage corresponds to which part of the html code we can press cmnd+shft+c on a Mac. To exit out of this mode, we can press esc. Most of the time, websites pull data from their own API. To see if this is the case here, we can go to the network tab: Press the Network tab: Green Arrow Now that we have the network tab open, the key is to refresh the page. That way, we’ll be able to see all the files this web page pulls in. And with a bit of luck, we’ll find the file that houses all the data we need. Network Tab After Refreshing the Page Most of these files are well beyond my understanding of website infrastructure. However, I have figured out that sites tend to store their underlying data as a .csv , .json or .ndjson . A .json is a more flexible .csv. Think of a .json as a .csv only instead of each cell housing a single data, it can house another .csv. In R terms, a .json is like a list. A .ndjson is like a .json only each row is it’s very own .json.15 Once we find a .json, we can right click it and copy the file path. Here, I’m opening 110705.json: Opening .json Attempt 1 Once we copy the link address, we can paste it in a new tab in Chrome and see where it takes us: Opening the .json Link We grabbed the right one. Nice! We can then import the file directly into R: ucsb &lt;- jsonlite::read_json(&quot;https://tuitiontracker.org/fitness/data/school-data/110705.json&quot;) We can then grab things like the name, IPEDS UNITID, and the stress scores (stored in flags): ucsb$institution ## [1] &quot;University of California-Santa Barbara&quot; ucsb$unitid ## [1] &quot;110705&quot; ucsb$flags ## [1] &quot;[0,0,0,0]&quot; Now, having data on one school is cool, but what if we had data on all the schools. For example, suppose we were interested in finding the stress scores for the following schools: schools &lt;- tibble(schools = c(&quot;UCSB&quot;, &quot;Cal Poly SLO&quot;, &quot;Sac State&quot;), unitid = c(110705, 110422, 110617)) print(schools) ## # A tibble: 3 × 2 ## schools unitid ## &lt;chr&gt; &lt;dbl&gt; ## 1 UCSB 110705 ## 2 Cal Poly SLO 110422 ## 3 Sac State 110617 Let’s look at the url for UCSB: \"https://tuitiontracker.org/fitness/data/school-data/110705.json%22. Now, let’s look at the url for Sac State: \"https://tuitiontracker.org/fitness/data/school-data/110617.json\" Notice that the urls are identical except of the numbers before .json. Usually, websites have some sort of method for their url names. In this case, the data url is “https://tuitiontracker.org/fitness/data/school-data/UNITID.json,” where UNITID is the IPEDS UNITID. We can pull those off of IPEDS easy, so all we’d need to do to get the stress scores is loop through the UNITIDS! Let’s do that here: num_schools &lt;- 3 # interested in 3 schools dat &lt;- tibble(school = rep(NA, num_schools), unitid = rep(NA, num_schools), enrollment_stress = rep(NA, num_schools), retention_stress = rep(NA, num_schools), avg_tui_stress = rep(NA, num_schools), approp_stress = rep(NA, num_schools)) for (i in 1:num_schools) { # remember, we&#39;re polite, so we honor the 5 second # rule Sys.sleep(5) school &lt;- jsonlite::read_json(paste0(&quot;https://tuitiontracker.org/fitness/data/school-data/&quot;, schools$unitid[i], &quot;.json&quot;)) # clean the flag scores and unlist scores &lt;- school$flags %&gt;% str_replace_all(&quot;\\\\[|\\\\]&quot;, &quot;&quot;) %&gt;% str_split(&quot;,&quot;) %&gt;% str_split(&quot;,&quot;) %&gt;% unlist() # save the stuff dat$school[i] &lt;- school$institution dat$unitid[i] &lt;- school$unitid dat$enrollment_stress[i] &lt;- scores[1] dat$retention_stress[i] &lt;- scores[2] dat$avg_tui_stress[i] &lt;- scores[3] dat$approp_stress[i] &lt;- scores[4] } ## Warning in stri_split_regex(string, pattern, n = n, simplify = simplify, : argument is not an atomic ## vector; coercing ## Warning in stri_split_regex(string, pattern, n = n, simplify = simplify, : argument is not an atomic ## vector; coercing ## Warning in stri_split_regex(string, pattern, n = n, simplify = simplify, : argument is not an atomic ## vector; coercing dat ## # A tibble: 3 × 6 ## school unitid enrollment_stre… retention_stress avg_tui_stress approp_stress ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 University of California-Sant… 110705 &quot;c(\\&quot;0\\&quot;&quot; &quot; \\&quot;0\\&quot;&quot; &quot; \\&quot;0\\&quot;&quot; &quot; \\&quot;0\\&quot;)&quot; ## 2 California Polytechnic State … 110422 &quot;c(\\&quot;0\\&quot;&quot; &quot; \\&quot;0\\&quot;&quot; &quot; \\&quot;0\\&quot;&quot; &quot; \\&quot;0\\&quot;)&quot; ## 3 California State University-S… 110617 &quot;c(\\&quot;0\\&quot;&quot; &quot; \\&quot;0\\&quot;&quot; &quot; \\&quot;3\\&quot;&quot; &quot; \\&quot;0\\&quot;)&quot; To recap, we performed the following steps: Identified a website we wanted to scrape Used the polite package to see if we were allowed to scrape the site We used Google Chrome’s inspector function to look at the source code We went to network and refreshed the page to try and find the source of the data We guessed which file had the data. When we found it, we imported the data into R using the url. 10.4 Web Scraping: UCSB Economics Contact Information Pulling from an API is always the preferable approach. However, sometimes we can’t pull from an API because it isn’t publicly available. In that case, we have to scrape the html directly from the website. Hadley Wickham, tidyverse creator, developed the rvest to assist in web scraping in R. There are many blog posts describing how to use rvest, but I’d recommend starting with the official github page. This example will require using SelectorGadget. In my experience, scraping a web page has a very similar code structure: read_html(&quot;website_name&quot;) %&gt;% # read in html html_nodes(&quot;found with selector gadget&quot;) %&gt;% #find right node html_text() %&gt;% # convert to text as_tibble() # tidy it up The first line reads in the website, the second line tells R which part of the html code to find, the third line converts it into readable text, and the fourth line puts it in a tibble. Each line will be discussed in detail through the example. We’re going to pull data from the UCSB Economics Directory.16 Our goal is to create a tibble with an individual’s name. To start, let’s take a look at the website: UCSB Economics Directory Screenshot First, let’s make sure we have permission to scrape this site: bow(url=&quot;https://econ.ucsb.edu/people&quot;, user_agent = &quot;Danny Klinenberg &lt;dklinenberg@ucsb.edu&gt;&quot;) ## &lt;polite session&gt; https://econ.ucsb.edu/people ## User-agent: Danny Klinenberg &lt;dklinenberg@ucsb.edu&gt; ## robots.txt: 42 rules are defined for 1 bots ## Crawl delay: 5 sec ## The path is scrapable for this user-agent Good news, we have permission! Now, we’re going to read in the raw html code into R: website &lt;- read_html(&quot;https://econ.ucsb.edu/people&quot;) Take a moment to open the website object in R. You should notice that it’s incomprehensible. It’s some list titled &lt;html&gt; then it has something called &lt;body&gt; and some other stuff. Thanks to Hadley, we don’t need to parse through the raw html code to try and extract our desired information. Instead, we can use the rvest package. Through rvest, we can tell R which specific node17 of the html code we want and it’ll grab the information for that node. To know which node we want, we use the selector gadget in chrome. To open selector gadget, click the puzzle piece in the top right hand corner, then the magnifying glass: Opening Selector Gadget Once open, you’ll notice a bunch of random orange squares appearing when you move your mouse. If you click on/next to a specific element, the square will turn green. At the bottom of the screen, you’ll notice a string in a box: Selector Gadget after clicking next to Alexander Abajian The green is the html node we asked for while the yellow boxes are the “guesses” selector gadget is making on information you want. If you click a yellow box (e.g. next to Camilo Abbate Granada’s name), the box will turn red and the string at the bottom (green circle) will change. If you click Camilo’s name again, it will turn yellow again. Once we have the information we want highlighted, we copy the string in the green circle and paste it into html_nodes: website %&gt;% html_nodes(&quot;h3&quot;) %&gt;% .[1:5] # only displaying first 5 ## {xml_nodeset (5)} ## [1] &lt;h3&gt;&lt;a href=&quot;/people/students/alexander-abajian&quot; hreflang=&quot;en&quot;&gt;Alexander Abajian&lt;/a&gt;&lt;/h3&gt; ## [2] &lt;h3&gt;&lt;a href=&quot;/people/students/camilo-abbate-granada&quot; hreflang=&quot;en&quot;&gt;Camilo Abbate Granada&lt;/a&gt;&lt;/h3&gt; ## [3] &lt;h3&gt;&lt;a href=&quot;/people/students/hazem-alshaikhmubarak&quot; hreflang=&quot;en&quot;&gt;Hazem Alshaikhmubarak&lt;/a&gt;&lt;/h3&gt; ## [4] &lt;h3&gt;&lt;a href=&quot;/people/students/roberto-amaral-de-castro-prado-santos&quot; hreflang=&quot;en&quot;&gt;Roberto Amar ... ## [5] &lt;h3&gt;&lt;a href=&quot;/people/lecturers/bob-anderson&quot; hreflang=&quot;en&quot;&gt;Bob Anderson&lt;/a&gt;&lt;/h3&gt; We could parse the information we want ourselves, or we could use the html_text command: website %&gt;% html_nodes(&quot;h3&quot;) %&gt;% html_text(trim=T) %&gt;% # removes hanging white space at the beginning and end as_tibble() %&gt;% slice(1:5) # only displaying first 5 ## # A tibble: 5 × 1 ## value ## &lt;chr&gt; ## 1 Alexander Abajian ## 2 Camilo Abbate Granada ## 3 Hazem Alshaikhmubarak ## 4 Roberto Amaral de Castro Prado Santos ## 5 Bob Anderson To extend this, you can add html endpoints to html_nodes using inspector gadget. Then it’s a matter of parsing the data using our data wrangling tools! The whole package is inspired by British etiquette at a tea party. They really get into it on their blogpost.↩︎ I’m not sure how to access the rules and it hasn’t come up as an issue yet so hopefully it’s fine?↩︎ For those extra excited, we’ll be using Sys.Sleep at the beginning of each loop.↩︎ You’ll have to work with .ndjson files if you want to use the Parler data dump.↩︎ If the UCSB page has undergone major revisions, you can replace the url with an archived verison of the page: https://web.archive.org/web/20210722193128/https://econ.ucsb.edu/people↩︎ html lingo for element.↩︎ "],["programming.html", "Chapter 11 Programming 11.1 Functions 11.2 For-loops 11.3 If-else 11.4 Selected Solutions", " Chapter 11 Programming For this chapter, you will not be working with a particular data set. Instead, we will be focusing on basic programming practices using vectors and functions that we create ourselves. 11.1 Functions Functions are an extremely useful tool. As you will see in your homework, they can provide the benefit of nearly zero marginal cost with some upfront fixed costs. Our world is a repetitive place, and minimizing the amount of time you need to repeatedly do a task should be minimized. This is where functions will help us. To motivate this, let’s consider finding the area of a circle. The formula for area of a circle is shown in equation (1). \\[\\begin{equation} Area = \\pi \\times r^2 \\end{equation}\\] Suppose you wanted to find the area of two circles with radii of 3 and 5 respectively. Although a simple task, it would be painfully slow to type the numbers over and over into R and return an answer. Instead, let’s create a function that will compute this area for us. Functions in R come with the following syntax: ## function_name is the function&#39;s name that we create ## function() tells R that we are creating a function ## x is an input for the function function_name &lt;- function(x) { ## body to add. return() } There are a few things to note here: function_name is the name we have given our function. function tells R that we are creating a function. x is an input to the function return specifies what value should return (i.e. output). Recall that functions are like a machine: they require an input, and using that input, create an output. In this example, our input is x, but we have not specified an output. To provide a concrete example, we will now create a function called area_of_circle that will do the following: Take the radius of the circle as an input. Calculate the area of the circle. Return the area of the circle as an output. Observe: ## This function returns the area of a circle This ## function takes 1 input: the radius of the circle area_of_circle &lt;- function(radius) { area &lt;- radius^2 * pi return(area) } Notice how the function was constructed. First, we write comments that explain what the function does, and what its inputs are. This is a best practice so you can understand what your function does in the future. Next, we write the actual code of the function. Now that we have created the function, we can input any value for the radius we like and the function will return the area of the circle. ## Calculating area of circle with radius 3 area_of_circle(radius = 3) ## [1] 28.27433 ## Calculating area of circle with radius 5 area_of_circle(radius = 5) ## [1] 78.53982 We could also modify the return statement so that it gives us a little more information: ## This function takes 1 input: the radius of the ## circle It returns the area of the circle area_of_circle &lt;- function(radius) { area &lt;- radius^2 * pi return(print(paste(&quot;The area of the circle with radius&quot;, radius, &quot;is&quot;, area))) } ## Calculating area of circle with radius 3 area_of_circle(radius = 3) ## [1] &quot;The area of the circle with radius 3 is 28.2743338823081&quot; ## Calculating area of circle with radius 5 area_of_circle(radius = 5) ## [1] &quot;The area of the circle with radius 5 is 78.5398163397448&quot; 11.1.1 Exercise Create a function called miles2kilo_feet2meter which takes two inputs, miles and feet. The function then converts the miles input to kilometers, and the feet input to meters. The function then prints out the results, specifying each. 11.2 For-loops For-loops are a common type of loop that, like functions, take care of repetitive tasks. For-loops work by iterating through a specified task for a certain amount of times. Once that specified amount of times has been met, the for-loop stops. The general syntax for for-loops is as follows: ## for-loop syntax for (i in {some specified range}){ ##do something } One thing to note about for loops is the indexing variable i. This variable i will be set equal to your indexed value at each stage in the loop. We will illustrate this by example: ## a for-loop that loops through values 1 to 5 and ## prints the index at each stage for (i in 1:5) { print(i) } ## [1] 1 ## [1] 2 ## [1] 3 ## [1] 4 ## [1] 5 The for-loop here is telling R to print the value of i at each iteration. The for-loop lasts for 5 iterations as we specified. Notice that at each iteration, the i variable is updated to match the index it is looping through. For instance, i is assigned to 1 the first time through the loop, 2 the second time through the loop, 3 the third time etc. However, numbers are not the only thing we can loop through. We can actually loop through all of the elements in a vector. ## a vector for demonstration favorite_econ = c(&quot;Econ 140A&quot;, &quot;Econ 241&quot;, &quot;Econ 290&quot;, &quot;Econ 145&quot;) ## looping through each element of the favorite_econ ## vector for (i in favorite_econ) { print(i) } ## [1] &quot;Econ 140A&quot; ## [1] &quot;Econ 241&quot; ## [1] &quot;Econ 290&quot; ## [1] &quot;Econ 145&quot; Here, i is still our index, but instead, we are telling the loop to go through each element in the vector one-by-one. Hence, on the first time through the loop, the index i is assigned to “Econ 140A,” while i is assigned to “Econ 241” the second time through etc. Now let’s try a loop that is most frequently used: looping through a entire vector’s indices. ## looping through a vectors indices for (i in 1:length(favorite_econ)) { print(favorite_econ[i]) } ## [1] &quot;Econ 140A&quot; ## [1] &quot;Econ 241&quot; ## [1] &quot;Econ 290&quot; ## [1] &quot;Econ 145&quot; There is quite a lot to unpack here: The for-loop is assigning the index i variable to the number 1 the first time through, 2 the second time through, and continuing on until it reaches the the number 4 which is equal to the length of the favorite_econ vector. At each iteration of the loop, we print the value of favorite_econ at each index. For instance, i is equal to 1 the first time through the loop, so the first thing that will be printed is favorite_econ[1] which is equivalent to “Econ 140A” (check yourself!). Another thing to note is that you do not need to have i as the name of the index. In fact, when you combine multiple for-loops together, it can be helpful to change your index. Observe: ## econ_class is the index in this case for (econ_class in favorite_econ) { print(econ_class) } ## [1] &quot;Econ 140A&quot; ## [1] &quot;Econ 241&quot; ## [1] &quot;Econ 290&quot; ## [1] &quot;Econ 145&quot; As a final example, we will modify our area_of_circle function. The function will take a range of numbers as an input, and collect the area of the circle using each of these numbers as a radii. In particular, our function will take two inputs: minradius and maxradius. The minradius argument will be the smallest radius we would like to calculate the area of the circle with, while the maxradius argument will be the largest. The function will calculate the area of the circle for every integer between minradius and maxradius and return a vector with all of the areas. ## modifying the function to collect the area of ## circles with radii of integers 1 through 10 area_of_circle &lt;- function(minradius, maxradius) { area_vector &lt;- rep(NA, 10) #creating an empty vector of 10 NAs for (i in minradius:maxradius) { area_vector[i] = pi * i^2 #calculating the area } return(area_vector) #returning the vector of areas } area_of_circle(minradius = 1, maxradius = 10) ## [1] 3.141593 12.566371 28.274334 50.265482 78.539816 113.097336 153.938040 201.061930 ## [9] 254.469005 314.159265 As an aside, it is important to note that we can also loop through columns in a data frame. This is a task you will likely need to do at some point in your data wrangling career, and there isn’t much great help for this online. library(tidyverse) ## loading in the mtcars data set from R cars &lt;- mtcars ## selecting only three columns for demonstration cars &lt;- cars %&gt;% select(mpg, hp, cyl) ## looping through the columns and printing them out for (i in names(cars)) { print(cars[i]) } ## mpg ## Mazda RX4 21.0 ## Mazda RX4 Wag 21.0 ## Datsun 710 22.8 ## Hornet 4 Drive 21.4 ## Hornet Sportabout 18.7 ## Valiant 18.1 ## Duster 360 14.3 ## Merc 240D 24.4 ## Merc 230 22.8 ## Merc 280 19.2 ## Merc 280C 17.8 ## Merc 450SE 16.4 ## Merc 450SL 17.3 ## Merc 450SLC 15.2 ## Cadillac Fleetwood 10.4 ## Lincoln Continental 10.4 ## Chrysler Imperial 14.7 ## Fiat 128 32.4 ## Honda Civic 30.4 ## Toyota Corolla 33.9 ## Toyota Corona 21.5 ## Dodge Challenger 15.5 ## AMC Javelin 15.2 ## Camaro Z28 13.3 ## Pontiac Firebird 19.2 ## Fiat X1-9 27.3 ## Porsche 914-2 26.0 ## Lotus Europa 30.4 ## Ford Pantera L 15.8 ## Ferrari Dino 19.7 ## Maserati Bora 15.0 ## Volvo 142E 21.4 ## hp ## Mazda RX4 110 ## Mazda RX4 Wag 110 ## Datsun 710 93 ## Hornet 4 Drive 110 ## Hornet Sportabout 175 ## Valiant 105 ## Duster 360 245 ## Merc 240D 62 ## Merc 230 95 ## Merc 280 123 ## Merc 280C 123 ## Merc 450SE 180 ## Merc 450SL 180 ## Merc 450SLC 180 ## Cadillac Fleetwood 205 ## Lincoln Continental 215 ## Chrysler Imperial 230 ## Fiat 128 66 ## Honda Civic 52 ## Toyota Corolla 65 ## Toyota Corona 97 ## Dodge Challenger 150 ## AMC Javelin 150 ## Camaro Z28 245 ## Pontiac Firebird 175 ## Fiat X1-9 66 ## Porsche 914-2 91 ## Lotus Europa 113 ## Ford Pantera L 264 ## Ferrari Dino 175 ## Maserati Bora 335 ## Volvo 142E 109 ## cyl ## Mazda RX4 6 ## Mazda RX4 Wag 6 ## Datsun 710 4 ## Hornet 4 Drive 6 ## Hornet Sportabout 8 ## Valiant 6 ## Duster 360 8 ## Merc 240D 4 ## Merc 230 4 ## Merc 280 6 ## Merc 280C 6 ## Merc 450SE 8 ## Merc 450SL 8 ## Merc 450SLC 8 ## Cadillac Fleetwood 8 ## Lincoln Continental 8 ## Chrysler Imperial 8 ## Fiat 128 4 ## Honda Civic 4 ## Toyota Corolla 4 ## Toyota Corona 4 ## Dodge Challenger 8 ## AMC Javelin 8 ## Camaro Z28 8 ## Pontiac Firebird 8 ## Fiat X1-9 4 ## Porsche 914-2 4 ## Lotus Europa 4 ## Ford Pantera L 8 ## Ferrari Dino 6 ## Maserati Bora 8 ## Volvo 142E 4 11.2.1 Exercise Write a function called sum_func that calculates the sum of all numbers within a specified range. The function will take two inputs: minval which is the smallest number and maxval which is the largest number. 11.3 If-else Conditional statements are the heart of programming. The if-else statement evaluates whether a condition is TRUE or FALSE and then perform a computation based on the truth of the statement. The syntax of an if-else statement is as follows: if (logical statement){ ##perform an action if the logical statement is TRUE } else{ ## perform a different action if NOT TRUE } For example, suppose we wanted to loop a vector of random numbers in the range of 1 to 100 and find out how many of them are greater than 50. We could do this in the following way: ## setting the seed for replication set.seed(1992) ## creating a random sample of 100 integers in the ## interval 1 to 100 numbers &lt;- sample(1:100, 100) ## counting how many numbers come out bigger than 50 count &lt;- 0 ## setting our counter to 0 for (i in numbers) { ## evaluating if the number is greater than 50 if (i &gt; 50) { count &lt;- count + 1 ## adding a 1 to our counter } else { count &lt;- count ## redundant, but here for example } } Note the set.seed function. This is a function that allows replication of results when using random sampling techniques. Essentially it ensures that your random sample is the same random sample every time you run the program. While the seed was set to 1992, you can set the seed to any number you like. Of course, each seed number has its own unique sample (e.g. set.seed(1) will give different results than set.seed(2)). 11.3.1 Exercise Loop through your numbers vector and assign grade values to each of the numbers, and place the grades in a separate vector. For the grade values, if the number is less than 60, assign an “F,” if the number is between 60 and 69 assign a “D,” if the number is between 70 and 79 assign a “C,” if the number is between 80 and 89 assign a “B,” and if the number is between 90 and 100 assign an “A.” For fun, graph a histogram of the distribution. 11.4 Selected Solutions ## a solution to Exercise 1.1.1 ## this function converts miles to kilometers and feet ## to meters it takes two input paramters: miles and ## feet it returns two values: the kilometers and the ## meters miles2kilo_feet2meter &lt;- function(miles, feet) { kilometers &lt;- miles * 1.6 meters &lt;- feet * 0.3 return(print(paste(&quot;Kilometers: &quot;, kilometers, &quot;Meters: &quot;, meters))) } ## a solution to Exercise 1.2.1 ## This function calculates the sum of all numbers ## within a specified range two parameters: minval and ## maxvalue minval: the minimum value of the range ## maxval: the maximum value of the range sum_func &lt;- function(minval, maxval) { total = 0 for (i in minval:maxval) { total = total + i } return(print(paste(&quot;The sum of all numbers is &quot;, total))) } "],["relational-data.html", "Chapter 12 Relational Data 12.1 Finding Primary Keys 12.2 Finding Primary Keys (harder) 12.3 Selected Solutions", " Chapter 12 Relational Data For this chapter, we will be focusing on how to find primary keys. A primary key is a compact way of saying “how to uniquely identify observations in your data set.” To practice finding primary keys, we will be using a variety of data sets that are already preloaded in R packages. The purpose of identifying primary keys is to make merging multiple data sets together easier. Merging data works best when you can merge on keys that uniquely identify your observations. This ensures that each observation is connected to their true data in the foreign data set (i.e. the data set that it will be merged to). A failure to merge your data correctly will result in inaccurate data that will not produce any meaningful result. This is what we want to avoid. 12.1 Finding Primary Keys The most useful technique to finding primary keys involves a combination of your intuition and the count and filter functions. To start, we’ll load in the titanic_train data from the titanic package. ## loading in the necessary package library(tidyverse) library(titanic) library(janitor) ## data we will be working with titanic &lt;- clean_names(titanic_train) Let’s take a look at the first few rows of our data by using the head function. ## getting a snapshot of our data titanic %&gt;% head() ## passenger_id survived pclass name sex age sib_sp ## 1 1 0 3 Braund, Mr. Owen Harris male 22 1 ## 2 2 1 1 Cumings, Mrs. John Bradley (Florence Briggs Thayer) female 38 1 ## 3 3 1 3 Heikkinen, Miss. Laina female 26 0 ## 4 4 1 1 Futrelle, Mrs. Jacques Heath (Lily May Peel) female 35 1 ## 5 5 0 3 Allen, Mr. William Henry male 35 0 ## 6 6 0 3 Moran, Mr. James male NA 0 ## parch ticket fare cabin embarked ## 1 0 A/5 21171 7.2500 S ## 2 0 PC 17599 71.2833 C85 C ## 3 0 STON/O2. 3101282 7.9250 S ## 4 0 113803 53.1000 C123 S ## 5 0 373450 8.0500 S ## 6 0 330877 8.4583 Q To uniquely identify an observation, we need a column (or combination of columns) that puts each passenger into one row. In other words, since we have individual-level data, we want to find a row that will uniquely identify each individual. Since this is our first example, this is relatively simple: passenger_id uniquely identifies an individual, and so does name. While this seems intuitive, it is important to actually check whether this is true. This is where the technique of filter and count must be applied. We will be using the following algorithm to check whether a column (or combination of columns) uniquely identifies our observations: Start with one column that you believe could uniquely identify an observation Count all of the elements in a column Filter out any of them that occur more than once If you do not receive any observation that occur more than once, you are done, if not, you must either try another column, or try a combination of columns. Use your intuition. This small algorithm ensures that we are uniquely identifying each observation. It clearly displays observations that occur more than once to inform us that this column (or columns) does or does not identify a primary key. To summarize, if we run our algorithm and receive any output of observations, we failed to find a primary key and need to rethink how we identify an observation. Let’s try out this algorithm on our two columns that we intuitively thought could identify each individual. ## using algorithm on the passenger_id column titanic %&gt;% count(passenger_id) %&gt;% filter(n &gt; 1) ## [1] passenger_id n ## &lt;0 rows&gt; (or 0-length row.names) Success! The passenger_id column does not contain multiple observations of identification. Therefore, it uniquely identifies each observation, and we could use this column to merge in data from other data sets. ## using algorithm on the name column titanic %&gt;% count(name) %&gt;% filter(n &gt; 1) ## [1] name n ## &lt;0 rows&gt; (or 0-length row.names) Another success! The name column also does not contain multiple observations of any particular name. Therefore, it also identifies each individual, and we could also use this column to merge in data from other data sets. On the other hand, let’s test the ticket column as it intuitively seems like it could also uniquely identify an observation (there is usually one ticket per person). ## testing if ticket uniquely identifies titanic %&gt;% count(ticket) %&gt;% filter(n &gt; 1) %&gt;% head() ## ticket n ## 1 110152 3 ## 2 110413 3 ## 3 110465 2 ## 4 111361 2 ## 5 113505 2 ## 6 113572 2 Clearly, since we see that there are multiple duplicates of ticket numbers, we cannot uniquely identify our observations using the ticket column. Our titanic dataset is simple in that we have two ways to uniquely identify an observation which only included one column, but this is not always true. In the next section, we will go through a harder example which will require a collection of columns. 12.2 Finding Primary Keys (harder) In the titanic example, finding the primary keys was pretty intuitive, and a little trivial. However, this is not always the case. Let’s take a look at a data set from the babynames package. The babynames data set provides data on names given at birth from the Social Security Administration. This includes all names with at least 5 uses (sorry Elon). For our purposes, we will subset the data set since the original data is almost 2 million observations. ## loading the necessary package library(babynames) ## selecting only the first 20,000 observations and ## getting rid of one of the rows we don&#39;t need babynames &lt;- babynames[1:20000, ] %&gt;% select(-n) ## getting a preview of the data babynames %&gt;% head() ## # A tibble: 6 × 4 ## year sex name prop ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 1880 F Mary 0.0724 ## 2 1880 F Anna 0.0267 ## 3 1880 F Emma 0.0205 ## 4 1880 F Elizabeth 0.0199 ## 5 1880 F Minnie 0.0179 ## 6 1880 F Margaret 0.0162 As we can see, there are four columns: year- the year of the birth sex - the sex of the child name - the name of the child prop - a weighting variable we do not care about We want to uniquely identify an observation. This is where we need intuition as well as our algorithm. Would name uniquely identify an observation? No. A name can appear in many different years. Observe our algorithm: ## checking if name uniquely identifies the data babynames %&gt;% count(name) %&gt;% filter(n &gt; 1) ## # A tibble: 2,728 × 2 ## name n ## &lt;chr&gt; &lt;int&gt; ## 1 Aaron 9 ## 2 Ab 4 ## 3 Abbie 10 ## 4 Abbott 2 ## 5 Abby 8 ## 6 Abe 9 ## 7 Abel 9 ## 8 Abigail 9 ## 9 Abner 9 ## 10 Abraham 9 ## # … with 2,718 more rows Clearly, we see that there are multiple times a name appears. Hence, we must use a collection of columns to uniquely identify (recall our algorithm). Our intuition should tell us that using name and year may allow us to uniquely identify our data since each name likely occurs one time within each year. As always, our algorithm can check this assumption: ## checking if name and year uniquely identifies the ## data babynames %&gt;% count(name, year) %&gt;% filter(n &gt; 1) ## # A tibble: 1,245 × 3 ## name year n ## &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; ## 1 Abbie 1887 2 ## 2 Ada 1885 2 ## 3 Ada 1886 2 ## 4 Ada 1887 2 ## 5 Addie 1880 2 ## 6 Addie 1881 2 ## 7 Addie 1882 2 ## 8 Addie 1883 2 ## 9 Addie 1884 2 ## 10 Addie 1886 2 ## # … with 1,235 more rows It seems we are still not getting unique observations as there are many names that appear twice. Why would this be? This is where you must think critically about your data. Notice that our algorithm has shown us that names occur a maximum of two times. This should hint at something: these names are being used for both males and females. Therefore, to uniquely identify an observation, we must use three columns: name, year, and sex. ## checking if name, year, and sex uniquely identify ## an observation babynames %&gt;% count(name, year, sex) %&gt;% filter(n &gt; 1) ## # A tibble: 0 × 4 ## # … with 4 variables: name &lt;chr&gt;, year &lt;dbl&gt;, sex &lt;chr&gt;, n &lt;int&gt; Success! We managed to find a grouping of columns that brought each observation to one entry. Hence, if we were merging in data, we would want to use these three columns to connect the data. 12.2.1 Exercise (Taken from R for Data Science Chapter 13.3 Exercises) Identify the primary key in the following data set from the fueleconomy package: vehicles. Remember, the primary key could be a single column or a collection of columns. 12.2.2 Exercise (Taken from R for Data Science Chapter 13.3 Exercises) Identify the primary key in the following data set from the Lahman package: Batting. Remember, the primary key could be a single column or a collection of columns. 12.2.3 Exercise (Taken from R for Data Science Chapter 13.3 Exercises) Identify the primary key in the following data set from the nasaweather package: atmos. Remember, the primary key could be a single column or a collection of columns. 12.3 Selected Solutions These are shown on the next page. Please do not look at these until you have tried the exercises. These are provided because these exercises are more difficult. (Exercise 1.2.1) The column id uniquely identifies the observations. (Exercise 1.2.2) The columns (playerID, yearID, stint) uniquely identify each observation. The columns (playerID,yearID) are not a primary key because players can play on different teams within the same year (Exercise 1.2.3) The primary key is (lat, long, year, month). The primary key represents the location and time that the measurement was taken. "]]
