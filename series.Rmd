--- 
title: "Data Wrangling for Economists"
author: "Michael Topper"
date: "`r Sys.Date()`"
site: bookdown::bookdown_site
# output: bookdown::gitbook
documentclass: book
bibliography: [book.bib, packages.bib]
biblio-style: apalike
link-citations: yes
github-repo: openscapes/series
description: "Enter description."
---

# Welcome {#welcome}


It's possible to create beautiful books for free using [RStudio's R Markdown](http://rmarkdown.rstudio.com/) and Yihui Xie's [bookdown](https://bookdown.org/yihui/bookdown/) and hosting them on [Github](http://github.com). This is pretty new and incredibly cool. It is a really powerful way to communicate science using the same reproducible workflow you use for your analyses and collaborations.

This tutorial borrows heavily from a lot of great tutorials and resources you should check out too -- there are links throughout. It also parallels a previous tutorial [Making free websites with RStudioâ€™s R Markdown](https://jules32.github.io/rmarkdown-website-tutorial/).

The best way to learn is to follow along with your own laptop, but all are welcome. We'll spend half the time with the tutorial and half the time for you to work on your own website and get help. If you bring your laptop please do this beforehand: 

1. install [RStudio](https://www.rstudio.com/products/rstudio/download/)
1. create a [GitHub]((http://github.com)) account ([advice](http://happygitwithr.com/github-acct.html))
1. set up your computer to talk to GitHub
    - have RStudio linked directly (highly recommended) ([instructions sections 8-14](http://happygitwithr.com/hello-git.html))
    - or install the [Desktop App](https://desktop.github.com/)
    - or be familiar with git commands for the command line ([tutorial](https://try.github.io/levels/1/challenges/1))

----


**Examples:**

We have been using bookdown for the Ocean Health Index:  [**ohi-science.org/data-science-training**](http://ohi-science.org/data-science-training) and Openscapes: [**openscapes.org/series**](https://openscapes.org/series).  
And R Markdown is much more than books and websites -- here's a [**one-minute video about R Markdown**](http://rmarkdown.rstudio.com/lesson-1.html) to get you excited. 

----

## Learn all about Bookdown

The best way to learn more about bookdown is from Yihui Xie himself. You can read his book [bookdown: Authoring Books and Technical Documents with R Markdown](https://bookdown.org/yihui/bookdown/) or watch his webinar [introducing bookdown](https://www.rstudio.com/resources/webinars/introducing-bookdown/).


<!--chapter:end:index.Rmd-->

---
title: 'Guided Exercises: R Projects'
subtitle: Econ 245
output:
  html_document:
    df_print: paged
header-includes:
- \usepackage{fancyhdr}
- \pagestyle{fancy}
- \fancypagestyle{plain}{\pagestyle{fancy}}
- \fancyhead[LE, LO]{Staying Organized}
- \fancyfoot[LE,LO]{Copyright UCSB 2021}
- \newcommand{\magenta}[1]{\textcolor{magenta}{#1}}
- \usepackage{xcolor}
- \usepackage[fontsize=11pt]{scrextend}
- \usepackage{float}
- \floatplacement{figure}{H}
- \usepackage{indentfirst}
editor_options:
  chunk_output_type: console
linkcolor: magenta
---

```{r, include=FALSE}

library(pacman)
pacman::p_load(
  "tidyverse",
  "modelsummary",
  "formatR" # used to wrap code output
)

```

This document provides an introduction to the `R Project` - an organizational tool which we highly recommend you adopt ASAP. This tool will be invaluable for reproducible research, collaboration, and integrates seamlessly with Git/Github. 

# The `Rproject`

When working with coauthors, each writer will need to source scripts between local machines. A common problem is that these scripts will no longer work since the file paths are "hard-coded". For example, if your Homework 1 was part of a research project, the naive start may be something like this:

```{r, eval=FALSE, echo=TRUE}
library(tidyverse)

## sets the working directory
## never use this command ever again!!!!
setwd("user/Desktop/econ_145/homework_1/")

```

If you were to send your script to your coauthor, it would not necessarily run on their local machine. It may be the case that you each have different files within different directories. This is a common problem, but there is one great solution: `R Projects`.

An `R Project` is a way to locally source all files regardless of computer you are operating on. An `R Project` automatically detects the file-path leading up to the project meaning you only have to locally source. For instance, say you created a research project folder named "research_project" on your Desktop where you keep all your files. To run a file named "regressions.R" *without* an `Rproject`, you would need to call the following using the `source` function:

```{r, eval = F, echo = T}
## The source function simply runs the file that is passed to it
## note that this file path is "hard-coded" and will not work on any other machine than the one it was created on
source("user/Desktop/research_project/regressions.R")
```

However, with an `Rproject` you could simply do the following:

```{r, eval = F, echo = T}
## this code would be able to run on any machine that has the R project
source("regressions.R")
```

Hence, as specified earlier, an `R Project` detects the file-path leading to the project folder. So in this case, every file we source will be relative to the `user/Desktop/research_project/`. This is terrific because `R Projects` will automatically detect the file-path leading to the folder, so you can send the `R Project` folder to any coauthor and they will be able to run the files on their local machine *without making any changes*. 

As a secondary example, suppose you want to load in the data which is nested in the following path: "user/Desktop/research_project/data/my_data.csv". If an `Rproject` was made in the "research_project" folder, then you would call in the data using the following:

```{r, eval = F, echo = T}
## reading in the data 
my_data <- read_csv("data/my_data.csv")
```

This is a much less error-prone way to work collaboratively, and sets you up for success for reproducibility. 

*Aside: If you're less comfortable writing file-paths, you can use the `here` package to make the job a bit easier. `here` finds the file-path leading to the `Rproject`, then allows you to enter each folder separating the lines with a comma.*

Creating an `R Project` is simple. Just click `File->New Project` in the RStudio user interface (see Figure \ref{makeproject}):

```{r, fig.cap="\\label{makeproject}Creating a Project", out.width="75%", fig.align="center"}
# here::here() is generating the filepath such that it'll work regardless of changes in earlier folder structure or the computer it's on!
knitr::include_graphics(here::here("images","rproject","pic_1.png"))
```

RStudio also allows you to quickly switch between your projects. Figure \ref{switching} points out the `R Project` in the top right hand corner of the ``R` session. If you click on the name, the drop down appears with all of the previously accessed projects to quickly hop between projects.

```{r switching, fig.cap="\\label{switching} Easily Switching Projects", out.width="75%",fig.align="center"}
knitr::include_graphics(here::here("images","rproject","switching.png"))
```

The other benefit of `R Projects` is the seamless synchronization and integration with Github, which will be covered soon.

This is a brief introduction to `Rprojects`. Additional reading on the matter can be found [here](https://www.r-bloggers.com/2020/01/rstudio-projects-and-working-directories-a-beginners-guide/). We highly recommend you adopt `R Projects` from the very beginning of this course - it will save you a ton of time later on!

<!--chapter:end:guided_exercise_rprojects.Rmd-->

---
title: "Guided Exercises: Introduction to R"
output: 
  html_document:
    df_print: paged
header-includes:
  - \usepackage{fancyhdr}
  - \pagestyle{fancy}
  - \fancypagestyle{plain}{\pagestyle{fancy}}
  - \fancyhead[LE, LO]{Econ 245 - Fall 2021}
  - \fancyfoot[LE,LO]{Copyright UCSB 2021}
  - \newcommand{\magenta}[1]{\textcolor{magenta}{#1}}
  - \usepackage{xcolor}
editor_options: 
  chunk_output_type: console
---


# Intro to R

Welcome to Econ 245 Guided Exercises! In these weekly documents, you will practice data wrangling with some hand-holding as well as some simple exercises to check your understanding. The purpose of these documents is the following:

1. Make your homework easier.
2. Make you a better coder by observing good code.
3. Get hands-on practice with functions you will need to complete your assignments.
4. Provide a reference document for each topic in the course.


We *strongly* suggest that you code along with the examples that we go through, although there will be times when copying and pasting can be useful (e.g., loading in a data set). 

This week we will be focusing on a couple topics. The first will be doing common statistics in R, while the other will be an introduction to vectors, tibbles, and logical operators. 

To begin, we will first load in the data sets that we want to use. We will be using the `titanic_train` data set from the `titanic` package. The `titanic_train` data set provides information on the fate of passengers on the fatal maiden voyage of the ocean liner "Titanic", summarized according to economic status (class), sex, age and survival. Some import columns:

* `Survived`: binary variable equal to 1 if the passenger survived
* `Pclass`: the passenger's class
* `name`: the passenger's name
* `Sex`: the sex of the passenger
* `Age`: the age of the passenger

Let's load in the data set along with the packages we will be using. Quick aside: A package is a set of functions that are not defined in R by default. Many people create their own packages which have their own unique functions and data sets within. Packages are easy to install, and you only have to install a package one time and then it will be in your local machine for future use. We can install packages using the `install.packages` function. Important: installing a package **does not** mean it has been loaded. To be able to use the functions and data sets within the package, you must load the package by using the `library` function. Also important: a package needs to be loaded within each R session Hence, if you restart R or quit and reopen RStudio (which will restart R), you will need to re-load your packages. Observe:  
```{r, eval = F}
## installing the necessary packages. The titanic package has the data set we want
## the tidyverse package has the functions we want
install.packages("titanic")
install.packages("tidyverse")
```

```{r}
## loading in the tidyverse and titanic packages
## remember: functions and data in the packages cannot be used unless loaded in!
## this must be done in each R session!
library(tidyverse)
library(titanic)

## loading in the titanic data set
titanic <- titanic_train
```

## Basic summary statistics

To start off, we will go through some basic summary statistics. For this section, we will focus on the `Age` column of the data set. 

Let's say we wanted to view only the `Age` column of the data. We could accomplish this using the `$` attachment. Observe:

```{r, eval = F}
## viewing only the age column
titanic$Age
```

From this, we can see that there are many values in the `Age` column, some numbers, and others NA. NA is a value that R recognizes as "missing". We will touch more on this in lectures and other assignments. For now, just think of it as a missing element. 

Alternatively, we can get a "snapshot" of our data using the `head` function. 

```{r}
## using the head function to get a snapshot of the data
head(titanic)
```

Taking a look at your data before you start doing analysis is imperative, and the `head` function gives you a concise preview of most of your columns. 

Now, let's attempt some basic summary statistics. For starters, we will use the `mean`, `sd`, and `var` functions to get the mean, standard deviation, and variance of the `Age` column respectively. 

```{r}
## finding the mean of the age column
mean(titanic$Age)
```

We get a value of NA as our mean of the `Age` column, despite our knowledge that the `Age` column contains many different age values. Let's use the `?` to get more information on the `mean` function to see what may be causing this. 

```{r, eval = F}
?mean
```

If we look at some of the arguments that the `mean` function takes, we can see that one of them is called `na.rm`. The `na.rm` function is initially defaulted to `FALSE`. But what does `na.rm` do? If we set the `na.rm` argument to `TRUE`, then `na.rm` will remove the NA values before the computation proceeds. This is exactly what we need to get a numerical answer for our mean. Before, R was trying to compute missing values into our `mean` function which does not make any sense (hence the nonsensical answer).  

```{r}
## trying this again using the na.rm = T argument
mean(titanic$Age, na.rm = T)
```

Now we finally get our desired result. It is important to check your column values using the `head` function if you ever get NA as a statistic to make sure your whole column is not solely missing values. Now it's time to try it yourself.

### Exercise 

* Using the `sd` and `var` functions, find the standard deviation and variance of the `Age` column. Check your solutions at the end of the document. 

## Basic histogram

Another tool to give you an idea of the distribution of your data is the `hist` function. The `hist` function creates a histogram of your data. Suppose we are interested in the distribution of ages on the titanic. We could quickly get an accurate depiction by graphing a histogram of the column.

```{r}
## graphing a histogram of the Age column
hist(titanic$Age)
```

### Exercise 

* Make a histogram of the `Fare` column. Change the title of the histogram to "Distribution of Fare". Do you notice anything interesting?

## Creating Vectors 

R is a *vectorized* computer language. This means that when you perform a function, it performs it on an entire vector of values, rather than value-by-value. The vectorization of R allows us to perform functions on an entire column of the spreadsheet, rather than going cell-by-cell. In the previous example with the `titanic` data set, we took the mean of an entire column of values by simply using the `mean` function rather than iterating through each element of our column, adding up the values, and dividing by the total. 

To get a better understanding of vectors, it is useful to create them yourself. Let's create a vector using the `c` function. To create a vector, we need a few things:

1. If we want to refer to our vector later, we need to name it.
2. We need to give the vector elements.

To begin, we will investigate (1). 
```{r}
## creating a vector but not saving it
## the vector has 4 elements
c(1,3,4,10)
```

Here, we created a vector of four values: 1, 3, 4, and 10. Notice at the top right of RStudio that our Global Environment did not change. This is because we did not save the vector. To save the vector, we need to give it a name. For our purposes, the vector will be named `first_vector`. 

```{r}
## creating a vector and naming it to save
first_vector <- c(1,3,4,10)
```

Once you run this line, you should see that your Global Environment has changed. It should now have the `first_vector` along with a small description of what it contains (e.g. 1, 3, 4, 10). The purpose of saving vectors (or saving anything) is so that we can refer to it later. Instead of creating a new vector of 1, 3, 4, and 10 each time we want to use it, we can *call* it by typing its name.

```{r}
## calling our vector to observe its elements
first_vector
```


### Exercise 

* Create two vectors called `my_own_vector1` and `my_own_vector2`. Each vector should have four numbers in them. Use whichever numbers you like. 


## Comparing Vectors

Vectors can be compared to values and other vectors. To perform this task we use *logical operators*. The *logical operators* are similar to what you learned in elementary math: greater than, equal to, or not equal to. In R, we use the following for logical operators for comparisons:

* `<` greater (less) than
* `<=` greater (less) than or equal to 
* `==` equal to
* `!=` not equal to

The best way to understand how logical operators work is to see them in action. As an example, we will compare our `first_vector` to the value 7.  

```{r}
## which elements are greater than 7?
7 > first_vector
```

```{r}
## ordering does not matter
first_vector < 7
```

Notice that R returned logical values TRUE and FALSE. R went through each element of our vector and checked whether the element was less than the number 7. According to our output, the first three elements in our vector were less than the number 7 (hence TRUE) and the last element was not (hence FALSE). We can evaluate the other logical operators as well:

```{r}
## checking if each element is not equal to 7
first_vector != 7
```

```{r}
## checking if each element is equal to 7
first_vector == 7
```

As a brief aside, observe the last line of code we wrote to check whether `first_vector` was equal to 7. Notice that the "equal to" operator is `==` rather than `=`. This is because `==` checks the equivalence of components, while `=`  is an *assignment* character similar to `<-`. In fact, `<-` and `=` serve the exact same purpose for assignment. 

```{r}
## assigning our first_vector to the value 7
## we are not checking whether it is equal to 7
first_vector = 7

## showing what our first_vector contains after assignment
first_vector
```

The R community typically uses `<-` as assignment rather than `=`. It does not matter which one you use when assigning a variable name, but this class will use the `<-` assignment as it is the the most frequent one you see online. 

### Exercise 

* Using your `my_own_vector1` and `my_own_vector2`, compare each of these vectors using the 4 logical operators.

## Creating a tibble

A tibble is essentially a collection of columns with names, similar to an excel spreadsheet. If you are familiar with other computer languages, it is a special type of data frame that has particularly user-friendly characteristics such as making previewing data easier. To demonstrate this, we will observe the `titanic` data set we were working with earlier. Enter and run the following code:

```{r, eval = F}
## this is currently a data frame - it does not have nice features to view the data or see the data types
## the code output is suppressed here to make this document shorter
titanic
```

The `titanic` data set is currently a data frame, and hence, it is difficult to view. Let's change it to a tibble:

```{r}
## changing the titanic data frame to a tibble
titanic <- tibble(titanic)
```

Now that we've changed titanic to a tibble, it has nicer previewing features. Observe what happens when we preview the data:
```{r}
## previewing the data
titanic
```

As you can see, we now have a helpful snapshot of our data that displays far nicer than when the `titanic` data set was a data frame: we can see multiple columns, we see only the first 10 rows, and we can see the data types of each column nested under the column names (for instance, `PassengerID` is an `<int>` which stands for integer).

Tibbles are what we will be working with most frequently in this course. While it is generally uncommon to manually create a tibble, it is a great exercise to get a better understanding of how they work. First, we will create another two vectors and recreate our `first_vector` with its original values:

```{r}
## reassigning original values to the first_vector
first_vector <- c(1,3,4,10)
## new vector
second_vector <- c(1,1,2,2)
```

Now let's create a tibble that has two columns. Our first column will be the values of `first_vector` and our second column will be the values of `second_vector`. We will use the `tibble` function which takes vectors as arguments. Similarly to vectors, we need to make sure that we **save our tibble** by assigning it to a name. 

```{r}
## creating a tibble named first_tibble with two columns
first_tibble <- tibble(first_vector, second_vector)

```

Since we assigned this tibble a name, we can now see in our Global Environment that it has saved with our desired name. If we click `first_tibble` in the Global Environment, it will give us a spreadsheet view of our tibble. We can also accomplish this by using the `View` function.

```{r, eval = F}
## Viewing our tibble in spreadsheet form
View(first_tibble)
```

Notice that the tibble has two columns which are named identically to our vectors. As shown earlier using the `titanic` data, we can also perform actions on this tibble.

```{r}
## finding the mean of the first_vector column
## I did not need to set the na.rm = T since no NA values, but did it anyways
mean(first_tibble$first_vector, na.rm = T)
```

Alternatively, we could create a tibble with column names that differ from our vector names. In the previous example, our `first_tibble` has two columns with the names defaulted to `first_vector` and `second_vector`. However, we can initialize different names to the column by adding a little more syntax to our `tibble` function. Suppose I want to make a new tibble named `second_tibble` with the `first_vector` and `second_vector` as columns. However, I want the `first_vector` column to be named `age` and the `second_vector` column to be named `gender`. 

```{r}
## Creating a new tibble with two columns with the names "age" and "gender"
second_tibble <- tibble("age" = first_vector, "gender" = second_vector)
## showing the result
second_tibble
```

**One other important point**: Notice how in the `tibble` function we used `=` rather than `<-` for assigning names. It is important that you use `=` for assigning arguments rather than `<-`. Try using `<-` in the tibble argument, and see how it fails to properly do what we want. 

### Exercise 

* Using your vectors `my_own_vector1` and `my_own_vector2` that you created in the earlier exercise, create a tibble using the `tibble` function. 


# Selected Solutions

* (Exercise 1.1.1) Standard deviation: `r sd(titanic$Age, na.rm = T)`  Variance: `r var(titanic$Age, na.rm= T)`


<!--chapter:end:intro_r.Rmd-->

---
title: 'Guided Exercises: Piping'
output:
  html_document:
    df_print: paged
header-includes:
- \usepackage{fancyhdr}
- \pagestyle{fancy}
- \fancypagestyle{plain}{\pagestyle{fancy}}
- \fancyhead[LE, LO]{Econ 245 - Fall 2021}
- \fancyfoot[LE,LO]{Copyright UCSB 2021}
- \newcommand{\magenta}[1]{\textcolor{magenta}{#1}}
- \usepackage{xcolor}
editor_options:
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Cleaning Data I

For this Guided Exercise, we will once again be working with the `titanic_train` data set from the `titanic` package. This data set provides information on the fate of passengers on the fatal maiden voyage of the ocean liner "Titanic" summarized according to economic status (class), sex, age, and survival. As a reminder, here are some of the important columns: 

* `Survived`: binary variable equal to 1 if the passenger survived
* `Pclass`: the passenger's class
* `Name`: the passenger's name
* `Sex`: the sex of the passenger
* `Age`: the age of the passenger

Now let's load in the data and necessary packages. 
```{r, message = F}
## install the package if you do not have it
# install.packages("titanic")
library(titanic)
library(tidyverse)
library(janitor)

## saving our data to the name titanic as a tibble
titanic <- tibble(titanic_train)
```

We will be focusing on getting comfortable with the following functions in the `tidyverse` package:

* `select`
* `distinct`
* `mutate`
* `group_by`
* `summarize`

We will also learn how to use the following functions in the `janitor` package:

* `clean_names`

We will be using these functions in conjunction with the pipe (typed as `%>%`) operator. By going through these exercises, you will see proper ways to utilize functions and learn to write code in a readable and reproducible way. 

## The Pipe

A pipe (typed as `%>%`) is a specific operator that comes from the `magrittr` package, but is automatically loaded in with the `tidyverse`. Essentially, it makes reading code easier, typing code faster, and finding  complicated results very easy. A pipe essentially is saying "and now, do this" to a tibble. Piping is best used to chain together multiple functions to subset your data set into smaller pieces that you find more interesting. We will see this pipe in action in the following sections. Mastering the pipe is essential to quick and efficient cleaning, and you can find some incredible results with using pipes and a few simple functions. To demonstrate how a pipe works, I'll use a rather bland motivating example: suppose we want to glance at our `titanic` data using the `head` function. Before the pipe existed, we would need to type the following:
```{r, eval = F}
## without a pipe
head(titanic)
```

However, with a pipe, we can type the following:
```{r, eval = F}
## using a pipe
titanic %>% 
  head()
```

Each of these give us the same result. The way the pipe works, is that it automatically fills the "data" argument of a function with the tibble you are piping from (in this case, the `titanic` tibble). While this seems extraneous in this example, the benefit of the pipe is that you can combine multiple functions together in a readable way. We will see a demonstration of this as we get further into this Guided Exercise.


## The `clean_names` function

The `clean_names` function allows us to put all of our column names in our tibble in a standardized format. In particular, the function makes certain that the column names are all lowercase and blank spaces are replaced with an underscore. Keeping your variable names standardized is an important practice that will make data wrangling much easier as your data sets get bigger and you begin collaborating with others.

Let's take a look at our data set without cleaning the names.

```{r}
## viewing a snapshot of our data set
titanic %>% 
  head()
```

Notice here we used the pipe. The pipe told us to take the `titanic` data set, and perform the `head` function to it. In terms of piping language we could specify what happened:

* Use titanic data set
* And now take the `head` of the titanic data set

Another important aspect of this output to notice is that  our columns begin with capital letters (e.g. `Class`). As stated, we can use the `clean_names` function from the janitor package to standardize the column name format to all lower case and underscores. Observe:

```{r, eval = F}
## Using the clean_names function on the titanic data
titanic %>% 
  clean_names()
```

The column names now all have our desired standardized format. Now let's try to use our previous `head` function:

```{r}
## Using the head function again
titanic %>% 
  head()
```

The columns have gone back to their normal messy ways! This is because **we failed to save the changes we made** to our titanic data set. The pipe operator will perform functions on your tibble, but it will **not** save the changes unless you explicitly tell R to do so. 

Let's use the `clean_names` function, and save the tibble with the cleaned column names.

```{r}
## saving the titanic tibble with cleaned names
titanic <- titanic %>% 
  clean_names()
## viewing the cleaned names data set as it has now been saved
titanic %>% 
  head()
```

For the rest of this guided exercise, we will be working with this tibble.

## The `select` function

The `select` function is a way to subset your data. It selects whichever variables you are particularly concerned with. For instance, suppose we were only interested in the `age` and `survived` columns of the `titanic` tibble. We could use the `select` function to observe only these columns.

```{r}
## selecting only the age and survived columns and then previewing with head
titanic %>% 
  select(age, survived) %>% 
  head()
```

There are a few things that should be noted here. First, we did not save this sub-selection of variables as a new tibble, so this is just a temporary sub-selection. Second, we performed two pipes with one pipe on each line until the ending function. This code could be read as:

* Use the `titanic` tibble
* And then `select` the `age` and `survived` columns
* And then use the `head` function to view 

Of course, if we wanted to save our sub-selection, we could easily do this by assigning it to a new tibble.

```{r}
## assigning the subselection to a new tibble
titanic_age_survived <- titanic %>% 
  select(age, survived)

## did not use head here because do not want only the first 5 rows to be saved
```

Generally, the `select` function is a great way to subset your data to focus on only the columns you are particularly concerned with. 

## The `filter` function

The `filter` function is one of the most powerful and frequently used functions when combined with a pipe. The filter function filters your data set based on some criteria you choose. For example, suppose we want to only look at children in this data set. We can filter out all of the passengers in the data set that have an age less than 18. Observe:

```{r}
titanic %>% 
  filter(age < 18) %>% 
  head()
```


Just to further our understanding, let's once again write out what this code is doing:

* Use the titanic tibble
* And then filter out only rows that have `age` equal to "Child"
* And then give the heading of the tibble

### Exercise

* Filter the rows of the `titanic` tibble such that the column `fare` column is greater than 100.

## The `distinct` function

The `distinct` function allows you to see the unique values within a specified column. For instance, suppose we wanted to know all of the unique values that are within the `pclass` column of the `titanic` tibble. We could use the `distinct` function to do this.

```{r}
## using distinct to find unique values in a column
titanic %>% 
  distinct(pclass)
```

We can see from the `distinct` function that the `pclass` column has three unique values: 1, 2, and 3 which correspond to the passengers' class. The `distinct` function can be a great way to take a look at your data and figure out what kind of values reside within specific columns.

### Exercise

* Using the `distinct` function, find the unique values of the `age` column. 


## The `mutate` function. 

The `mutate` function creates a new column in your tibble based on some computation statement. To motivate this, suppose we wanted to create a column in the `titanic` tibble that is named `adjusted_fare` which takes the `fare` column and multiplies it by the rate of inflation to get the ticket fare in today's prices. Using the `mutate` function, we could accomplish this:

```{r}
## assigning a variable the inflation rate
inflation_rate <- 27.14

## creating a new variable called adjusted_fare which will be the fare in today's dollars
titanic %>% 
  mutate(adjusted_fare = fare * inflation_rate) %>% 
  head()
```

There is actually quite a bit going on here, so it's worth noting the syntax of the `mutate` function. 

```{r, eval = F}
## mutate function syntax
titanic %>% 
  mutate(your_variable_name = some expression)
```

Recall that the tibble **will not** save with this new variable that you created unless you tell it to do so.  

Where `mutate` becomes very powerful is using in conjunction with the `ifelse` function. The `ifelse` function is a function that takes a conditional statement, and if it is TRUE, assigns a value, and if it is FALSE, assigns a different value. For instance, suppose we want to create a binary variable equal to 1 if a person is under the age of 18 and 0 if are not. Hence, we can use the `ifelse` function to create our desired binary variable. The syntax for the `ifelse` function is as follows:
```{r, eval = F}
## ifelse syntax
ifelse(a condition, value if condition is TRUE, value if condition is FALSE)
```

This will be more clear once you see it in action. Let's actually create the desired binary variable:

```{r}
titanic %>% 
  mutate(child = ifelse(age < 18, 1, 0)) %>% 
  head()
```

Since we cannot see from the preview that we actually created a binary variable, let's use the `distinct` function as a check.

```{r}
titanic %>% 
  mutate(child = ifelse(age < 18, 1, 0)) %>% 
  distinct(child)
```

**REMEMBER** the `child` variable **DID NOT** save unless you specifically tell R to do so. We will save this variable as we will use it later.

```{r}
## saving the new variable
titanic <- titanic %>% 
  mutate(child = ifelse(age < 18, 1, 0))

## observing the first 5 rows
titanic %>%
  head()
```

## The `summarize` function

The `summarize` function allows us to create statistics over columns quickly and efficiently. As a demonstration, we will be focusing on our `survived` column. Let's suppose that we wanted to know the average of `survived`. Since this is a binary variable, this would be equivalent to the proportion of people who survived the titanic. 

Now let's make a new column called `proportion_survived` which is equal to the mean of `survived`.
```{r}
## finding the average of the survived column
titanic %>% 
  summarize(proportion_survived = mean(survived, na.rm = T))
```

Take a closer look at the `summarize` function. You can think of the `summarize` function as similar to the `mutate` function as it creates a new variable equal to some summary statistic that you tell it to do. The basic syntax for the `summarize` function is as follows:

```{r, eval = F}
summarize(your_variable_name = somefunction)
```

As another example, we could find the standard deviation of the `survived` column using the summarize function.

```{r}
##finding the standard deviation of the survived column
titanic %>% 
  summarize(sd_survived = sd(survived, na.rm = T))
```

### Exercise

* Find the variance of the `survived` column using the `summarize` function. See solutions at the end of the document. 

## The `group_by` and `summarize` functions

The `group_by` and `summarize` functions work together to make computing statistics within-groups easy. Suppose you wanted to know the average rate of survival by class type on the titanic. In other words, you suspect that the survival rate differs by people of different class To do this, you want to take the average of each group. The `group_by` function will group classes together and then the `summarize` function will be able to do summary statistics on each group individually. 
```{r}
## finding the survival rate among classes
titanic %>% 
  group_by(pclass) %>% 
  summarize(survival_rate = mean(survived, na.rm = T))
```

From here you can see that the survival rate greatly varied across different classes. It appears that survival was much more prevalent for higher class people. An interesting result! Let's also review what is happening here in the language of pipes:

* Take the `titanic` data
* And now group by class
* And now summarize the survival rate by creating a column equal to the mean of the `survived` column within each class. 

You may be curious what happens when you do a `group_by` without a `summarize`. The truth is, nothing happens! R will create a grouping, but it means nothing unless you actually perform some sort of meaningful statistic on each group. 

```{r}
## using a group_by without a summarize or following function does nothing
titanic %>% 
  group_by(sex)
```

Since it is imperative to understand the `group_by` followed by the `summarize` function, try out a couple of exercises. 

### Exercise

 * Did women have a higher rate of survival than males? Find the answer to this question using the `group_by` and `summarize` functions.

### Exercise
 * Is there a difference in survival rates between women and men who were in a higher class? Using the `group_by` and `summarize` functions, find the answer to this question. Hint: put two arguments in the `group_by` function.


```{r, echo = F}
survive_gender = titanic %>% 
  group_by(sex) %>% 
  summarize(survivalrate = mean(survived, na.rm = T))
survive_female = survive_gender$survivalrate[1]
survive_male = survive_gender$survivalrate[2]

class = titanic %>% 
  group_by(sex, pclass) %>% 
  summarize(groupings = mean(survived, na.rm = T))
first_class_f = class$groupings[1]
second_class_f = class$groupings[2]
third_class_f = class$groupings[3]
first_class_m = class$groupings[4]
second_class_m = class$groupings[5]
third_class_m = class$groupings[6]
```

# Selected Solutions

* (Exercise 1.7.1) Variance = `r round(var(titanic$survived, na.rm = T),2)`
* (Exercise 1.8.1) Women had higher survival rates at `r round(survive_female,2)`. Males were at `r round(survive_male,2)`.
* (Exercise 1.8.2) Females in first, second, and third class had survivals rate of `r round(first_class_f,2)`, `r round(second_class_f,2)`, and `r round(third_class_f,2)` respectively. On the other hand, males in first, second, and third class had survival rates of `r round(first_class_m,2)`, `r round(second_class_m,2)`, and `r round(third_class_m,2)` respectively. 




<!--chapter:end:intro_piping.Rmd-->

---
title: 'Guided Exercises: Piping and Other Common Functions'
output:
  html_document:
    df_print: paged
header-includes:
- \usepackage{fancyhdr}
- \pagestyle{fancy}
- \fancypagestyle{plain}{\pagestyle{fancy}}
- \fancyhead[LE, LO]{Econ 245 - Fall 2021}
- \fancyfoot[LE,LO]{Copyright UCSB 2021}
- \newcommand{\magenta}[1]{\textcolor{magenta}{#1}}
- \usepackage{xcolor}
editor_options:
  chunk_output_type: console
---

# Data Cleaning II

For this Guided Exercise,  we will be importing  a dataset from TidyTuesday Github. Tidy Tuesday is a weekly social data project in R where users explore a new dataset each week and share their findings on Twitter with #TidyTuesday. In particular, we will be focusing on a horror movies data set from IMDB. IMDB is the world's most popular and authoritative source for movie, TV and celebrity content, designed to help fans explore the world of movies and shows and decide what to watch. This data set shows us information on horror movies that are on IMDB's website. Here are some important variables we will be working with:

* `review_rating`- the IMDB users average rating of the movie.
* `release_country` - the country the movie was released in.
* `movie_rating` - the movie's Motion Picture Association film rating system score (e.g. G, PG, PG-13)

We will be focusing on getting comfortable with the following functions:

* `count`
* `is.na`
* `arrange`
* `filter` in conjunction with logicals

Let's begin by importing in the data. To do this, we will be importing it using the `read_csv` function. Copy and paste the following link: https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-10-22/horror_movies.csv
and put it into a tibble called `horror_movies` using the `read_csv` function as shown below.

```{r, message = "hide"}
## install the package if you do not have it
library(tidyverse)

## loading in the data
horror_movies <- read_csv("https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-10-22/horror_movies.csv")

```

Notice how easy it was to read data off of a website and into R using the `read_csv` function: all it took was copying a pasting a link. 

## The `count` function

The `count` function takes all of the unique elements in a column, and counts how many times each element occurs. For instance, say we want to find the amount of times each movie rating occurs in our data set. We can do this using the `count` function.

```{r}
## finding out how many of each rating of horror movie there are
horror_movies %>% 
  count(movie_rating)
```

The `count` function also has a helpful argument called `sort`. By default, `sort` is set to `FALSE`. This means that the `count` function will not order your results in descending order by the number of times they occur. If you want to view your elements in descending order, you can set the `sort` argument to `TRUE`. 

```{r}
## counting in descending order by setting sort = T
horror_movies %>% 
  count(movie_rating, sort = T)
```

The `sort` argument is particularly useful for spotting things like a large amount of NAs, or getting an idea of how a column is distributed.

### Exercise

* What is the most frequent review rating?


## Using the `is.na` function

The `is.na` function used to find the NAs withing a particular column. It takes one argument: the column you specify . The `is.na` function works particularly well with the `filter` function. Suppose we want to see how many NAs are in the `movie_rating` column. We can do this by `count`, and a `filter` in conjunction with the `is.na` function.

```{r}
## Looking at only the NAs
horror_movies %>% 
  count(movie_rating, sort = T) %>% 
  filter(is.na(movie_rating))
```

While this is useful, it might be even *more* useful if we filter out the NAs. Observe:

```{r}
## Filtering out the NAs
horror_movies %>% 
  count(review_rating, sort = T) %>% 
  filter(!is.na(review_rating))
```

What exactly happened here? The `!` logical is the "not" or "negating" logical. If we were to type `filter(is.na(review_rating))` we are telling R to filter all the elements inside of `review_rating` that are NA. However, if we type `filter(!is.na(review_rating))` we are telling R to NOT filter all the elements inside of `review_rating` taht are NA. Hence, we are actually filtering out the NAs in this line of code.

### Exercise

*  Make a new tibble called $\color{magenta}{\text{horrror\_movies\_NA}}$ that filters out all the NAs in the entire data set. 

## The `arrange` function

The arrange function is a simple function that simply sorts columns into ascending or descending order. For instance, suppose we sort our entire data set by which movies had the highest `review_rating`. We could do this by using the `arrange` function:
```{r}
## using the arrange function to sort the review rating from lowest to highest
horror_movies %>% 
  arrange(review_rating) %>% 
  head(10)
```

By default, the `arrange` function sorts in ascending rather than descending order. If we want to change this, we can use the `arrange` function in conjunction with the `desc` function.

```{r}
## using the arrange and desc functions to sort the review rating from highest to lowest
horror_movies %>% 
  arrange(desc(review_rating)) %>% 
  head(10)
```


## The `filter` function with logicals

As you saw last week, the `filter` function is great for subsetting your data based on a certain criteria. However, the `filter` function becomes much more powerful when used with logical operators. The three most common logical operators we use are the following:

* `!` - the "not" logical operator
* `&` - the "and" logical operator
* `|` - the "or" logical operator

We already briefly specified the `!` logical operator in the previous section, so let's focus on the `&` and `|`. The `&` operator becomes useful when we want to `filter` based on more than one true criteria. For example, suppose we want to filter out the movies that received a 9.0 review rating or higher AND was released in Canada. We would need to evaluate whether two criteria are satisfied: the statement "movies that received a 9.0 movie rating or higher"and the statement "released only in Canada". If **both** of these statements are TRUE, then they get displayed. If not, they are filtered out.

```{r}
## filtering for only movies receiving a movie rating of 9.0 or higher 
## and in the country Canada
horror_movies %>% 
  filter(review_rating >= 9.0 & release_country == "Canada")
```

Notice that now we are looking at movies that have a 9.0 or higher movie rating, and were released in Canada. We can see that there are only 2 movies that match these criteria.

On the other hand, suppose we used the `|` logical operator instead. The `|` operator will evaluate whether "review rating is great than 9.0" is TRUE, or "release country is Canada" is TRUE. If **either** of these statements are TRUE or **both** of these are TRUE, then the data is displayed. If **both** of these are false, then they are filtered out. Observe:

```{r}
horror_movies %>% 
  filter(review_rating >= 9.0 | release_country == "Canada") %>% 
  count(review_rating, release_country,  sort = T)
```

Notice that we we have review ratings that are less than 9.0, and also countries that are not Canada. This is because only **one** of our statements need to be TRUE (although, as stated, **both** can be TRUE as well).

### Exercise

* Use the `filter` function to filter the horror movies that were released only in the USA or were  "NOT RATED". Find which of these movies had the highest review rating. 

### Exercise

* Count the number of PG-13 movies that are only in Japan and USA. 


# Selected Solutions

```{r, echo = F}
## exercise 1.1.1
top_review_ratings = horror_movies %>% 
  count(review_rating, sort = T) 
```

* (Exercise 1.1.1) The most common review rating is `r top_review_ratings$n[1]` for NA, and `r top_review_ratings$n[2]` if we consider NA to not be a review rating. 

```{r, echo = F}
## Exercise 1.4.1
only_usa = horror_movies %>% 
  filter(release_country == "USA" | movie_rating == "NOT RATED") %>% 
  arrange(desc(review_rating))
```

 * (Exercise 1.4.1) Of the movies that were released in USA or had a rating of "NOT RATED" the highest review rating was a 9.8 by the movie `r only_usa$title[1]`.
 
```{r, echo = F}
## Exercise 1.4.2
only_usa_japan = horror_movies %>% 
  filter(release_country == "USA" | release_country == "Japan") %>% 
  count(movie_rating, sort = T) %>% 
  filter(movie_rating == "PG-13")
```
 
 * (Exercise 1.4.2) Of the movies that were released in USA or Japan, there were `r only_usa_japan$n` movies that were rated "PG-13". 

<!--chapter:end:piping_2.Rmd-->

---
title: 'Guided Exercises: Graphics with ggplot2'
output:
  html_document:
    df_print: paged
header-includes:
- \usepackage{fancyhdr}
- \pagestyle{fancy}
- \fancypagestyle{plain}{\pagestyle{fancy}}
- \fancyhead[LE, LO]{Econ 245 - Fall 2021}
- \fancyfoot[LE,LO]{Copyright UCSB 2021}
- \newcommand{\magenta}[1]{\textcolor{magenta}{#1}}
- \usepackage{xcolor}
editor_options:
  chunk_output_type: console
---

# Graphics with ggplot2

In this Guided Exercise, we will be focusing on visualization with an emphasis on using `ggplot2`. While the basic R plots have lower fixed costs to begin using, they are generally less customizable, less initially pretty, and do not work as well in the *flow* of the `tidyverse` package. On the other hand, `ggplot2` has a logical flow to the graphics system. There is always a specific grammar that must be followed to make graphs, and once you understand it, making graphs becomes fun and (more or less) easy. In practice, you will learn that the essence of making graphs is Googling your questions. There is almost certainly an individual who has needed to make a graph similar to yours, and the R community has probably responded using `ggplot2`. 

For this week, we will once again be working with the `titanic_train` data from the `titanic` package. As a reminder, this data set provides information on the fate of passengers on the fatal maiden voyage of the ocean liner "Titanic," summarized according to economic status (class), sex, age, and survival. Here are some of the important columns:

* `Survived`: binary variable equal to 1 if the passenger survived
* `Pclass`: the passenger's class
* `name`: the passenger's name
* `Sex`: the sex of the passenger
* `Age`: the age of the passenger
* `Fare`: the price of the ticket the passenger paid


```{r, message = F}
## loading in the data and packages
library(tidyverse)
library(titanic)

##loading in the data set and cleaning the names
titanic <- janitor::clean_names(titanic_train)
```

## The grammar of graphics

The most important aspect to understand in `ggplot2` is the "grammar of graphics". The `ggplot2` package has its own syntax for making graphs. This syntax, while confusing at first, is extremely elegant when your graphics become more complicated. Let's start off with the basic template for making graphics:

```{r}
##The basic template
## This uses the titanic data set
## creates a histogram with the variable being the age column
ggplot(data = titanic, aes(x = age)) +
  geom_histogram() 
```

There is a LOT to unpack here, so we will go through each component thoroughly: 

* The `ggplot` function tells R that we want to make a `ggplot2` graphic. The `ggplot` function *generally* takes two arguments: the tibble you want to use in the `data` argument, and the `aes` function. The `aes` function stands for the "aesthetic mapping". The purpose of this function is to tell `ggplot2` what you want on your x and y axis. It will then take these inputs and "aesthetically map" them to the desired type of graph. 
* You should notice that there are addition signs (`+`) between these two lines of code. These addition signs can be thought of as a pipe, but for graphics. Specifically, they tell the graph "and now add on this". 
* The `geom_histogram` function is a function that specifies we want to make a histogram. All graphs in the `ggplot2` package begin with "geom" so that we can easily recognize that we are calling a specific type of graph. Other examples are a scatter plot (`geom_point`), density plot (`geom_density`), box-and-whisker plot (`geom_boxplot`), or a bar graph (`geom_bar`). 

## Adding options

As stated above, the `+` is essentially a `%>%`, but for graphics. It can be thought of verbally as "and now add this to the graph". To demonstrate this, let's use our histogram of the `age` column that we saw in the last section. Suppose we wanted to do the following:

* Edit the x axis with our own custom label
* Edit the y axis with our own custom label
* Add a title
* Make the default colors look better

This becomes rather simple to do in `ggplot2` thanks to the grammar of graphics. 
```{r}
## creating the same plot as above except with a title, and edited axis
ggplot(data = titanic, aes(x = age)) + ## use the titanic tibble, map the age column to the graph
  geom_histogram() + ## and now make a histogram of age
  xlab("My x-axis label which is age") + ## and now label the x axis
  ylab("My y axis label which is Count") + ## and now label the y axis
  labs(title = "My title") +## and now label. the label I want is the title
  theme_light() ## and now use this graphing theme to make it pretty
```

As specified in the comments, the way we would read this code is

* Make a ggplot object using the `titanic` tibble and map `age` to the x-axis
* And now add on a histogram 
* And now add on a label the x axis with `xlab`
* And now add on a label the y axis with `ylabs`
* And now add on the graph a title with `labs` and the title argument
* And now use a color scheme that is more appealing with `theme_light`

Let's try to make a few other types of graphs. As mentioned earlier, graph types usually begin with the `geom_` followed by the type of graph that it is. For instance, let's make a box-and-whisker graph (also known as a box-plot) using the `sex` and `age` columns. 

```{r}
## making a box-and-whisker plot
ggplot(data = titanic, aes(x = sex, y = age)) + ## make a ggplot plot using the titanic data and map age and sex to x and y
  geom_boxplot() + ## and now make a box plot with x axis sex and y axis age
  xlab("Sex of the passenger") + ## and now label the x axis 
  ylab("Age of the passenger") + ## and now label the y axis
  labs(title = "Distribution of ages by sex") + ## and now title the graph
  theme_light() ## and now make the graph look prettier
```

Now let's make a scatter plot using the `age` and `fare` columns:

```{r}
## making a scatter plot 
ggplot(data = titanic, aes(x = age, y = fare)) + ## make a ggplot plot using the titanic dat
  geom_point() + ## using age as x axis and fare as y axis
  xlab("Age of passenger") + ## and now label the x axis
  ylab("Ticket price paid") + ## and now label the y axis
  labs(title = "Relationship between age and ticket price") + ## and now title the graph
  theme_light() ## and now make the graph look prettier
```

As shown, it is incredibly simple to switch between different types of graphs. In fact, once you have a template of the certain options you like to add to your graph, you can simply change the `geom_` to your desired graph type. 

## Adding multiple plots together

One of the main draws of `ggplot2` is how simple it is to overlay graphs. For instance, suppose we want a plot that has two histograms, one for male age, and one for female age. We can easily do this by simply adding on a `geom_histogram` argument. 

```{r}
## making two histograms on one graph
ggplot(data = titanic, aes(x = age)) +
  geom_density(data = titanic %>% filter(sex == "male")) +
  geom_density(data = titanic %>% filter(sex == "female"))
```

Notice that the `geom_density` told ggplot to create a density graph. Also notice something new: we added in a `data` argument to `geom_density`. This can be extremely useful when making multiple plots on the same graph. In our example, we told our first density graph to use the `titanic` data, but `filter` only the males. This shows how simple it is to add in `tidyverse` to ggplot!

Let's make this graph a little "prettier". Suppose we wanted to fill these density graphs with some color so we could tell the difference between them. To do this, we will use the `fill` argument that comes standard in each `geom` graph. 

```{r}
## making two histograms on one graph and adding color using the fill argument
ggplot(data = titanic, aes(x = age)) +
  geom_density(data = titanic %>% filter(sex == "male"), fill = 'blue') +
  geom_density(data = titanic %>% filter(sex == "female"), fill = 'red')
```

Of course, this isn't so pretty since one of the densities is clearly over-powering the other. This is where another new argument `alpha` can help us. The `alpha` argument is simply a number between 0 and 1 which tells `ggplot` how transparent the color should be. Observe:

```{r}
## making two histograms on one graph and adding color using the fill argument, and alpha argument
ggplot(data = titanic, aes(x = age)) +
  geom_density(data = titanic %>% filter(sex == "male"), fill = 'blue', alpha = 0.4) +
  geom_density(data = titanic %>% filter(sex == "female"), fill = 'red', alpha = 0.4) +
  theme_light()
```

## Creating legends

Legends are automatically created for you using the `fill` argument **within the aesthetic mapping**. For instance, suppose we wanted to create a graph similar to above with two densities of `age`: one for males and one for females. We can actually accomplish this in a more compact way by adding the `fill` argument to our aesthetic mapping. The `fill` argument within `aes` specifically tells `ggplot` that you want to separate this graph by a categorical variable.  
```{r}
## making two histograms on one graph and adding a legend using the fill argument
ggplot(data = titanic, aes(x = age, fill = sex)) +
  geom_density(alpha = 0.4) +
  xlab("Age") + ## and now add on an xlabel
  ylab("Density") + ## and now add on a ylabel
  labs(title = "Age by Sex", fill = "Sex of Passenger") + ## and now give the graph a title, and 
  # rename the fill argument to "Sex of Passenger"
  theme_minimal() ## and now make the graph have pretty color scheme
  
```

Notice that within the `labs` function, we added in another argument, `fill`. This `fill` will specifically label the `fill` you called in the aesthetic mapping (`aes`). This is beneficial so you can label your legend however you want. Omit the `fill` argument in the `labs` function and see what happens for yourself.

Let's go through the "grammar of graphics" of this graph in plain English:

* Make a ggplot object and use the `titanic` tibble and map the `age` column to the graph, but do two separate "fills" (e.g., versions of the graph), one for each category of sex.
* And now add on a density plot
* And now add on a label the x axis with `xlab`
* And now add on a label the y axis with `ylabs`
* And now add on the graph a title with `labs` and the title argument, and re-label the `fill` argument with the label "Sex of Passenger"
* And now make the graph have default pretty colors with `theme_minimal`

### Exercise

* Create the following graph (HINT: use the `color` argument in the aesthetic mapping and turn `survived` into a factor using `as.factor`):

```{r, echo = F}
exercise_graph = titanic %>% 
  ggplot() +
  geom_point(aes(x = age, y = fare, color = as.factor(survived))) +
  xlab("Age of passenger") +
  ylab("Fare paid") +
  labs(title = "Age and fare and survival", color = "Survived") +
  theme_minimal()
```

```{r, echo = F, warning = F}
exercise_graph
```
 

<!--chapter:end:ggplot2.Rmd-->

---
title: 'Guided Exercises: Strings'
output:
  html_document: default
number_sections: yes
header-includes:
- \usepackage{fancyhdr}
- \pagestyle{fancy}
- \fancypagestyle{plain}{\pagestyle{fancy}}
- \fancyhead[LE, LO]{Econ 245 - Fall 2021}
- \fancyfoot[LE,LO]{Copyright UCSB 2021}
- \newcommand{\magenta}[1]{\textcolor{magenta}{#1}}
- \usepackage{xcolor}
editor_options:
  chunk_output_type: console
---

# Strings

For this Guided Exercise, we will once again be importing the horror movies data set from the TidyTuesday Github. This data set contains information from IMDB on various horror movies. Some important columns we will be focusing on this week:

* `title`- the title of the movie
* `release_date`- movie release date in day-month-year format

Let's load in the data:

```{r}
## install the package if you do not have it
library(tidyverse)

## Load in the data
horror_movies <- read_csv("https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-10-22/horror_movies.csv")
```


Our goal this week to get comfortable with three things:

1. Simple pattern matching with regular expressions
2. Using the `extract` function
3. Using the `separate` function

Using all of these three things together will allow you to do powerful data wrangling techniques that are valued greatly in the workforce. 

## Regular Expressions

Regular expressions are a fantastic tool that will allow you to match patterns in strings. To demonstrate their value, we will start off by making a vector of strings, and use `str_view` to show how we can match patterns using regular expressions.


```{r}
## creating a vector of strings I would like to analyze
x <-  c("Econ 145", "Hello!", "Best CLASS")
```

Let's see if we can match some basic patterns. Suppose I want to find the "o" in each component of the vector. I can do the following:

```{r}
## finding all of the o's in tthe vector x using str_view
str_view(string = x, pattern = "o")
```

Notice that we are matching (see the highlighted text) on the pattern "o" in every element of the vector. Note that there was no "o" to match on in the last element, "Best CLASS", so nothing was highlighted. 

We can take this even further by matching on a selection of numbers. Suppose we want to match the numbers "145". We can simply type in "145" into our pattern match.

```{r}
## matching on the pattern 145
str_view(string = x, pattern = "145")
```

However, these are all trivial examples. Regular expressions allow us to match on *patterns*, not just simple expressions. For example, suppose we have a vector which has multiple names of courses in the economics department:

```{r}
## creating a new vector with three string elements 
econ_classes <-  c("Econ 145", "Econ 10A", "Econ 140A")
```

Now suppose I want to pattern match only the course numbers. I can do this by using a regular expression. 

* `\d`: the regular expression pattern that matches any digit

Let's see this in action.

```{r, eval = F}
## matching incorrectly on any digit
str_view(string = econ_classes, pattern = "\d")
```

The first thing you should notice when you click enter is that an error message occurs: Error: '\d' is an unrecognized escape in character string starting ""\d". We get this error message because `\` is an escape character in the R programming language. Therefore, we need to escape the escape character by using `\\d` to match on a number. This can often be annoyingly difficult to remember, but the the error message should guide you to remember this detail. 
```{r}
## matching correctly on any digit
str_view(string = econ_classes, pattern = "\\d")
```

We managed to match on a number in every single element of the vector without actually specifying we wanted a "1". This is absolutely incredible. 

It is important to note that `\\d` will only match on one number, and by default, the first number it comes across in the string going from left to right. If we want to match on more numbers, we need to add in more `\\d`s. For instance, if we wanted to match on 2 digits, our pattern argument would be equal to `\\d\\d`.

```{r}
## matching on any two digits in each component
str_view(string = econ_classes, pattern = "\\d\\d")
```

Let's try to match on all of the course numbers. Notice that some course numbers have 2 digits, while others have 3. Let's see what happens when we try to match on 3 digits.

```{r}
## matching on exactly three digits in each component
str_view(string = econ_classes, pattern = "\\d\\d\\d")
```

We can see that we matched on *exactly* 3 digits, and failed to match on the element that only contained 2 digits. However, as you may have expected, we have ways to work around this using what we call *repetition patterns*. You can specify the number of matches you would like to make using the following:

* `{n}`: matches exactly n amount of your pattern
* `{n,}`: matches n or more
* `{,m}`: matches at most m
* `{n,m}`: matches between n and m

Hence, we can match on all the course digits by specifying how many times we would like to match the `\d` patter.

```{r}
##matches any digit 2 or more times
str_view(string = econ_classes, pattern = "\\d{2,}")
```

Success! We managed to match the `\d` pattern two or more times and have matched on the course digits. The way we would read this pattern is left to right: "match on any digit, and do this two times or more".  

### Exercise 1

* Find another way to match on the digits of the `econ_classes` vector.

## Regular Expressions Continued

Let's try matching on other types of expressions. 
```{r}
## creating a new vector for us to match patterns on
vector <- c("aaabbbccc", "dddAAAccc", "eib iii")
```

Here are a couple more useful patterns:

* `[abc]`: matches exactly one time on a, b, or c. If multiple appear, it matches on the one that comes first.
* `[^abc]`: matches exactly one time on anything except a, b, or c. 
* `\s`: matches any whitespace (e.g. space, tab, newline).

We will match on the beginning letter of each of these elements in our vector.

```{r}
##matching on the letters a d or e
str_view(string = vector, pattern = "[ade]")
```

### Exercise 2 

* Using the `vector` and `str_view`, match on the capital A and the whitespace. 

## Using `extract`

We will now focus on matching regular expressions within the context of tidying data. Let's specifically focus on the `title` and `release_date` columns. 

```{r}
## selecting only the title and release date columns in the horror movies data set
horror_movies <- horror_movies %>% 
  select(title, release_date)
## showing the head of the data set
horror_movies %>% head()
```

Notice that it looks like each movie title is followed by a whitespace, and then a parenthesis with the movie release year inside of it. For the purposes of explaining `extract`, we will focus on extracting the dates from the `title` column. 

The `extract` function extracts information you want from a column and puts it into a column of your choice. The specific arguments it has are col, into, and regex. These correspond to the column you want to extract an expression from, the column name you are going to send your extracted expression into, and the regular expression pattern you want to extract respectively. 

```{r}
## extracting the year from the 
horror_movies %>% 
  extract(col = title, into = "year", regex = "(\\d\\d\\d\\d)")
```

It is important to note that we **need to put parenthesis** around the pattern that we want to match in our `regex` argument for the match to work. Observe what happens when we do not:

```{r, eval = F}
## code does not work because no parenthesis around the regex expression
horror_movies %>% 
  extract(col = title, into = "year", regex = "\\d\\d\\d\\d")
```

This is because the parenthesis define a group of patterns that you want to match. Everything inside your parenthesis is a group. For the purposes of this class, we will only be extracting 1 group, as extracting more than one group gets very complicated. 

```{r}
## the correct code: works because we put parenthesis around the regex expression
horror_movies %>% 
  extract(col = title, into = "year", regex = "(\\d\\d\\d\\d)")
```

Notice when we ran the previous correct code, our `title` column disappeared. This is because by default, the extract function deletes the original column. To avoid this, we can set the `remove` argument to `FALSE`. 

```{r}
## the correct code: works because we put parenthesis around the regex expression
horror_movies %>% 
  extract(col = title, into = "year", regex = "(\\d\\d\\d\\d)", remove = F)
```

## Using `separate`

The `separate` function will split a column into multiple columns based on a regular expression. You can think of separate as a way to split with a more complicated delimiter (a delimiter is a character that separates values). For starters, we will separate once again look at the `title` column in the horror movies data. Recall that the `title` column is organized as the movie title, followed by a blank space and then the year of release in parenthesis. We will take advantage of this unique organization and separate our `title` column into two columns: `title` which will have the title of the movie, and `year` which will have the release year. While this will take multiple steps to get into a perfectly cleaned data set, we can utilize our piping procedures to make it relatively straightforward. 

First, let's separate the column based on the first parenthesis that we see.

```{r}
## separating on the first parenthesis in the title column
horror_movies %>% 
  separate(col = title, into = c("title","year"), sep = "\\(") 
```

Notice how we managed to separate the two columns, but there are now more problems we need to deal with:

1. What do the warning messages mean?
2. We need to get rid of the extra parenthesis in the `year` column.
3. We need (well, we don't NEED) to get rid of the blank space at the end of the `title` column. 

First and foremost, we will take a second to review what a warning message is. 

**Warning message:** These are messages that tell you that your R code was able to execute, but in the process, R decided to do something that you did not tell it to. It is **extremely** important that you Google warning messages, as your data could be manipulated by R in ways you really did not want. Let's look at our two warning messages in depth:
```{r, eval = F}
Warning messages:
1: Expected 2 pieces. Additional pieces discarded in 7 rows [691, 928, 1289, 2086, 2130, 2545, 3262]. 
2: Expected 2 pieces. Missing pieces filled with `NA` in 1 rows [932]
```

The first warning message is telling us that R expected 2 pieces, and then discarded additional pieces in 7 rows. While this does not make much sense at first sight, it gives us the rows which it performed this process. The best practice is to investigate these rows to get a better idea of what is happening.
```{r}
## investigating a couple of the rows that caused the warning message
horror_movies$title[691]
horror_movies$title[928]
horror_movies$title[1289]
```
By now you should see a problem: each of these warning rows have a parenthesis in the title name! This means that R is separating based on our parenthesis, but since there are multiple parenthesis, it is separating multiple times. Therefore, it is discarding the extra separated piece in each row. Generally, you want to make sure R is not throwing away any important information. You could check this yourself by saving this as a new tibble, and investigating the rows. Hence, we will create a new tibble for demonstration purposes.

```{r}
## performing the same task but saving it in a new tibble
investigate_horror_movies <- horror_movies %>% 
  separate(col = title, into = c("title","year"), sep = "\\(") 

## investigating the 691th row of the saved tibble
investigate_horror_movies[691,]

## investigating the 928th row of the saved tibble 
investigate_horror_movies[928,]
```
Clearly, this isn't giving us our desired result for the 7 rows that were causing this issue. While we will ignore this for the purpose of this exercise, you want to be very aware of what is happening to your data.

Next, let's investigate the second warning message: Expected 2 pieces. Missing pieces filled with `NA` in 1 rows [932]. It seems as though R filled a missing piece of information in our row 932. Let's take a closer look:
```{r}
## investigating what happened in row 932
## checking the title column first in our original data
horror_movies$title[932]

## look what happened to our data in row 932
investigate_horror_movies[932,]

```

Clearly we missed something: not all the movies have the same format of MOVIE TITLE (YEAR). It appears that the movie "American Exorcist" in row 932 did not have a date attached to it. Therefore, when we tried to separate by parenthesis, R was unable to perform this task and replaced the value with NA. In our case, this wouldn't have affected our analysis since there was no date attached to it, but we would want to find another way to extract the date from another column. However, as before, we will ignore this warning message since fixing it will take a lot of time in effort. It is important to realize that **you must read and investigate warning messages** since R constantly performs operations on your data that may not be exactly what you intend. 


Moving on, let's start solving our second task: getting rid of the extra parenthesis in the `year` column. Recall, we can actually use the `extract` function here to remove the final parenthesis. We can do this all in one step using a pipe.

```{r}
## separating on the first parenthesis in the title column and then extracting the four numbers for date
horror_movies %>% 
  separate(col = title, into = c("title","year"), sep = "\\(") %>% 
  extract(col = year, into = "year", regex = "(\\d\\d\\d\\d)") 
```

Finally, let's satisfy (2) and get rid of the whitespace that is at the end of our `title` column. Luckily, the `stringr` package has a pre-programmed function called `stringr::str_trim` that will trim the whitespace off the end of our column. Now we can perform the entire cleaning of the `title` column in one piping procedure:

```{r}
## separating on the first parenthesis in the title column and then extracting the four numbers for date
## and then removing the whitespace that is left over
horror_movies %>% 
  separate(col = title, into = c("title","year"), sep = "\\(") %>% 
  extract(col = year, into = "year", regex = "(\\d\\d\\d\\d)") %>% 
  mutate(title = str_trim(title))

```


## The `gsub` function

Many times, we want to simply replace simple patterns in columns of data sets. The `stringr::str_replace` function is a simple way to take expressions within variables and substitute them with a different result. Let's create a vector of values to demonstrate.

```{r}
## creating a vector to demonstrate gsub
money <- c("$100", "$150", "$200")
```

A common use of `gsub` is to get rid of dollar signs in columns that have monetary values. Omitting the dollar sign is essential if you want to perform any type of summary statistic. 

The three arguments in the `stringr::str_replace` function that we are concerned with are the `pattern`, `replacement`, and `string` arguments. The `pattern` argument is the regular expression we want to find in our vector, and the `replacement` argument is what we would like to replace the regular expression with. The `string` argument is the vector you want to perform the `stringr::str_replace` function on. 

```{r}
## the gsub function attempting (but unsuccessfully) trying to replace the $ with nothing
str_replace(money, "\\$", "")
```

Notice that we had to once again, use the escape characters since the dollar sign is a special characer.

```{r}
## successfully replacing the $ with nothing
str_replace(money, "\\$", "")

## saving this new result
money <- str_replace(money, "\\$", "")
```


### Exercise 3

```{r}
## use the following vector for the exercise
exercise <- c("100%", "94%", "87%")

```
 * Using `stringr::str_replace`, replace the percent signs in the `exercise` vector with nothing. Then, convert the `exercise` vector to a double using `as.double`, and find the variance.
 

 
## Solutions
 
 * Exercise 1: `str_view(string = econ_classes, pattern = "\\d{1,3}")`
 * Exercise 2:  `str_view(string = vector, pattern = "[A\\s]")`
 * Exercise 3: `var_exercise <- var(as.double(gsub("\\%", "", exercise)))`. 
 

 

<!--chapter:end:strings.Rmd-->

---
title: 'Guided Exercises: Programming'
output:
  html_document:
    df_print: paged
  pdf_document:
    number_sections: yes
header-includes:
- \usepackage{fancyhdr}
- \pagestyle{fancy}
- \fancypagestyle{plain}{\pagestyle{fancy}}
- \fancyhead[LE, LO]{Econ 245 - Fall 2021}
- \fancyfoot[LE,LO]{Copyright UCSB 2021}
- \newcommand{\magenta}[1]{\textcolor{magenta}{#1}}
- \usepackage{xcolor}
editor_options:
  chunk_output_type: console
---

# Programming

For this Guided Exercise, you will not be working with a particular data set. Instead, we will be focusing on basic programming practices using vectors and functions that we create ourselves.  

## Functions

Functions are an extremely useful tool. As you will see in your homework, they can provide the benefit of nearly zero marginal cost with some upfront fixed costs. Our world is a repetitive place, and minimizing the amount of time you need to repeatedly do a task should be minimized. This is where functions will help us.

To motivate this, let's consider finding the area of a circle. The formula for area of a circle is shown in equation (1). 

\begin{equation}
Area = \pi \times r^2
\end{equation}

Suppose you wanted to find the area of two circles with radii of 3 and 5 respectively. Although a simple task, it would be painfully slow to type the numbers over and over into R and return an answer. Instead, let's create a function that will compute this area for us. 

Functions in R come with the following syntax: 
```{r, eval = F}
## function_name is the function's name that we create
## function() tells R that we are creating a function
## x is an input for the function
function_name <- function(x){
  ## body to add. 
  return()
}
```
There are a few things to note here:

* `function_name` is the name we have given our function.
* `function` tells R that we are creating a function.
* `x` is an input to the function
* `return` specifies what value should return (i.e. output).

Recall that functions are like a machine: they require an input, and using that input, create an output. In this example, our input is x, but we have not specified an output. 

To provide a concrete example, we will now create a function called `area_of_circle` that will do the following: 

1. Take the radius of the circle as an input.
2. Calculate the area of the circle.
3. Return the area of the circle as an output.

Observe:
```{r}
## This function returns the area of a circle
## This function takes 1 input: the radius of the circle
area_of_circle <- function(radius){
  area <- radius^2 * pi
  return(area)
}
```

Notice how the function was constructed. First, we write comments that explain what the function does, and what its inputs are. This is a best practice so you can understand what your function does in the future. Next, we write the actual code of the function. 

Now that we have created the function, we can input any value for the radius we like and the function will return the area of the circle.

```{r}
## Calculating area of circle with radius 3
area_of_circle(radius = 3)

## Calculating area of circle with radius 5
area_of_circle(radius = 5)
```

We could also modify the `return` statement so that it gives us a little more information:

```{r}
## This function takes 1 input: the radius of the circle
## It returns the area of the circle
area_of_circle <- function(radius){
  area <- radius^2 * pi
  return(print(paste("The area of the circle with radius", radius, "is", area)))
}
```

```{r}
## Calculating area of circle with radius 3
area_of_circle(radius = 3)

## Calculating area of circle with radius 5
area_of_circle(radius = 5)
```
### Exercise

* Create a function called `miles2kilo_feet2meter` which takes two inputs, `miles` and `feet`. The function then converts the miles input to kilometers, and the feet input to meters. The function then prints out the results, specifying each. 

## For-loops

For-loops are a common type of loop that, like functions, take care of repetitive tasks. For-loops work by iterating through a specified task for a certain amount of times. Once that specified amount of times has been met, the for-loop stops. 

The general syntax for for-loops is as follows: 
```{r, eval = F}
## for-loop syntax
for (i in {some specified range}){
  ##do something
}
```

One thing to note about for loops is the indexing variable `i`. This variable `i` will be set equal to your indexed value at each stage in the loop. We will illustrate this by example:

```{r}
## a for-loop that loops through values 1 to 5 and prints the index at each stage
for (i in 1:5){
  print(i)
}
```

The for-loop here is telling R to print the value of `i` at each iteration. The for-loop lasts for 5 iterations as we specified. Notice that at each iteration, the `i` variable is updated to match the index it is looping through. For instance, `i` is assigned to 1 the first time through the loop, 2 the second time through the loop, 3 the third time etc. However, numbers are not the only thing we can loop through. We can actually loop through all of the elements in a vector.

```{r}
## a vector for demonstration
favorite_econ = c("Econ 140A", "Econ 241", "Econ 290", "Econ 145")

## looping through each element of the favorite_econ vector
for (i in favorite_econ){
  print(i)
}
```

Here, `i` is still our index, but instead, we are telling the loop to go through each element in the vector one-by-one. Hence, on the first time through the loop, the index `i` is assigned to "Econ 140A", while `i` is assigned to "Econ 241" the second time through etc. 

Now let's try a loop that is most frequently used: looping through a entire vector's indices. 
```{r}
## looping through a vectors indices 
for (i in 1:length(favorite_econ)){
  print(favorite_econ[i])
}

```

There is quite a lot to unpack here:

* The for-loop is assigning the index `i` variable to the number 1 the first time through, 2 the second time through, and continuing on until it reaches the the number 4 which is equal to the length of the `favorite_econ` vector.
* At each iteration of the loop, we print the value of `favorite_econ` at each index. For instance, `i` is equal to 1 the first time through the loop, so the first thing that will be printed is `favorite_econ[1]` which is equivalent to "Econ 140A" (check yourself!).

Another thing to note is that you do not need to have `i` as the name of the index. In fact, when you combine multiple for-loops together, it can be helpful to change your index. Observe:

```{r}
## econ_class is the index in this case
for (econ_class in favorite_econ){
  print(econ_class)
}
```

As a final example, we will modify our `area_of_circle` function. The function will take a range of numbers as an input, and collect the area of the circle using each of these numbers as a radii. In particular, our function will take two inputs: `minradius` and `maxradius`. The `minradius` argument will be the smallest radius we would like to calculate the area of the circle with, while the `maxradius` argument will be the largest. The function will calculate the area of the circle for every integer between `minradius` and `maxradius` and return a vector with all of the areas. 

```{r}
## modifying the function to collect the area of circles with radii of integers 1 through 10
area_of_circle <- function(minradius, maxradius){
  area_vector <- rep(NA, 10) #creating an empty vector of 10 NAs
  for (i in minradius:maxradius){
    area_vector[i] = pi * i^2  #calculating the area 
  }
  return(area_vector) #returning the vector of areas
}

```

```{r}
area_of_circle(minradius = 1, maxradius = 10)
```


As an aside, it is important to note that we can also loop through columns in a data frame. This is a task you will likely need to do at some point in your data wrangling career, and there isn't much great help for this online.
```{r}
library(tidyverse)
## loading in the mtcars data set from R
cars <- mtcars

## selecting only three columns for demonstration
cars <- cars %>% select(mpg, hp, cyl)

## looping through the columns and printing them out
for (i in names(cars)){
  print(cars[i])
}
```


### Exercise

* Write a function called `sum_func` that calculates the sum of all numbers within a specified range. The function will take two inputs: `minval` which is the smallest number and `maxval` which is the largest number. 

## If-else

Conditional statements are the heart of programming. The if-else statement evaluates whether a condition is `TRUE` or `FALSE` and then perform a computation based on the truth of the statement. The syntax of an if-else statement is as follows:

```{r, eval = F}

if (logical statement){
  ##perform an action if the logical statement is TRUE 
}
else{
  ## perform a different action if NOT TRUE
}
```

For example, suppose we wanted to loop a vector of random numbers in the range of 1 to 100 and find out how many of them are greater than 50. We could do this in the following way:

```{r}
## setting the seed for replication
set.seed(1992)

## creating a random sample of 100 integers in the interval 1 to 100
numbers <- sample(1:100, 100)

## counting how many numbers come out bigger than 50
count <- 0 ## setting our counter to 0
for (i in numbers){
  ## evaluating if the number is greater than 50
  if (i > 50) {
    count <- count + 1 ## adding a 1 to our counter
  }
  else{
    count <- count ## redundant, but here for example
  }
}

```

Note the `set.seed` function. This is a function that allows replication of results when using random sampling techniques. Essentially it ensures that your random sample is the same random sample every time you run the program. While the seed was set to 1992, you can set the seed to any number you like. Of course, each seed number has its own unique sample (e.g. `set.seed(1)` will give different results than `set.seed(2)`).

### Exercise

* Loop through your `numbers` vector and assign grade values to each of the numbers, and place the grades in a separate vector. For the grade values, if the number is less than 60, assign an "F", if the number is between 60 and 69 assign a "D", if the number is between 70 and 79 assign a "C", if the number is between 80 and 89 assign a "B", and if the number is between 90 and 100 assign an "A". For fun, graph a histogram of the distribution.


\newpage

# Selected Solutions

```{r}
## a solution to Exercise 1.1.1

## this function converts miles to kilometers and feet to meters
## it takes two input paramters: miles and feet
## it returns two values: the kilometers and the meters
miles2kilo_feet2meter <- function(miles, feet){
  kilometers <- miles * 1.6
  meters <- feet * 0.3
  return(print(paste("Kilometers: ", kilometers, "Meters: ", meters)))
}

```


```{r}
## a solution to Exercise 1.2.1

## This function calculates the sum of all numbers within a specified range
## two parameters: minval and maxvalue
## minval: the minimum value of the range
## maxval: the maximum value of the range
sum_func <- function(minval, maxval) {
  total = 0
  for (i in minval:maxval) {
    total = total + i
  }
  return(print(paste("The sum of all numbers is ", total)))
}

```


<!--chapter:end:programming.Rmd-->

---
title: 'Guided Exercises: Relational Data'
output:
  html_document:
    df_print: paged
  pdf_document:
    number_sections: yes
header-includes:
- \usepackage{fancyhdr}
- \pagestyle{fancy}
- \fancypagestyle{plain}{\pagestyle{fancy}}
- \fancyhead[LE, LO]{Econ 245 - Fall 2021}
- \fancyfoot[LE,LO]{Copyright UCSB 2021}
- \newcommand{\magenta}[1]{\textcolor{magenta}{#1}}
- \usepackage{xcolor}
editor_options:
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Relational Data

For this Guided Exercise, we will be focusing on how to find *primary keys*. A primary key is a compact way of saying "how to uniquely identify observations in your data set". To practice finding primary keys, we will be using a variety of data sets that are already preloaded in R packages. The purpose of identifying primary keys is to make merging multiple data sets together easier. Merging data works best when you can merge on keys that uniquely identify your observations. This ensures that each observation is connected to their true data in the foreign data set (i.e. the data set that it will be merged to). A failure to merge your data correctly will result in inaccurate data that will not produce any meaningful result. This is what we want to avoid. 

## Finding Primary Keys 

The most useful technique to finding primary keys involves a combination of your intuition and the `count` and `filter` functions. To start, we'll load in the `titanic_train` data from the `titanic` package.

```{r, message = F}
##loading in the necessary package
library(tidyverse)
library(titanic)
library(janitor)
## data we will be working with  
titanic <- clean_names(titanic_train)
```

Let's take a look at the first few rows of our data by using the `head` function.

```{r}
##getting a snapshot of our data
titanic %>% 
  head()
```

To uniquely identify an observation, we need a column (or combination of columns) that puts each passenger into one row. In other words, since we have individual-level data, we want to find a row that will uniquely identify each individual. Since this is our first example, this is relatively simple: `passenger_id` uniquely identifies an individual, and so does `name`. While this seems intuitive, it is important to actually check whether this is true. This is where the technique of `filter` and `count` must be applied.

We will be using the following algorithm to check whether a column (or combination of columns) uniquely identifies our observations:

* Start with one column that you believe could uniquely identify an observation
* Count all of the elements in a column
* Filter out any of them that occur more than once
* If you do not receive any observation that occur more than once, you are done, if not, you must either try another column, or try a combination of columns. Use your intuition. 

This small algorithm ensures that we are uniquely identifying each observation. It clearly displays observations that occur more than once to inform us that this column (or columns) does or does not identify a primary key. To summarize, if we run our algorithm and receive any output of observations, we failed to find a primary key and need to rethink how we identify an observation. 

Let's try out this algorithm on our two columns that we intuitively thought could identify each individual.
```{r}
## using algorithm on the passenger_id column
titanic %>% 
  count(passenger_id) %>% 
  filter(n >1)
```

Success! The `passenger_id` column does not contain multiple observations of identification. Therefore, it uniquely identifies each observation, and we could use this column to merge in data from other data sets. 

```{r}
## using algorithm on the name column
titanic %>% 
  count(name) %>% 
  filter(n >1)
```

Another success! The `name` column also does not contain multiple observations of any particular name. Therefore, it also identifies each individual, and we could also use this column to merge in data from other data sets.

On the other hand, let's test the `ticket` column as it intuitively seems like it could also uniquely identify an observation (there is usually one ticket per person). 
```{r}
## testing if ticket uniquely identifies
titanic %>% 
  count(ticket) %>% 
  filter(n >1) %>% 
  head()
```

Clearly, since we see that there are multiple duplicates of ticket numbers, we cannot uniquely identify our observations using the `ticket` column. 

Our `titanic` dataset is simple in that we have two ways to uniquely identify an observation which only included one column, but this is not always true. In the next section, we will go through a harder example which will require a collection of columns. 

## Finding Primary Keys (harder)

In the `titanic` example, finding the primary keys was pretty intuitive, and a little trivial. However, this is not always the case. Let's take a look at a data set from the `babynames` package. The `babynames` data set provides data on names given at birth from the Social Security Administration. This includes all names with at least 5 uses (sorry Elon). For our purposes, we will subset the data set since the original data is almost 2 million observations.

```{r, message = F}
## loading the necessary package
library(babynames)
## selecting only the first 20,000 observations and getting rid of one of the rows we don't need
babynames <- babynames[1:20000,] %>% 
  select(-n)
```

```{r}
## getting a preview of the data
babynames %>% 
  head()
```

As we can see, there are four columns:

* `year`- the year of the birth
* `sex` - the sex of the child
* `name` - the name of the child
* `prop` - a weighting variable we do not care about

We want to uniquely identify an observation. This is where we need intuition as well as our algorithm. Would `name` uniquely identify an observation? No. A name can appear in many different years. Observe our algorithm:
```{r}
## checking if name uniquely identifies the data 
babynames %>% 
  count(name) %>% 
  filter(n >1)
```

Clearly, we see that there are multiple times a name appears. Hence, we must use a *collection* of columns to uniquely identify (recall our algorithm). 

Our intuition should tell us that using `name` and `year` may allow us to uniquely identify our data since each name likely occurs one time within each year. As always, our algorithm can check this assumption:

```{r}
## checking if name and year uniquely identifies the data
babynames %>% 
  count(name, year) %>% 
  filter(n>1)
```

It seems we are still not getting unique observations as there are many names that appear twice. Why would this be? This is where you must think critically about your data. Notice that our algorithm has shown us that names occur a maximum of two times. This should hint at something: *these names are being used for both males and females*. Therefore, to uniquely identify an observation, we must use *three* columns: `name`, `year`, and `sex`. 

```{r}
## checking if name, year, and sex uniquely identify an observation
babynames %>% 
  count(name, year, sex) %>% 
  filter(n > 1)
```

Success! We managed to find a grouping of columns that brought each observation to one entry. Hence, if we were merging in data, we would want to use these three columns to connect the data.

### Exercise

* (Taken from R for Data Science Chapter 13.3 Exercises) Identify the primary key in the following data set from the `fueleconomy` package: `vehicles`. Remember, the primary key could be a single column or a collection of columns.

### Exercise

* (Taken from R for Data Science Chapter 13.3 Exercises) Identify the primary key in the following data set from the `Lahman` package: `Batting`. Remember, the primary key could be a single column or a collection of columns.

### Exercise

* (Taken from R for Data Science Chapter 13.3 Exercises) Identify the primary key in the following data set from the `nasaweather` package: `atmos`. Remember, the primary key could be a single column or a collection of columns.


# Selected Solutions

These are shown on the next page. Please do not look at these until you have tried the exercises. These are provided because these exercises are more difficult.

\newpage

* (Exercise 1.2.1) The column `id` uniquely identifies the observations.
* (Exercise 1.2.2) The columns (`playerID`, `yearID`, `stint`) uniquely identify each observation. The columns (`playerID`,`yearID`) are not a primary key because players can play on different teams within the same year
* (Exercise 1.2.3) The primary key is (`lat`, `long`, `year`, `month`). The primary key represents the location and time that the measurement was taken.



<!--chapter:end:relational_data.Rmd-->

